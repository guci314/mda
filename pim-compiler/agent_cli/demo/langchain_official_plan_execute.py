#!/usr/bin/env python3
"""
ä½¿ç”¨ LangChain å®˜æ–¹ Plan-and-Execute Agent

åŸºäº LangChain çš„å®éªŒæ€§ plan-and-execute agents
"""

import sys
import os
from pathlib import Path

# æ·»åŠ  pim-compiler åˆ° Python è·¯å¾„
pim_compiler_path = Path(__file__).parent.parent.parent
sys.path.insert(0, str(pim_compiler_path))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
env_path = Path(__file__).parent.parent.parent / '.env'
load_dotenv(env_path)

# è®¾ç½® LLM
os.environ['LLM_PROVIDER'] = 'deepseek'

try:
    # å°è¯•å¯¼å…¥ langchain_experimental
    from langchain_experimental.plan_and_execute import (
        PlanAndExecute,
        load_agent_executor,
        load_chat_planner
    )
    EXPERIMENTAL_AVAILABLE = True
except ImportError:
    EXPERIMENTAL_AVAILABLE = False
    print("âŒ éœ€è¦å®‰è£… langchain-experimental:")
    print("   pip install langchain-experimental")

from langchain_openai import ChatOpenAI
from langchain.agents.tools import Tool
from pydantic import SecretStr

# Agent CLI å·¥å…·
from agent_cli.tools import get_all_tools
from agent_cli.core import LLMConfig


def create_langchain_tools():
    """å°† Agent CLI å·¥å…·è½¬æ¢ä¸º LangChain Tool æ ¼å¼"""
    agent_cli_tools = get_all_tools()
    
    # è½¬æ¢ä¸ºç®€å•çš„ Tool å¯¹è±¡
    tools = []
    for tool in agent_cli_tools:
        # åˆ›å»ºåŒ…è£…å‡½æ•°æ¥å¤„ç†å‚æ•°
        def make_func(t):
            def wrapper(query: str) -> str:
                try:
                    # ç®€å•çš„å‚æ•°è§£æ
                    if ":" in query:
                        parts = query.split(":", 1)
                        if len(parts) == 2:
                            return t.run({"path": parts[1].strip()})
                    return t.run(query)
                except Exception as e:
                    return f"Error: {str(e)}"
            return wrapper
        
        tools.append(Tool(
            name=tool.name,
            description=tool.description,
            func=make_func(tool)
        ))
    
    return tools


def main():
    """ä¸»å‡½æ•° - ä½¿ç”¨ LangChain å®˜æ–¹ Plan-and-Execute"""
    
    if not EXPERIMENTAL_AVAILABLE:
        return
    
    print("ğŸ¤– LangChain å®˜æ–¹ Plan-and-Execute Agent æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»º LLM
    config = LLMConfig.from_env('deepseek')
    llm = ChatOpenAI(
        api_key=SecretStr(config.api_key) if config.api_key else None,
        base_url=config.base_url,
        model=config.model,
        temperature=0
    )
    
    print(f"ä½¿ç”¨ LLM: {config.provider} - {config.model}")
    
    # è·å–å·¥å…·
    tools = create_langchain_tools()
    print(f"å¯ç”¨å·¥å…·: {len(tools)} ä¸ª")
    
    # åˆ›å»º planner
    planner = load_chat_planner(llm)
    
    # åˆ›å»º executor 
    # ä½¿ç”¨ zero-shot-react-description ä»£ç†
    executor = load_agent_executor(
        llm,
        tools,
        verbose=True
    )
    
    # åˆ›å»º Plan-and-Execute agent
    agent = PlanAndExecute(
        planner=planner,
        executor=executor,
        verbose=True
    )
    
    # æ¼”ç¤ºä»»åŠ¡
    demo_tasks = [
        "åˆ›å»ºä¸€ä¸ª hello.py æ–‡ä»¶ï¼Œå†…å®¹æ˜¯æ‰“å°å½“å‰æ—¶é—´",
        "åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰ Python æ–‡ä»¶",
        "åˆ›å»ºä¸€ä¸ªç®€å•çš„è®¡ç®—å™¨å‡½æ•°å¹¶æµ‹è¯•å®ƒ"
    ]
    
    print("\né¢„è®¾ä»»åŠ¡:")
    for i, task in enumerate(demo_tasks, 1):
        print(f"{i}. {task}")
    
    choice = input("\né€‰æ‹©ä»»åŠ¡ (1-3) æˆ–è¾“å…¥è‡ªå®šä¹‰ä»»åŠ¡: ")
    
    if choice.isdigit() and 1 <= int(choice) <= len(demo_tasks):
        task = demo_tasks[int(choice) - 1]
    else:
        task = choice
    
    print(f"\næ‰§è¡Œä»»åŠ¡: {task}")
    print("-" * 60)
    
    try:
        # æ‰§è¡Œä»»åŠ¡
        result = agent.run(task)
        
        print("\n" + "=" * 60)
        print("âœ… æ‰§è¡Œå®Œæˆ!")
        print(f"ç»“æœ: {result}")
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()