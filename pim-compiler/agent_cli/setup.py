#!/usr/bin/env python3
"""
Agent CLI 配置助手
支持多种 LLM 提供商配置
"""
import os
import sys
import json
from pathlib import Path
from getpass import getpass

from .core import LLMConfig


# LLM 提供商信息
PROVIDERS = {
    "openai": {
        "name": "OpenAI",
        "env_key": "OPENAI_API_KEY",
        "base_url": "https://api.openai.com/v1",
        "models": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
        "default_model": "gpt-3.5-turbo",
        "docs_url": "https://platform.openai.com",
        "price_input": "$0.01/1K tokens",
        "price_output": "$0.03/1K tokens"
    },
    "deepseek": {
        "name": "DeepSeek",
        "env_key": "DEEPSEEK_API_KEY",
        "base_url": "https://api.deepseek.com/v1",
        "models": ["deepseek-chat", "deepseek-coder"],
        "default_model": "deepseek-chat",
        "docs_url": "https://platform.deepseek.com",
        "price_input": "¥0.001/1K tokens",
        "price_output": "¥0.002/1K tokens"
    },
    "qwen": {
        "name": "通义千问 (Qwen)",
        "env_key": "DASHSCOPE_API_KEY",
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "models": ["qwen-turbo", "qwen-plus", "qwen-max"],
        "default_model": "qwen-turbo",
        "docs_url": "https://dashscope.console.aliyun.com",
        "price_input": "¥0.008/1K tokens",
        "price_output": "¥0.02/1K tokens"
    },
    "glm": {
        "name": "智谱清言 (GLM)",
        "env_key": "ZHIPU_API_KEY",
        "base_url": "https://open.bigmodel.cn/api/paas/v4",
        "models": ["glm-4", "glm-3-turbo"],
        "default_model": "glm-4",
        "docs_url": "https://open.bigmodel.cn",
        "price_input": "¥0.1/1K tokens",
        "price_output": "¥0.1/1K tokens"
    },
    "moonshot": {
        "name": "月之暗面 (Moonshot)",
        "env_key": "MOONSHOT_API_KEY",
        "base_url": "https://api.moonshot.cn/v1",
        "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
        "default_model": "moonshot-v1-8k",
        "docs_url": "https://platform.moonshot.cn",
        "price_input": "¥0.012/1K tokens",
        "price_output": "¥0.012/1K tokens"
    }
}


def show_providers():
    """显示所有支持的提供商"""
    print("\n支持的 LLM 提供商：")
    print("=" * 60)
    
    for key, info in PROVIDERS.items():
        print(f"\n{key}: {info['name']}")
        print(f"  文档: {info['docs_url']}")
        print(f"  模型: {', '.join(info['models'])}")
        print(f"  价格: 输入 {info['price_input']}, 输出 {info['price_output']}")


def test_llm_connection(config: LLMConfig) -> bool:
    """测试 LLM 连接"""
    print(f"\n测试 {config.provider} API 连接...")
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage
        
        llm = ChatOpenAI(
            api_key=config.api_key,
            base_url=config.base_url,
            model=config.model,
            temperature=0.3,
            max_tokens=10
        )
        
        response = llm.invoke([HumanMessage(content="Hello")])
        
        if response and response.content:
            print(f"✅ API 连接成功！")
            print(f"响应: {response.content[:50]}...")
            return True
        else:
            print(f"❌ API 返回空响应")
            return False
            
    except Exception as e:
        print(f"❌ 连接失败：{str(e)}")
        return False


def save_config(config: LLMConfig):
    """保存配置到文件"""
    # 保存到 .env 文件
    env_file = Path(".env")
    
    # 读取现有内容
    existing_lines = []
    if env_file.exists():
        with open(env_file, "r") as f:
            existing_lines = [line.strip() for line in f.readlines() 
                            if line.strip() and not line.startswith("#")]
    
    # 更新配置
    env_vars = {
        "LLM_PROVIDER": config.provider,
        PROVIDERS[config.provider]["env_key"]: config.api_key,
        f"{config.provider.upper()}_MODEL": config.model,
        f"{config.provider.upper()}_BASE_URL": config.base_url,
    }
    
    # 合并配置
    for key, value in env_vars.items():
        found = False
        for i, line in enumerate(existing_lines):
            if line.startswith(f"{key}="):
                existing_lines[i] = f"{key}={value}"
                found = True
                break
        if not found:
            existing_lines.append(f"{key}={value}")
    
    # 写入文件
    with open(env_file, "w") as f:
        f.write("# Agent CLI Configuration\n")
        f.write(f"# Generated by agent_cli setup\n\n")
        for line in existing_lines:
            f.write(f"{line}\n")
    
    print(f"\n✅ 配置已保存到 {env_file}")
    
    # 同时保存为 JSON
    config_file = Path("agent_config.json")
    config_data = {
        "provider": config.provider,
        "api_key": config.api_key,
        "base_url": config.base_url,
        "model": config.model
    }
    
    with open(config_file, "w") as f:
        json.dump(config_data, f, indent=2)
    
    print(f"✅ 配置已保存到 {config_file}")


def setup_provider():
    """设置 LLM 提供商"""
    print("\nAgent CLI 配置助手")
    print("=" * 60)
    
    # 显示提供商列表
    show_providers()
    
    # 选择提供商
    print("\n请选择 LLM 提供商：")
    provider = input("输入提供商代码 (openai/deepseek/qwen/glm/moonshot): ").strip().lower()
    
    if provider not in PROVIDERS:
        print(f"❌ 无效的提供商: {provider}")
        return False
    
    provider_info = PROVIDERS[provider]
    print(f"\n已选择: {provider_info['name']}")
    print(f"获取 API Key: {provider_info['docs_url']}")
    
    # 检查现有配置
    env_key = provider_info["env_key"]
    existing_key = os.getenv(env_key)
    if existing_key:
        print(f"\n检测到现有 API Key：{existing_key[:8]}...")
        use_existing = input("是否使用现有配置？[Y/n]: ").strip().lower()
        if use_existing != 'n':
            config = LLMConfig(
                api_key=existing_key,
                base_url=provider_info["base_url"],
                model=provider_info["default_model"],
                provider=provider
            )
            if test_llm_connection(config):
                save_config(config)
                return True
            else:
                print("\n需要重新配置")
    
    # 输入新的 API Key
    print(f"\n请输入 {provider_info['name']} API Key")
    print("(输入时不会显示，按回车确认)")
    api_key = getpass("API Key: ").strip()
    
    if not api_key:
        print("❌ API Key 不能为空")
        return False
    
    # 选择模型
    print(f"\n可用模型: {', '.join(provider_info['models'])}")
    model = input(f"选择模型 (默认: {provider_info['default_model']}): ").strip()
    if not model:
        model = provider_info["default_model"]
    elif model not in provider_info["models"]:
        print(f"⚠️ 警告: {model} 不在推荐列表中")
    
    # 询问是否使用自定义 URL
    use_custom = input("\n是否使用自定义 API 地址？[y/N]: ").strip().lower()
    if use_custom == 'y':
        base_url = input(f"API 地址 (默认: {provider_info['base_url']}): ").strip()
        if not base_url:
            base_url = provider_info["base_url"]
    else:
        base_url = provider_info["base_url"]
    
    # 创建配置
    config = LLMConfig(
        api_key=api_key,
        base_url=base_url,
        model=model,
        provider=provider
    )
    
    # 测试连接
    if test_llm_connection(config):
        save_config(config)
        
        # 设置环境变量（当前会话）
        os.environ["LLM_PROVIDER"] = provider
        os.environ[env_key] = api_key
        os.environ[f"{provider.upper()}_MODEL"] = model
        os.environ[f"{provider.upper()}_BASE_URL"] = base_url
        
        print(f"\n✅ {provider_info['name']} 配置完成！")
        print("\n下一步：")
        print("1. 运行测试：python -m agent_cli test")
        print("2. 执行任务：python -m agent_cli run '你的任务'")
        print("3. PIM 转换：python -m agent_cli convert input.md")
        
        return True
    else:
        print("\n❌ 配置失败，请检查 API Key 是否正确")
        return False


def show_prices():
    """显示价格对比"""
    print("\nLLM 价格对比（2024年）：")
    print("=" * 60)
    print(f"{'提供商':<15} {'输入价格':<20} {'输出价格':<20}")
    print("-" * 60)
    
    for key, info in PROVIDERS.items():
        print(f"{info['name']:<15} {info['price_input']:<20} {info['price_output']:<20}")
    
    print("\n注：价格可能会变化，请查看官方文档获取最新价格")


def main():
    """主函数"""
    if len(sys.argv) > 1 and sys.argv[1] == "--prices":
        show_prices()
        return
    
    if len(sys.argv) > 1 and sys.argv[1] == "--list":
        show_providers()
        return
    
    setup_provider()


if __name__ == "__main__":
    main()