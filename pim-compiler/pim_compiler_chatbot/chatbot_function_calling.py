#!/usr/bin/env python3
"""
PIM Compiler Chatbot - åŸç”Ÿ Function Calling ç‰ˆæœ¬
ä½¿ç”¨ LangChain çš„å‡½æ•°è°ƒç”¨åŠŸèƒ½ï¼Œé¿å…æ‰‹åŠ¨å‚æ•°æ¸…ç†
"""

import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from pydantic import BaseModel, Field

from pim_compiler_chatbot.chatbot import PIMCompilerTools


# ä½¿ç”¨ Pydantic å®šä¹‰å‚æ•°æ¨¡å‹ï¼Œè¿™æ · LangChain ä¼šè‡ªåŠ¨å¤„ç†å‚æ•°éªŒè¯å’Œæ¸…ç†
class SearchInput(BaseModel):
    """æœç´¢è¾“å…¥å‚æ•°"""
    query: str = Field(description="æœç´¢å…³é”®è¯ï¼Œå¦‚'åšå®¢'ã€'åŒ»é™¢'ã€'ç”¨æˆ·'ç­‰")


class CompileInput(BaseModel):
    """ç¼–è¯‘è¾“å…¥å‚æ•°"""
    file_path: str = Field(description="PIMæ–‡ä»¶è·¯å¾„ï¼Œå¦‚ 'examples/blog.md'")


class LogInput(BaseModel):
    """æ—¥å¿—æŸ¥çœ‹è¾“å…¥å‚æ•°"""
    system_name: Optional[str] = Field(default=None, description="ç³»ç»Ÿåç§°ï¼Œå¦‚'blog'ã€'hospital'ã€‚ä¸æä¾›åˆ™æ˜¾ç¤ºæ‰€æœ‰")


class StopInput(BaseModel):
    """åœæ­¢ç¼–è¯‘è¾“å…¥å‚æ•°"""
    system_name: Optional[str] = Field(default=None, description="è¦ç»ˆæ­¢çš„ç³»ç»Ÿåç§°")


# åˆå§‹åŒ–å·¥å…·å®ä¾‹ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
# è·å– pim-compiler ç›®å½•è·¯å¾„ï¼ˆchatbot.py çš„çˆ¶ç›®å½•ï¼‰
pim_compiler_path = Path(__file__).parent.parent
tools_instance = PIMCompilerTools(pim_compiler_path=str(pim_compiler_path))


# ä½¿ç”¨ @tool è£…é¥°å™¨åˆ›å»ºå·¥å…·ï¼Œè‡ªåŠ¨å¤„ç†å‚æ•°
@tool("search_pim_files", args_schema=SearchInput)
def search_pim_files(query: str) -> str:
    """æœç´¢ PIM æ–‡ä»¶"""
    return tools_instance.search_pim_files(query)


@tool("compile_pim", args_schema=CompileInput)
def compile_pim(file_path: str) -> str:
    """ç¼–è¯‘ PIM æ–‡ä»¶"""
    return tools_instance.compile_pim(file_path)


@tool("check_log", args_schema=LogInput)
def check_log(system_name: Optional[str] = None) -> str:
    """æŸ¥çœ‹ç¼–è¯‘æ—¥å¿—"""
    return tools_instance.check_log(system_name)


@tool("list_projects")
def list_projects() -> str:
    """åˆ—å‡ºæ‰€æœ‰å·²ç¼–è¯‘çš„é¡¹ç›®"""
    return tools_instance.list_compiled_projects("")


@tool("stop_compilation", args_schema=StopInput)
def stop_compilation(system_name: Optional[str] = None) -> str:
    """ç»ˆæ­¢ç¼–è¯‘è¿›ç¨‹"""
    return tools_instance.stop_compilation(system_name)


def create_function_calling_agent(llm_config: Optional[Dict[str, Any]] = None):
    """åˆ›å»ºä½¿ç”¨åŸç”Ÿ Function Calling çš„ Agent"""
    
    # å·¥å…·åˆ—è¡¨
    tools = [
        search_pim_files,
        compile_pim,
        check_log,
        list_projects,
        stop_compilation
    ]
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ PIM ç¼–è¯‘å™¨åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç¼–è¯‘ PIMï¼ˆå¹³å°æ— å…³æ¨¡å‹ï¼‰æ–‡ä»¶ã€‚

ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·ï¼š
1. æœç´¢å’Œç¼–è¯‘ PIM æ–‡ä»¶
2. æŸ¥çœ‹ç¼–è¯‘è¿›åº¦å’Œæ—¥å¿—
3. ç®¡ç†ç¼–è¯‘è¾“å‡º
4. ç»ˆæ­¢ç¼–è¯‘è¿›ç¨‹

ä½¿ç”¨å·¥å…·æ—¶è¯·æ³¨æ„ï¼š
- å½“ç”¨æˆ·è¯´"ç¼–è¯‘XXç³»ç»Ÿ"æ—¶ï¼Œå…ˆæœç´¢ç›¸å…³æ–‡ä»¶ï¼Œç„¶åç¼–è¯‘
- ç”¨æˆ·å¯èƒ½ä½¿ç”¨ä¸­æ–‡æˆ–è‹±æ–‡ï¼Œè¦çµæ´»ç†è§£
- æä¾›æ¸…æ™°ã€æœ‰å¸®åŠ©çš„å“åº”"""),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    # åˆ›å»º LLM
    if llm_config is None:
        llm_config = {
            "model": "gpt-3.5-turbo",
            "temperature": 0.3
        }
    
    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
    if "openai_api_key" in llm_config:
        llm_config["api_key"] = llm_config.pop("openai_api_key")
    if "openai_api_base" in llm_config:
        llm_config["base_url"] = llm_config.pop("openai_api_base")
    
    llm = ChatOpenAI(**llm_config)
    
    # åˆ›å»º OpenAI Tools Agent (æ”¯æŒåŸç”Ÿ function calling)
    agent = create_openai_tools_agent(llm, tools, prompt)
    
    # åˆ›å»º Agent Executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        max_iterations=5,
        handle_parsing_errors=True,
        return_intermediate_steps=False
    )
    
    return agent_executor


# åˆ›å»ºä¸€ä¸ªæ›´ç®€æ´çš„å¯¹è¯å¼æ¥å£
class PIMCompilerChat:
    """PIM ç¼–è¯‘å™¨èŠå¤©æ¥å£"""
    
    def __init__(self, llm_config: Optional[Dict[str, Any]] = None):
        self.agent = create_function_calling_agent(llm_config)
        self.history: List[Any] = []
    
    def chat(self, message: str) -> str:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›å“åº”"""
        try:
            result = self.agent.invoke({
                "input": message,
                "chat_history": self.history
            })
            
            # æ›´æ–°å†å²
            self.history.append(HumanMessage(content=message))
            self.history.append(AIMessage(content=result["output"]))
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†é•¿åº¦
            if len(self.history) > 20:
                self.history = self.history[-20:]
            
            return result["output"]
        except Exception as e:
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºé”™äº†: {str(e)}"


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– PIM ç¼–è¯‘å™¨åŠ©æ‰‹ - åŸç”Ÿ Function Calling ç‰ˆæœ¬")
    print("=" * 60)
    print("è¿™ä¸ªç‰ˆæœ¬ä½¿ç”¨åŸç”Ÿçš„å‡½æ•°è°ƒç”¨ï¼Œæ— éœ€æ‰‹åŠ¨å‚æ•°æ¸…ç†")
    print()
    
    # é…ç½® LLM
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    if deepseek_key:
        llm_config = {
            "api_key": deepseek_key,
            "base_url": "https://api.deepseek.com/v1",
            "model": "deepseek-chat",
            "temperature": 0.3
        }
        print("âœ… ä½¿ç”¨ DeepSeek æ¨¡å‹\n")
    else:
        print("âš ï¸  æœªè®¾ç½® DEEPSEEK_API_KEY\n")
        return
    
    # åˆ›å»ºèŠå¤©æ¥å£
    chat = PIMCompilerChat(llm_config)
    
    print("è¾“å…¥ 'exit' é€€å‡º")
    print("=" * 60)
    
    # å¯ç”¨å‘½ä»¤å†å²
    try:
        import readline
        # è®¾ç½®å†å²æ–‡ä»¶
        history_file = Path.home() / ".pim_compiler_history"
        if history_file.exists():
            readline.read_history_file(str(history_file))
        
        # è®¾ç½®è‡ªåŠ¨ä¿å­˜
        import atexit
        atexit.register(readline.write_history_file, str(history_file))
    except ImportError:
        pass  # Windows ç³»ç»Ÿå¯èƒ½æ²¡æœ‰ readline
    
    # äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("\nä½ : ").strip()
            
            if user_input.lower() in ['exit', 'quit']:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # è·å–å“åº”
            response = chat.chat(user_input)
            print(f"\nåŠ©æ‰‹: {response}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‡ºé”™äº†: {str(e)}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()