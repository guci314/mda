#!/usr/bin/env python3
"""
PIM Compiler Chatbot - Tool Calling Agent ç‰ˆæœ¬
ä½¿ç”¨æ›´ç°ä»£çš„ Tool Calling Agent æ›¿ä»£ ReAct Agent
"""

import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain.tools import Tool

from pim_compiler_chatbot.chatbot import PIMCompilerTools


def create_tool_calling_pim_agent(llm_config: Optional[Dict[str, Any]] = None):
    """åˆ›å»ºä½¿ç”¨ Tool Calling çš„ PIM ç¼–è¯‘å™¨æ™ºèƒ½ä½“"""
    
    # åˆå§‹åŒ–å·¥å…·ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    pim_compiler_path = Path(__file__).parent.parent
    tools_instance = PIMCompilerTools(pim_compiler_path=str(pim_compiler_path))
    
    # åˆ›å»ºé€šç”¨çš„å‚æ•°æ¸…ç†å‡½æ•°
    def clean_param(param: str) -> str:
        """æ¸…ç† LangChain ä¼ é€’çš„å‚æ•°"""
        if not param:
            return ""
        # å»é™¤é¦–å°¾ç©ºç™½å’Œå¼•å·
        cleaned = param.strip()
        # å»é™¤å¯èƒ½çš„å¼•å·ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰
        while cleaned and cleaned[0] in '"\'':
            cleaned = cleaned[1:]
        while cleaned and cleaned[-1] in '"\'':
            cleaned = cleaned[:-1]
        # å†æ¬¡å»é™¤ç©ºç™½
        cleaned = cleaned.strip()
        return cleaned
    
    # åˆ›å»ºå·¥å…·åˆ—è¡¨
    tools = [
        Tool(
            name="search_pim_files",
            func=lambda q: tools_instance.search_pim_files(clean_param(q)),
            description="æœç´¢ PIM æ–‡ä»¶ã€‚è¾“å…¥æœç´¢å…³é”®è¯ã€‚"
        ),
        Tool(
            name="compile_pim",
            func=lambda f: tools_instance.compile_pim(clean_param(f)),
            description="ç¼–è¯‘ PIM æ–‡ä»¶ã€‚è¾“å…¥æ–‡ä»¶è·¯å¾„ã€‚"
        ),
        Tool(
            name="check_log",
            func=lambda s: tools_instance.check_log(clean_param(s) if clean_param(s) else None),
            description="æŸ¥çœ‹ç¼–è¯‘æ—¥å¿—ã€‚å¯é€‰è¾“å…¥ç³»ç»Ÿåç§°ã€‚"
        ),
        Tool(
            name="list_projects",
            func=lambda _: tools_instance.list_compiled_projects(""),
            description="åˆ—å‡ºæ‰€æœ‰å·²ç¼–è¯‘çš„é¡¹ç›®ã€‚"
        ),
        Tool(
            name="stop_compilation",
            func=lambda s: tools_instance.stop_compilation(clean_param(s) if clean_param(s) else None),
            description="ç»ˆæ­¢ç¼–è¯‘è¿›ç¨‹ã€‚å¯é€‰è¾“å…¥ç³»ç»Ÿåç§°ã€‚"
        )
    ]
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿ - Tool Calling Agent ä½¿ç”¨ä¸åŒçš„æ ¼å¼
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ PIM ç¼–è¯‘å™¨åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç¼–è¯‘ PIMï¼ˆå¹³å°æ— å…³æ¨¡å‹ï¼‰æ–‡ä»¶ã€‚

ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·ï¼š
1. æœç´¢å’Œç¼–è¯‘ PIM æ–‡ä»¶
2. æŸ¥çœ‹ç¼–è¯‘è¿›åº¦å’Œæ—¥å¿—
3. ç®¡ç†ç¼–è¯‘è¾“å‡º
4. ç»ˆæ­¢ç¼–è¯‘è¿›ç¨‹

ä½¿ç”¨å·¥å…·æ—¶è¯·æ³¨æ„ï¼š
- å½“ç”¨æˆ·è¯´"ç¼–è¯‘XXç³»ç»Ÿ"æ—¶ï¼Œå…ˆæœç´¢ç›¸å…³æ–‡ä»¶ï¼Œç„¶åç¼–è¯‘
- ç”¨æˆ·å¯èƒ½ä½¿ç”¨ä¸­æ–‡æˆ–è‹±æ–‡ï¼Œè¦çµæ´»ç†è§£
- æä¾›æ¸…æ™°ã€æœ‰å¸®åŠ©çš„å“åº”"""),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    # åˆ›å»º LLM
    if llm_config is None:
        llm_config = {
            "model": "gpt-3.5-turbo",
            "temperature": 0.3
        }
    
    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
    if "openai_api_key" in llm_config:
        llm_config["api_key"] = llm_config.pop("openai_api_key")
    if "openai_api_base" in llm_config:
        llm_config["base_url"] = llm_config.pop("openai_api_base")
    
    llm = ChatOpenAI(**llm_config)
    
    # åˆ›å»º Tool Calling Agent
    agent = create_tool_calling_agent(llm, tools, prompt)
    
    # åˆ›å»º Agent Executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        max_iterations=5,
        handle_parsing_errors=True,
        return_intermediate_steps=False
    )
    
    return agent_executor


def create_openai_functions_agent(llm_config: Optional[Dict[str, Any]] = None):
    """åˆ›å»ºä½¿ç”¨ OpenAI Functions çš„ Agentï¼ˆæ›´é€‚åˆ GPT æ¨¡å‹ï¼‰"""
    from langchain.agents import create_openai_functions_agent
    
    # åˆå§‹åŒ–å·¥å…·ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    pim_compiler_path = Path(__file__).parent.parent
    tools_instance = PIMCompilerTools(pim_compiler_path=str(pim_compiler_path))
    
    # åˆ›å»ºé€šç”¨çš„å‚æ•°æ¸…ç†å‡½æ•°
    def clean_param(param: str) -> str:
        """æ¸…ç† LangChain ä¼ é€’çš„å‚æ•°"""
        if not param:
            return ""
        cleaned = param.strip()
        while cleaned and cleaned[0] in '"\'':
            cleaned = cleaned[1:]
        while cleaned and cleaned[-1] in '"\'':
            cleaned = cleaned[:-1]
        cleaned = cleaned.strip()
        return cleaned
    
    # åˆ›å»ºå·¥å…·åˆ—è¡¨ - Functions Agent éœ€è¦æ›´è¯¦ç»†çš„æè¿°
    tools = [
        Tool(
            name="search_pim_files",
            func=lambda q: tools_instance.search_pim_files(clean_param(q)),
            description="æœç´¢ PIM æ–‡ä»¶ã€‚å‚æ•°ï¼šquery (str) - æœç´¢å…³é”®è¯ï¼Œå¦‚'åŒ»é™¢'ã€'hospital'ã€'åšå®¢'ç­‰ã€‚"
        ),
        Tool(
            name="compile_pim",
            func=lambda f: tools_instance.compile_pim(clean_param(f)),
            description="ç¼–è¯‘ PIM æ–‡ä»¶ã€‚å‚æ•°ï¼šfile_path (str) - PIMæ–‡ä»¶è·¯å¾„ï¼Œå¦‚ 'examples/blog.md'ã€‚"
        ),
        Tool(
            name="check_log",
            func=lambda s: tools_instance.check_log(clean_param(s) if clean_param(s) else None),
            description="æŸ¥çœ‹ç¼–è¯‘æ—¥å¿—å’Œè¿›åº¦ã€‚å‚æ•°ï¼šsystem_name (str, optional) - ç³»ç»Ÿåç§°ï¼Œå¦‚'blog'ã€'hospital'ã€‚ä¸æä¾›åˆ™æ˜¾ç¤ºæ‰€æœ‰ã€‚"
        ),
        Tool(
            name="list_projects",
            func=lambda _: tools_instance.list_compiled_projects(""),
            description="åˆ—å‡ºæ‰€æœ‰å·²ç¼–è¯‘çš„é¡¹ç›®ã€‚æ— éœ€å‚æ•°ã€‚"
        ),
        Tool(
            name="stop_compilation",
            func=lambda s: tools_instance.stop_compilation(clean_param(s) if clean_param(s) else None),
            description="ç»ˆæ­¢ç¼–è¯‘è¿›ç¨‹ã€‚å‚æ•°ï¼šsystem_name (str, optional) - è¦ç»ˆæ­¢çš„ç³»ç»Ÿåç§°ã€‚"
        )
    ]
    
    # Functions Agent çš„æç¤ºæ›´ç®€æ´
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ PIM ç¼–è¯‘å™¨åŠ©æ‰‹ã€‚å¸®åŠ©ç”¨æˆ·æœç´¢ã€ç¼–è¯‘ PIM æ–‡ä»¶ï¼ŒæŸ¥çœ‹æ—¥å¿—ï¼Œç®¡ç†é¡¹ç›®ã€‚"),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    # é…ç½® LLM
    if llm_config is None:
        llm_config = {"model": "gpt-3.5-turbo", "temperature": 0}
    
    llm = ChatOpenAI(**llm_config)
    
    # åˆ›å»º OpenAI Functions Agent
    agent = create_openai_functions_agent(llm, tools, prompt)
    
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        max_iterations=3
    )


def create_structured_chat_agent(llm_config: Optional[Dict[str, Any]] = None):
    """åˆ›å»ºç»“æ„åŒ–èŠå¤© Agentï¼ˆæ”¯æŒå¤æ‚çš„å¤šæ­¥éª¤æ¨ç†ï¼‰"""
    from langchain.agents import create_structured_chat_agent
    
    tools_instance = PIMCompilerTools()
    
    # ç»“æ„åŒ– Agent çš„å·¥å…·å®šä¹‰
    tools = [
        Tool(
            name="search_pim_files",
            func=lambda q: tools_instance.search_pim_files(q.strip()),
            description=(
                "æœç´¢ PIM æ–‡ä»¶ã€‚\n"
                "è¾“å…¥æ ¼å¼: æœç´¢å…³é”®è¯\n"
                "è¾“å‡ºæ ¼å¼: æ‰¾åˆ°çš„æ–‡ä»¶åˆ—è¡¨"
            )
        ),
        Tool(
            name="compile_pim",
            func=lambda f: tools_instance.compile_pim(f.strip()),
            description=(
                "ç¼–è¯‘ PIM æ–‡ä»¶ã€‚\n"
                "è¾“å…¥æ ¼å¼: æ–‡ä»¶è·¯å¾„ (å¦‚ examples/blog.md)\n"
                "è¾“å‡ºæ ¼å¼: ç¼–è¯‘çŠ¶æ€ä¿¡æ¯"
            )
        ),
        Tool(
            name="check_log",
            func=lambda s: tools_instance.check_log(s.strip() if s and s.strip() else None),
            description=(
                "æŸ¥çœ‹ç¼–è¯‘æ—¥å¿—ã€‚\n"
                "è¾“å…¥æ ¼å¼: [å¯é€‰] ç³»ç»Ÿåç§°\n"
                "è¾“å‡ºæ ¼å¼: æ—¥å¿—å†…å®¹å’Œè¿›åº¦"
            )
        ),
        Tool(
            name="list_projects",
            func=lambda _: tools_instance.list_compiled_projects(""),
            description="åˆ—å‡ºæ‰€æœ‰å·²ç¼–è¯‘çš„é¡¹ç›®ã€‚"
        ),
        Tool(
            name="stop_compilation",
            func=lambda s: tools_instance.stop_compilation(s.strip() if s and s.strip() else None),
            description=(
                "ç»ˆæ­¢ç¼–è¯‘è¿›ç¨‹ã€‚\n"
                "è¾“å…¥æ ¼å¼: [å¯é€‰] ç³»ç»Ÿåç§°\n"
                "è¾“å‡ºæ ¼å¼: ç»ˆæ­¢ç»“æœ"
            )
        )
    ]
    
    # ç»“æ„åŒ– Chat Agent çš„æç¤ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ PIM ç¼–è¯‘å™¨åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

æ€è€ƒï¼šåˆ†æç”¨æˆ·éœ€æ±‚
è®¡åˆ’ï¼šåˆ—å‡ºéœ€è¦æ‰§è¡Œçš„æ­¥éª¤
æ‰§è¡Œï¼šä½¿ç”¨å·¥å…·å®Œæˆä»»åŠ¡
æ€»ç»“ï¼šç®€æ´åœ°æ€»ç»“ç»“æœ

å¯ç”¨å·¥å…·ï¼š{tools}
å·¥å…·åç§°ï¼š{tool_names}"""),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    if llm_config is None:
        llm_config = {"model": "gpt-3.5-turbo", "temperature": 0.3}
    
    llm = ChatOpenAI(**llm_config)
    
    agent = create_structured_chat_agent(llm, tools, prompt)
    
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True
    )


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºä¸åŒç±»å‹çš„ Agent"""
    print("ğŸ¤– PIM ç¼–è¯‘å™¨åŠ©æ‰‹ - Agent ç±»å‹é€‰æ‹©")
    print("=" * 60)
    print("1. Tool Calling Agent (æ¨è)")
    print("2. OpenAI Functions Agent")
    print("3. Structured Chat Agent")
    print("4. ReAct Agent (åŸç‰ˆ)")
    
    choice = input("\né€‰æ‹© Agent ç±»å‹ [1-4, é»˜è®¤1]: ").strip() or "1"
    
    # é…ç½® LLM
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    if deepseek_key:
        llm_config = {
            "api_key": deepseek_key,
            "base_url": "https://api.deepseek.com/v1",
            "model": "deepseek-chat",
            "temperature": 0.3
        }
        print(f"\nâœ… ä½¿ç”¨ DeepSeek æ¨¡å‹")
    else:
        print("\nâš ï¸  æœªè®¾ç½® DEEPSEEK_API_KEY")
        return
    
    # åˆ›å»ºé€‰å®šçš„ Agent
    if choice == "1":
        print("ä½¿ç”¨ Tool Calling Agent...")
        agent = create_tool_calling_pim_agent(llm_config)
    elif choice == "2":
        print("ä½¿ç”¨ OpenAI Functions Agent...")
        agent = create_openai_functions_agent(llm_config)
    elif choice == "3":
        print("ä½¿ç”¨ Structured Chat Agent...")
        agent = create_structured_chat_agent(llm_config)
    else:
        print("ä½¿ç”¨ ReAct Agent...")
        from pim_compiler_chatbot.chatbot import create_pim_compiler_agent
        agent = create_pim_compiler_agent(llm_config)
    
    print("\nè¾“å…¥ 'exit' é€€å‡º\n")
    
    # äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("\nä½ : ").strip()
            
            if user_input.lower() in ['exit', 'quit']:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # æ‰§è¡Œ agent
            result = agent.invoke({"input": user_input})
            print(f"\nåŠ©æ‰‹: {result['output']}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‡ºé”™äº†: {str(e)}")


if __name__ == "__main__":
    main()