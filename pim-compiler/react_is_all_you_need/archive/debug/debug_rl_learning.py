#!/usr/bin/env python3
"""
å¼ºåŒ–å­¦ä¹ å¼è°ƒè¯•çŸ¥è¯†ä¼˜åŒ–
åªæä¾›ç®€å•å¥–åŠ±ï¼Œè®©ç³»ç»Ÿè‡ªå·±å‘ç°ä¼˜åŒ–æ¨¡å¼
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd()))

from core.react_agent_minimal import ReactAgentMinimal

print("ğŸ§  å¼ºåŒ–å­¦ä¹ å¼å…ƒè®¤çŸ¥ä¼˜åŒ–")
print("=" * 60)

# åˆ›å»ºå…ƒè®¤çŸ¥Agent - åªç»™æœ€ç®€å•çš„æŒ‡å¯¼
meta_agent = ReactAgentMinimal(
    work_dir=".",
    name="rl_meta_agent",
    description="é€šè¿‡è¯•é”™å­¦ä¹ ä¼˜åŒ–",
    model="kimi-k2-turbo-preview",
    knowledge_files=[
        "knowledge/meta_cognitive_simple.md"
    ]
)

# æç®€ä»»åŠ¡ - åªå®šä¹‰å¥–åŠ±ï¼Œä¸å®šä¹‰æ–¹æ³•
task = """
# ä»»åŠ¡ï¼šä¼˜åŒ–è°ƒè¯•æµç¨‹

## å†å²æ•°æ®
- æŸAgentç”¨äº†86è½®å®Œæˆè°ƒè¯•
- æµ‹è¯•æœ€ç»ˆ100%é€šè¿‡

## å¥–åŠ±å‡½æ•°
```python
def reward(rounds, success):
    if not success:
        return -100  # å¤±è´¥æƒ©ç½š
    else:
        return max(0, 100 - rounds)  # è½®æ•°è¶Šå°‘å¥–åŠ±è¶Šé«˜
```

## ä½ çš„ä»»åŠ¡
1. åˆ†æä¸ºä»€ä¹ˆéœ€è¦86è½®
2. å‘ç°å¯ä»¥ä¼˜åŒ–çš„æ¨¡å¼
3. å°†å‘ç°å†™å…¥`knowledge/mda/debugging_unified.md`

## é™åˆ¶
- ä¸è¦å‚è€ƒ`debug_error_patterns.md`ï¼ˆäººç±»çŸ¥è¯†ï¼‰
- è‡ªå·±å‘ç°ä¼˜åŒ–æ¨¡å¼
- ç›®æ ‡ï¼šè®©æœªæ¥è°ƒè¯•è·å¾—æ›´é«˜å¥–åŠ±ï¼ˆæ›´å°‘è½®æ•°ï¼‰

## å¯ç”¨ä¿¡æ¯
86è½®è°ƒè¯•çš„å…³é”®å¤±è´¥ç‚¹ï¼š
- è½®1-30ï¼šé‡å¤å°è¯•ä¸åŒæµ‹è¯•å‘½ä»¤
- è½®31-60ï¼šé€ä¸ªæ–‡ä»¶ä¿®å¤Pydanticå…¼å®¹æ€§
- è½®61-86ï¼šé€ä¸ªä¿®å¤å…¶ä»–é”™è¯¯

è¯·è‡ªå·±å‘ç°ï¼šä»€ä¹ˆå¯¼è‡´äº†ä½æ•ˆï¼Ÿå¦‚ä½•æ”¹è¿›ï¼Ÿ
"""

result = meta_agent.execute(task=task)

print("\n" + "=" * 60)
print("âœ… å¼ºåŒ–å­¦ä¹ å¼ä¼˜åŒ–å®Œæˆ")
if result:
    print(f"\nAgentè‡ªä¸»å‘ç°çš„æ¨¡å¼ï¼š")
    print(result[:1000])
print("=" * 60)