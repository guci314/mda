#!/usr/bin/env python3
"""
Cognitive Memory Integration Layer
è¿æ¥SimpleMemoryManagerï¼ˆæŠ€æœ¯å±‚ï¼‰å’ŒNLPLMemorySystemï¼ˆè®¤çŸ¥å±‚ï¼‰
"""

import os
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import json

from .simple_memory_manager import SimpleMemoryManager, Message
from .nlpl_memory_system import NLPLMemorySystem, MemoryEvent
from .react_agent import ReactAgent  # type: ignore


class CognitiveMemoryIntegration:
    """
    è®¤çŸ¥è®°å¿†é›†æˆå±‚
    åè°ƒSimpleMemoryManagerå’ŒNLPLMemorySystemçš„å·¥ä½œ
    """
    
    def __init__(self, 
                 work_dir: str = ".",
                 window_size: int = 50,
                 memory_dir: str = ".memory"):
        """
        åˆå§‹åŒ–é›†æˆå±‚
        
        Args:
            work_dir: å·¥ä½œç›®å½•
            window_size: æ¶ˆæ¯çª—å£å¤§å°
            memory_dir: è®°å¿†ç³»ç»Ÿç›®å½•
        """
        self.work_dir = Path(work_dir)
        self.work_dir.mkdir(parents=True, exist_ok=True)
        
        # æŠ€æœ¯å±‚ï¼šæ¶ˆæ¯ç®¡ç†
        self.message_manager = SimpleMemoryManager(window_size=window_size)
        
        # è®¤çŸ¥å±‚ï¼šè®°å¿†ç³»ç»Ÿ
        self.memory_system = NLPLMemorySystem(memory_dir=str(self.work_dir / memory_dir))
        
        # 4å±‚Agentï¼ˆæ‡’åŠ è½½ï¼‰
        self._agents = {}
        self._init_counters()
        
    def _init_counters(self):
        """åˆå§‹åŒ–è®¡æ•°å™¨"""
        self.total_rounds = 0
        self.message_count = 0
        self.episode_count = 0
        
    # ========== æ¶ˆæ¯å¤„ç† ==========
    
    def add_message(self, role: str, content: str, 
                   tool_calls: Optional[List[Dict]] = None) -> None:
        """
        æ·»åŠ æ¶ˆæ¯å¹¶è§¦å‘è®¤çŸ¥å¤„ç†
        
        Args:
            role: æ¶ˆæ¯è§’è‰²
            content: æ¶ˆæ¯å†…å®¹
            tool_calls: å·¥å…·è°ƒç”¨
        """
        # 1. æ·»åŠ åˆ°æ¶ˆæ¯çª—å£
        self.message_manager.add_message(role, content, tool_calls)
        self.message_count += 1
        
        # 2. è§¦å‘è§‚å¯Ÿï¼ˆæ¯10æ¡æ¶ˆæ¯ï¼‰
        if self.message_count % 10 == 0:
            self._trigger_observation()
        
        # 3. è§¦å‘å·©å›ºï¼ˆæ¯50ä¸ªäº‹ä»¶ï¼‰
        if self.episode_count >= 50:
            self._trigger_consolidation()
            self.episode_count = 0
            
        # 4. è§¦å‘å…ƒè®¤çŸ¥ï¼ˆæ¯100è½®ï¼‰
        if self.total_rounds >= 100:
            self._trigger_metacognition()
            self.total_rounds = 0
    
    def process_task_completion(self, task_name: str, success: bool, 
                               rounds: int) -> Tuple[str, str, str]:
        """
        å¤„ç†ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæƒ…æ™¯è®°å¿†
        
        Args:
            task_name: ä»»åŠ¡åç§°
            success: æ˜¯å¦æˆåŠŸ
            rounds: æ‰§è¡Œè½®æ•°
            
        Returns:
            ä¸‰ä¸ªè®°å¿†æ–‡ä»¶è·¯å¾„
        """
        # ä»æ¶ˆæ¯å†å²æå–æ‰§è¡Œç‰¹å¾
        messages = self.message_manager.get_messages()
        event = self._extract_event_from_messages(task_name, success, rounds, messages)
        
        # åˆ›å»ºæƒ…æ™¯è®°å¿†
        paths = self.memory_system.create_episodic_memory(event)
        self.episode_count += 1
        
        return paths
    
    # ========== è®¤çŸ¥è§¦å‘ ==========
    
    def _trigger_observation(self):
        """è§¦å‘L2è§‚å¯ŸAgent"""
        print("ğŸ” è§¦å‘è§‚å¯ŸAgentåˆ†ææ‰§è¡Œæ¨¡å¼...")
        
        # è·å–è§‚å¯ŸAgent
        observer = self._get_observer_agent()
        
        # å‡†å¤‡è§‚å¯Ÿä»»åŠ¡
        messages = self.message_manager.get_recent_messages(10)
        observation_task = self._prepare_observation_task(messages)
        
        # æ‰§è¡Œè§‚å¯Ÿï¼ˆå¼‚æ­¥æˆ–åŒæ­¥ï¼‰
        try:
            result = observer.execute_task(observation_task)
            print("âœ… è§‚å¯Ÿå®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ è§‚å¯Ÿå¤±è´¥ï¼š{e}")
    
    def _trigger_consolidation(self):
        """è§¦å‘L3æµ·é©¬ä½“Agent"""
        print("ğŸ§  è§¦å‘æµ·é©¬ä½“å·©å›ºè®°å¿†...")
        
        # è·å–æµ·é©¬ä½“Agent
        hippocampus = self._get_hippocampus_agent()
        
        # æ‰§è¡Œå·©å›º
        consolidation_task = """
        æ‰«ææœ€è¿‘çš„æƒ…æ™¯è®°å¿†ï¼Œæå–å¯å¤ç”¨çš„æ¨¡å¼å’ŒçŸ¥è¯†ã€‚
        å°†é‡å¤å‡ºç°çš„æ¨¡å¼ä¿å­˜ä¸ºè¯­ä¹‰è®°å¿†ï¼Œ
        å°†æˆåŠŸçš„æ‰§è¡Œæ­¥éª¤ä¿å­˜ä¸ºç¨‹åºæ€§è®°å¿†ã€‚
        """
        
        try:
            result = hippocampus.execute_task(consolidation_task)
            print("âœ… è®°å¿†å·©å›ºå®Œæˆ")
            
            # åº”ç”¨æ—¶é—´è¡°å‡
            decay_log = self.memory_system.apply_temporal_decay()
            if decay_log:
                print(f"ğŸ• æ—¶é—´è¡°å‡å¤„ç†ï¼š{len(decay_log)}ä¸ªæ–‡ä»¶")
                
        except Exception as e:
            print(f"âš ï¸ å·©å›ºå¤±è´¥ï¼š{e}")
    
    def _trigger_metacognition(self):
        """è§¦å‘L4å…ƒè®¤çŸ¥Agent"""
        print("ğŸ¯ è§¦å‘å…ƒè®¤çŸ¥è¯„ä¼°...")
        
        # è·å–å…ƒè®¤çŸ¥Agent  
        metacognition = self._get_metacognition_agent()
        
        # å‡†å¤‡è¯„ä¼°æ•°æ®
        stats = self._collect_system_stats()
        evaluation_task = f"""
        è¯„ä¼°ç³»ç»Ÿæ•´ä½“è¡¨ç°ï¼š
        {json.dumps(stats, indent=2, ensure_ascii=False)}
        
        ç”Ÿæˆä¼˜åŒ–å»ºè®®å’Œç­–ç•¥è°ƒæ•´ã€‚
        """
        
        try:
            result = metacognition.execute_task(evaluation_task)
            print("âœ… å…ƒè®¤çŸ¥è¯„ä¼°å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ å…ƒè®¤çŸ¥å¤±è´¥ï¼š{e}")
    
    # ========== Agentç®¡ç† ==========
    
    def _get_observer_agent(self) -> ReactAgent:
        """è·å–è§‚å¯ŸAgentï¼ˆæ‡’åŠ è½½ï¼‰"""
        if 'observer' not in self._agents:
            knowledge_file = Path(__file__).parent.parent / "knowledge" / "memory" / "nlpl" / "observer_agent.nlpl"
            self._agents['observer'] = ReactAgent(
                work_dir=str(self.work_dir / ".memory" / "episodic"),
                knowledge_files=[str(knowledge_file)] if knowledge_file.exists() else [],
                max_rounds=10,
                window_size=30  # è§‚å¯ŸAgentä½¿ç”¨è¾ƒå°çš„çª—å£
            )
        return self._agents['observer']
    
    def _get_hippocampus_agent(self) -> ReactAgent:
        """è·å–æµ·é©¬ä½“Agentï¼ˆæ‡’åŠ è½½ï¼‰"""
        if 'hippocampus' not in self._agents:
            knowledge_file = Path(__file__).parent.parent / "knowledge" / "memory" / "nlpl" / "hippocampus_agent.nlpl"
            self._agents['hippocampus'] = ReactAgent(
                work_dir=str(self.work_dir / ".memory"),
                knowledge_files=[str(knowledge_file)] if knowledge_file.exists() else [],
                max_rounds=20,
                window_size=30  # æµ·é©¬ä½“ä½¿ç”¨è¾ƒå°çª—å£
            )
        return self._agents['hippocampus']
    
    def _get_metacognition_agent(self) -> ReactAgent:
        """è·å–å…ƒè®¤çŸ¥Agentï¼ˆæ‡’åŠ è½½ï¼‰"""
        if 'metacognition' not in self._agents:
            knowledge_file = Path(__file__).parent.parent / "knowledge" / "memory" / "nlpl" / "metacognition_agent.nlpl"
            self._agents['metacognition'] = ReactAgent(
                work_dir=str(self.work_dir / ".memory" / "metacognitive"),
                knowledge_files=[str(knowledge_file)] if knowledge_file.exists() else [],
                max_rounds=15,
                window_size=20  # å…ƒè®¤çŸ¥ä½¿ç”¨æ›´å°çª—å£
            )
        return self._agents['metacognition']
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _extract_event_from_messages(self, task_name: str, success: bool,
                                    rounds: int, messages: List[Message]) -> MemoryEvent:
        """ä»æ¶ˆæ¯å†å²æå–äº‹ä»¶ç‰¹å¾"""
        
        # åˆ†ææ¶ˆæ¯è·å–æ¨¡å¼
        patterns = self._identify_patterns(messages)
        emotions = self._assess_emotions(messages)
        load = self._assess_cognitive_load(messages)
        innovations = self._find_innovations(messages)
        errors = self._find_errors(messages)
        
        return MemoryEvent(
            timestamp=datetime.now().isoformat(),
            task_name=task_name,
            task_type=self._classify_task(task_name),
            execution_rounds=rounds,
            success=success,
            key_patterns=patterns,
            emotional_markers=emotions,
            cognitive_load=load,
            innovations=innovations,
            errors=errors
        )
    
    def _prepare_observation_task(self, messages: List[Message]) -> str:
        """å‡†å¤‡è§‚å¯Ÿä»»åŠ¡æè¿°"""
        # å°†æ¶ˆæ¯è½¬æ¢ä¸ºNLPLæ ¼å¼çš„æ‰§è¡Œè½¨è¿¹
        trace = "# æ‰§è¡Œè½¨è¿¹\n\n"
        for i, msg in enumerate(messages, 1):
            trace += f"## æ¶ˆæ¯{i} ({msg.role})\n"
            trace += f"æ—¶é—´ï¼š{msg.timestamp}\n"
            trace += f"å†…å®¹ï¼š{msg.content[:200]}...\n\n"
            
        return f"""
åˆ†æä»¥ä¸‹æ‰§è¡Œè½¨è¿¹ï¼Œè¯†åˆ«æ‰§è¡Œæ¨¡å¼å’Œå…³é”®ç‰¹å¾ï¼š

{trace}

è¯·ç”Ÿæˆè§‚å¯ŸæŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æ‰§è¡Œæ¨¡å¼è¯†åˆ«
2. å…³é”®å†³ç­–ç‚¹
3. è®¤çŸ¥è´Ÿè·è¯„ä¼°
4. æ”¹è¿›å»ºè®®
"""
    
    def _collect_system_stats(self) -> Dict[str, Any]:
        """æ”¶é›†ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            "message_stats": self.message_manager.get_stats(),
            "message_summary": self.message_manager.get_message_summary(),
            "episode_count": self.episode_count,
            "total_rounds": self.total_rounds,
            "memory_files": self._count_memory_files(),
            "recent_patterns": self._get_recent_patterns()
        }
    
    def _identify_patterns(self, messages: List[Message]) -> List[str]:
        """è¯†åˆ«æ‰§è¡Œæ¨¡å¼"""
        patterns = []
        
        # ç»Ÿè®¡å·¥å…·ä½¿ç”¨
        tool_count = sum(1 for m in messages if m.role == "tool")
        if tool_count > len(messages) * 0.3:
            patterns.append("å·¥å…·å¯†é›†å‹")
            
        # æ£€æŸ¥é”™è¯¯æ¢å¤
        error_recovery = any("é”™è¯¯" in m.content or "å¤±è´¥" in m.content 
                            for m in messages)
        if error_recovery:
            patterns.append("é”™è¯¯æ¢å¤")
            
        # æ£€æŸ¥è¿­ä»£æ¨¡å¼
        if len(messages) > 15:
            patterns.append("è¿­ä»£ä¼˜åŒ–")
        else:
            patterns.append("å¿«é€Ÿæ‰§è¡Œ")
            
        return patterns
    
    def _assess_emotions(self, messages: List[Message]) -> Dict[str, float]:
        """è¯„ä¼°æƒ…ç»ªæ ‡è®°"""
        emotions = {}
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        positive_words = ["æˆåŠŸ", "å®Œæˆ", "å¾ˆå¥½", "å®Œç¾"]
        negative_words = ["å¤±è´¥", "é”™è¯¯", "é—®é¢˜", "æ— æ³•"]
        
        positive_count = 0
        negative_count = 0
        
        for msg in messages:
            content_lower = msg.content.lower()
            positive_count += sum(1 for word in positive_words if word in content_lower)
            negative_count += sum(1 for word in negative_words if word in content_lower)
        
        total = max(1, positive_count + negative_count)
        if positive_count > negative_count:
            emotions["æ»¡æ„"] = positive_count / total
        else:
            emotions["æŒ«æŠ˜"] = negative_count / total
            
        return emotions
    
    def _assess_cognitive_load(self, messages: List[Message]) -> float:
        """è¯„ä¼°è®¤çŸ¥è´Ÿè·"""
        # åŸºäºæ¶ˆæ¯é•¿åº¦å’Œæ•°é‡çš„ç®€å•ä¼°ç®—
        avg_length = sum(len(m.content) for m in messages) / max(1, len(messages))
        
        if avg_length > 500 or len(messages) > 20:
            return 0.8  # é«˜è´Ÿè·
        elif avg_length > 200 or len(messages) > 10:
            return 0.5  # ä¸­è´Ÿè·
        else:
            return 0.3  # ä½è´Ÿè·
    
    def _find_innovations(self, messages: List[Message]) -> List[str]:
        """å‘ç°åˆ›æ–°ç‚¹"""
        innovations = []
        
        innovation_markers = ["æ–°æ–¹æ³•", "åˆ›æ–°", "å‘ç°", "åŸæ¥", "æƒ³åˆ°"]
        for msg in messages:
            if msg.role == "assistant":
                for marker in innovation_markers:
                    if marker in msg.content:
                        # æå–åŒ…å«åˆ›æ–°æ ‡è®°çš„å¥å­
                        sentences = msg.content.split("ã€‚")
                        for sent in sentences:
                            if marker in sent:
                                innovations.append(sent.strip())
                                break
                                
        return innovations[:3]  # æœ€å¤š3ä¸ª
    
    def _find_errors(self, messages: List[Message]) -> List[str]:
        """å‘ç°é”™è¯¯"""
        errors = []
        
        error_markers = ["é”™è¯¯", "å¤±è´¥", "å¼‚å¸¸", "æ— æ³•", "Error", "Failed"]
        for msg in messages:
            for marker in error_markers:
                if marker in msg.content:
                    # æå–é”™è¯¯æè¿°
                    lines = msg.content.split("\n")
                    for line in lines:
                        if marker in line:
                            errors.append(line.strip()[:100])
                            break
                            
        return errors[:3]  # æœ€å¤š3ä¸ª
    
    def _classify_task(self, task_name: str) -> str:
        """åˆ†ç±»ä»»åŠ¡ç±»å‹"""
        task_lower = task_name.lower()
        
        if any(word in task_lower for word in ["åˆ›å»º", "æ–°å»º", "ç”Ÿæˆ"]):
            return "åˆ›å»ºä»»åŠ¡"
        elif any(word in task_lower for word in ["ä¿®æ”¹", "æ›´æ–°", "ç¼–è¾‘"]):
            return "ä¿®æ”¹ä»»åŠ¡"
        elif any(word in task_lower for word in ["åˆ†æ", "æ£€æŸ¥", "è¯„ä¼°"]):
            return "åˆ†æä»»åŠ¡"
        elif any(word in task_lower for word in ["æµ‹è¯•", "éªŒè¯", "è°ƒè¯•"]):
            return "æµ‹è¯•ä»»åŠ¡"
        else:
            return "é€šç”¨ä»»åŠ¡"
    
    def _count_memory_files(self) -> Dict[str, int]:
        """ç»Ÿè®¡è®°å¿†æ–‡ä»¶æ•°é‡"""
        counts = {}
        memory_dir = self.work_dir / ".memory"
        
        if memory_dir.exists():
            counts["episodic"] = len(list((memory_dir / "episodic").glob("**/*.nlpl")))
            counts["semantic"] = len(list((memory_dir / "semantic").glob("**/*.nlpl")))
            counts["procedural"] = len(list((memory_dir / "procedural").glob("**/*.nlpl")))
            
        return counts
    
    def _get_recent_patterns(self) -> List[str]:
        """è·å–æœ€è¿‘ä½¿ç”¨çš„æ¨¡å¼"""
        # ä»è¯­ä¹‰è®°å¿†ä¸­è¯»å–æœ€è¿‘çš„æ¨¡å¼
        patterns = []
        patterns_dir = self.work_dir / ".memory" / "semantic" / "patterns"
        
        if patterns_dir.exists():
            pattern_files = sorted(patterns_dir.glob("*.nlpl"), 
                                 key=lambda p: p.stat().st_mtime, 
                                 reverse=True)
            for pf in pattern_files[:3]:
                patterns.append(pf.stem)
                
        return patterns
    
    # ========== å…¬å…±æ¥å£ ==========
    
    def get_context(self) -> List[Dict[str, Any]]:
        """è·å–LLMä¸Šä¸‹æ–‡"""
        return self.message_manager.get_context()
    
    def search_memory(self, query: str, limit: int = 10) -> List[str]:
        """æœç´¢è®°å¿†"""
        return self.memory_system.search_memories(query, limit=limit)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆç»Ÿè®¡"""
        return {
            "message_manager": self.message_manager.get_stats(),
            "cognitive_counters": {
                "total_rounds": self.total_rounds,
                "message_count": self.message_count,
                "episode_count": self.episode_count
            },
            "memory_files": self._count_memory_files()
        }
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.message_manager.clear()
        # NLPLMemorySystemçš„æ–‡ä»¶ä¿ç•™ï¼Œä¸æ¸…ç†


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºé›†æˆå±‚
    cognitive_memory = CognitiveMemoryIntegration(
        work_dir="test_memory",
        window_size=30
    )
    
    # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
    cognitive_memory.add_message("user", "åˆ›å»ºä¸€ä¸ªè®¡ç®—å™¨æ¨¡å—")
    cognitive_memory.add_message("assistant", "å¼€å§‹åˆ›å»ºè®¡ç®—å™¨æ¨¡å—...")
    cognitive_memory.add_message("tool", "æ–‡ä»¶ calculator.py åˆ›å»ºæˆåŠŸ")
    cognitive_memory.add_message("assistant", "è®¡ç®—å™¨æ¨¡å—åˆ›å»ºå®Œæˆ")
    
    # å¤„ç†ä»»åŠ¡å®Œæˆ
    paths = cognitive_memory.process_task_completion(
        task_name="åˆ›å»ºè®¡ç®—å™¨æ¨¡å—",
        success=True,
        rounds=4
    )
    
    print(f"ç”Ÿæˆçš„è®°å¿†æ–‡ä»¶ï¼š")
    for path in paths:
        print(f"  - {path}")
    
    # è·å–ç»Ÿè®¡
    stats = cognitive_memory.get_stats()
    print(f"\nç³»ç»Ÿç»Ÿè®¡ï¼š{json.dumps(stats, indent=2, ensure_ascii=False)}")