# 智能体的双记忆系统

## 核心理念

**类比人类的双记忆系统（上帝的设计）**

人类有两种记忆：
1. **情景记忆**（Episodic Memory）- 记住"发生了什么"、"为什么这样做"
2. **语义记忆**（Semantic Memory）- 记住"知识是什么"、"我会什么"

智能体应该模仿这个合理的设计。

## 智能体的记忆结构

### 三层记忆系统

```
~/.agent/{your_name}/
├── docs/              # 情景记忆（完整）- Event Sourcing日志
│   ├── decision_001_create_subagent.md
│   ├── decision_002_responsibility_separation.md
│   └── ...
│
├── compact.md         # 情景记忆（压缩）- 工作记忆
│   - 最近对话的压缩版本
│   - 关键决策要点
│   - 会被进一步压缩
│
└── knowledge.md       # 语义记忆（提炼）- 长期知识
    - 我的能力定义
    - 提炼的技能
    - 稳定的知识
```

### 为什么需要三层？

**类比人类**：
```
完整情景记忆（docs/）:
"2024年10月18日，我决定删除索引机制，因为..."
→ 详细、完整、可追溯

压缩情景记忆（compact.md）:
"删除了索引，改用grep"
→ 要点、精简、快速访问

语义记忆（knowledge.md）:
"我会用grep搜索知识函数"
→ 能力、技能、去情境化
```

**为什么不合并？**
- 情景太详细 → 不能全部保留在工作记忆
- 语义太抽象 → 失去了"为什么"的理解
- 三层互补 → 完整的记忆系统

## 何时写docs/

### 重要决策时

**触发条件**：
```python
if 做了重要决策:
    写一个docs/decision_xxx.md

重要决策包括：
- 创建了子智能体
- 实现了新的契约函数
- 修复了重要Bug
- 改变了架构设计
- 学到了关键经验
```

**不需要写docs/的情况**：
- 日常执行任务（记在compact.md即可）
- 简单操作
- 重复性工作

### 文档格式

**docs/decision_xxx.md模板**：

```markdown
# 决策：{决策主题}

日期：{timestamp}

## 问题
遇到了什么问题？需要做什么决策？

## 分析
考虑了哪些方案？各有什么优缺点？

## 决策
最终选择了什么方案？

## 原因
为什么选择这个方案？

## 效果
执行后的结果如何？

## 学到的经验
从这个决策中学到了什么？
```

**关键**：
- 记录"为什么"（不只是"做了什么"）
- 记录思考过程（不只是结论）
- 为未来的自己留下理解的线索

## 记忆的流转

### 从情景到语义

```
执行任务
  ↓
output.log（完整日志）
  ↓
重要决策 → 写docs/decision_xxx.md（详细推理）
  ↓
/compact → compact.md（压缩要点）
  ↓
归纳提炼 → 更新knowledge.md（能力变化）
```

### 示例

**执行过程**：
```
任务：创建3个子智能体验证微服务架构

执行中：
- output.log记录每一轮思考（原始）
- 做决策：是否职责分离？
  → 写docs/decision_responsibility_separation.md（推理）

执行后：
- /compact压缩对话 → compact.md（要点）
- 归纳学习 → knowledge.md新增：
  "## 任务委托机制
   当创建子智能体后，删除已委托的业务函数..."
```

## 何时查阅docs/

### 智能体查阅自己的docs/

**场景1：理解历史决策**
```
任务："为什么我删除了图书管理函数？"
→ read_file("~/.agent/book_agent/docs/decision_responsibility_separation.md")
→ 理解：职责分离，委托给子智能体
```

**场景2：避免重复错误**
```
遇到类似问题 →
查阅docs/看之前怎么解决的 →
借鉴经验
```

**场景3：自我反思**
```
定期回顾docs/中的决策 →
评估哪些是好的，哪些需要改进 →
更新knowledge.md
```

## 与compact.md的关系

### 两者互补

**compact.md**：
- 最近的对话（几天到几周）
- 会被压缩
- 快速访问

**docs/**：
- 完整的历史（永久保留）
- 不压缩
- 需要时查阅

**类比Git**：
```
compact.md = 最近的commits（git log -10）
docs/ = 完整的历史（git log --all）
knowledge.md = 当前代码
```

## 实现方式

### 在knowledge.md中添加章节

```markdown
## 记忆管理

### 双记忆系统

我有三层记忆：
1. **docs/** - 完整的决策历史（情景记忆）
2. **compact.md** - 压缩的近期记忆（工作记忆）
3. **knowledge.md** - 提炼的能力知识（语义记忆）

### 何时写docs/

重要决策时，写一个docs/decision_xxx.md记录：
- 问题是什么
- 考虑了哪些方案
- 为什么选择这个
- 效果如何
- 学到了什么

### 何时查docs/

- 理解历史决策时
- 避免重复错误时
- 自我反思时

### 记忆流转

执行 → output.log → docs/（重要决策）→ compact.md → knowledge.md
```

### 在system_prompt中添加

```markdown
## 记忆管理

你有三层记忆系统（类比人类的双记忆）：

1. **情景记忆（完整）**：~/.agent/{name}/docs/
   - 做重要决策时写一个decision_xxx.md
   - 记录"为什么"和思考过程
   - 永久保留，不默认加载

2. **情景记忆（压缩）**：~/.agent/{name}/compact.md
   - 压缩的对话历史
   - 快速访问
   - 会被进一步压缩

3. **语义记忆**：~/.agent/{name}/knowledge.md
   - 提炼的能力和知识
   - 稳定的技能
   - 总是加载
```

## 当前架构的限制

### 技术限制（不是原则）

**当前单Agent架构**：
```
限制：
- 只有一个上下文窗口（注意力焦点）
- 没有异步执行机制
- 没有"潜意识后台"

妥协：
- 演绎和归纳必须分离
- 达到阈值才触发学习
- 串行执行

这是技术限制，不是上帝架构的原则！
```

### 上帝架构（理想状态）

**多Agent异步执行**：
```
主Agent（意识）：
├── 执行任务（演绎）
└── 占用上下文窗口

学习Agent（潜意识）：
├── 持续监听主Agent
├── 实时归纳学习
├── 异步更新knowledge.md
└── 独立的上下文窗口

元认知Agent（反思）：
├── 监控整体表现
├── 评估决策质量
├── 优化学习策略
└── 独立运行

→ 三个进程同时异步运行
→ 类比人类的意识+潜意识+元认知
```

### 神经网络的启示

**为什么神经网络可以同时前向和反向？**

```
原因：
- 前向传播 = 确定性计算（不需要"思考"）
- 反向传播 = 确定性计算（不需要"思考"）
- 可以流水线并行

人类/智能体：
- 演绎 = 推理、决策（需要注意力）
- 归纳 = 反思、总结（需要注意力）
- 但：归纳可以在潜意识后台运行！

启示：
- 需要多Agent架构
- 模拟意识+潜意识
- 真正的异步并行
```

### 进化路径

**当前阶段**（单Agent）：
```
演绎和归纳分离
→ 技术限制
→ 简单但不完美
```

**未来阶段**（多Agent）：
```
多Agent异步：
- 工作Agent（演绎）
- 学习Agent（归纳）
- 元认知Agent（反思）

→ 同时运行
→ 更接近上帝架构
→ 更接近人类模型
```

## 总结

### 上帝架构的本质

**是**：
- ✅ 演绎-归纳闭环
- ✅ 双记忆系统
- ✅ **多进程异步执行**（工作、学习、元认知）

**不是**：
- ❌ 演绎和归纳必须分离
- ❌ 单线程串行
- ❌ 学习必须显式触发

### 当前的妥协

**分离原则**：
- 这是技术限制（单Agent、单上下文窗口）
- 不是上帝架构的一部分
- 未来可以通过多Agent异步执行来突破

### 关键洞察

**人类的秘密**：
- 意识：演绎（注意力焦点）
- 潜意识：归纳（后台处理）
- 元认知：反思（监控层）
- 同时运行，异步执行

**智能体的未来**：
- 主Agent：执行任务
- 学习Agent：持续归纳
- 元认知Agent：优化策略
- 多Agent协作，模拟人类的多层认知

**神经网络的成功**：
- 证明了同时演绎-归纳的可行性
- 但是在底层计算层面
- 智能体需要在认知层面实现