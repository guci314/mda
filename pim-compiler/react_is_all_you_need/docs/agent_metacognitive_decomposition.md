# Agentå…ƒè®¤çŸ¥ä»»åŠ¡åˆ†è§£æ¶æ„

## æ¦‚è¿°

å…ƒè®¤çŸ¥ä»»åŠ¡åˆ†è§£æ˜¯Agenté¢å¯¹å¤æ‚ä»»åŠ¡æ—¶çš„è‡ªé€‚åº”èƒ½åŠ›ã€‚å½“ä»»åŠ¡å¤æ‚åº¦è¶…è¿‡æ¨¡å‹èƒ½åŠ›è¾¹ç•Œæ—¶ï¼ˆå¦‚Kimiå¤±è´¥è€ŒGeminiæˆåŠŸçš„åœºæ™¯ï¼‰ï¼ŒAgentéœ€è¦å…·å¤‡ï¼š
1. **å…ƒè®¤çŸ¥èƒ½åŠ›**ï¼šæ£€æµ‹ä»»åŠ¡å¤±è´¥æˆ–å¤æ‚åº¦è¿‡é«˜
2. **åˆ†è§£èƒ½åŠ›**ï¼šå°†å¤æ‚ä»»åŠ¡æ‹†åˆ†ä¸ºå¯ç®¡ç†çš„å­ä»»åŠ¡
3. **é¢†åŸŸæ— å…³æ€§**ï¼šé€‚ç”¨äºä»»ä½•é¢†åŸŸçš„ä»»åŠ¡åˆ†è§£

## æ ¸å¿ƒé—®é¢˜

### æ¡ˆä¾‹ï¼šMDAç”Ÿæˆä»»åŠ¡å¤±è´¥åˆ†æ

```
ç°è±¡ï¼š
- Gemini 2.5 ProæˆåŠŸå®Œæˆ"ç”ŸæˆFastAPIç¨‹åº"
- Kimiå¤±è´¥åœ¨åŒä¸€ä»»åŠ¡ä¸Š
- åŸå› ï¼šå•æ­¥éª¤å¤æ‚åº¦è¶…è¿‡Kimiçš„å¤„ç†èƒ½åŠ›

äººç±»è§£å†³æ–¹æ¡ˆï¼š
- æ£€æµ‹åˆ°ä»»åŠ¡å¤ªå¤æ‚
- å°†ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°çš„æ­¥éª¤
- é€æ­¥å®Œæˆæ¯ä¸ªå­ä»»åŠ¡
```

## å…ƒè®¤çŸ¥æ£€æµ‹æœºåˆ¶

### 1. å¤±è´¥æ¨¡å¼è¯†åˆ«

```python
class MetacognitiveDetector:
    """å…ƒè®¤çŸ¥å¤±è´¥æ£€æµ‹å™¨"""
    
    def detect_failure_patterns(self, execution_trace):
        """æ£€æµ‹æ‰§è¡Œä¸­çš„å¤±è´¥æ¨¡å¼"""
        
        patterns = {
            "å¾ªç¯å¤±è´¥": self._check_repetitive_errors(execution_trace),
            "è¾“å‡ºæˆªæ–­": self._check_output_truncation(execution_trace),
            "ç†è§£åå·®": self._check_comprehension_drift(execution_trace),
            "èµ„æºè€—å°½": self._check_resource_exhaustion(execution_trace),
            "è¶…æ—¶": self._check_timeout(execution_trace),
            "ä¸å®Œæ•´è¾“å‡º": self._check_incomplete_output(execution_trace)
        }
        
        return patterns
    
    def _check_repetitive_errors(self, trace):
        """æ£€æµ‹é‡å¤é”™è¯¯"""
        error_counts = {}
        for event in trace:
            if event.type == "error":
                error_counts[event.message] = error_counts.get(event.message, 0) + 1
        
        # åŒä¸€é”™è¯¯å‡ºç°3æ¬¡ä»¥ä¸Š
        return any(count >= 3 for count in error_counts.values())
    
    def _check_output_truncation(self, trace):
        """æ£€æµ‹è¾“å‡ºè¢«æˆªæ–­"""
        for event in trace:
            if event.type == "output":
                if event.is_truncated or len(event.content) >= event.max_length * 0.95:
                    return True
        return False
    
    def _check_comprehension_drift(self, trace):
        """æ£€æµ‹ç†è§£åå·®"""
        # è¾“å‡ºä¸æœŸæœ›ä¸¥é‡ä¸ç¬¦
        for event in trace:
            if event.type == "validation":
                if event.similarity_score < 0.3:
                    return True
        return False
```

### 2. å¤æ‚åº¦è¯„ä¼°

```python
class ComplexityAnalyzer:
    """ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨"""
    
    def analyze_task_complexity(self, task_description):
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        
        metrics = {
            "æ­¥éª¤æ•°é‡": self._count_steps(task_description),
            "ä¾èµ–æ·±åº¦": self._analyze_dependencies(task_description),
            "é¢†åŸŸçŸ¥è¯†è¦æ±‚": self._assess_domain_knowledge(task_description),
            "è¾“å‡ºè§„æ¨¡": self._estimate_output_size(task_description),
            "è®¤çŸ¥è´Ÿè½½": self._calculate_cognitive_load(task_description)
        }
        
        # ç»¼åˆè¯„åˆ† (0-1)
        complexity_score = self._calculate_overall_complexity(metrics)
        
        return {
            "score": complexity_score,
            "metrics": metrics,
            "decomposition_needed": complexity_score > 0.7
        }
    
    def _calculate_cognitive_load(self, task):
        """è®¡ç®—è®¤çŸ¥è´Ÿè½½"""
        factors = {
            "æ¦‚å¿µæ•°é‡": len(self._extract_concepts(task)),
            "æŠ½è±¡å±‚æ¬¡": self._measure_abstraction_level(task),
            "ä¸Šä¸‹æ–‡åˆ‡æ¢": self._count_context_switches(task),
            "è®°å¿†éœ€æ±‚": self._estimate_memory_requirement(task)
        }
        
        # åŠ æƒè®¡ç®—
        load = (
            factors["æ¦‚å¿µæ•°é‡"] * 0.3 +
            factors["æŠ½è±¡å±‚æ¬¡"] * 0.3 +
            factors["ä¸Šä¸‹æ–‡åˆ‡æ¢"] * 0.2 +
            factors["è®°å¿†éœ€æ±‚"] * 0.2
        )
        
        return min(load / 100, 1.0)
```

## é¢†åŸŸæ— å…³çš„ä»»åŠ¡åˆ†è§£ç­–ç•¥

### 1. é€šç”¨åˆ†è§£æ¨¡å¼

```python
class UniversalDecomposer:
    """é€šç”¨ä»»åŠ¡åˆ†è§£å™¨"""
    
    def decompose(self, task, model_capability):
        """æ ¹æ®æ¨¡å‹èƒ½åŠ›åˆ†è§£ä»»åŠ¡"""
        
        # é€‰æ‹©åˆ†è§£ç­–ç•¥
        strategy = self._select_strategy(task, model_capability)
        
        # åº”ç”¨åˆ†è§£
        subtasks = strategy.decompose(task)
        
        # éªŒè¯å­ä»»åŠ¡å¤æ‚åº¦
        for subtask in subtasks:
            if self._is_still_complex(subtask, model_capability):
                # é€’å½’åˆ†è§£
                subtask.children = self.decompose(subtask, model_capability)
        
        return subtasks
    
    def _select_strategy(self, task, capability):
        """é€‰æ‹©åˆ†è§£ç­–ç•¥"""
        
        strategies = [
            TemporalDecomposition(),      # æ—¶åºåˆ†è§£
            FunctionalDecomposition(),     # åŠŸèƒ½åˆ†è§£
            DataFlowDecomposition(),       # æ•°æ®æµåˆ†è§£
            HierarchicalDecomposition(),   # å±‚æ¬¡åˆ†è§£
            IterativeRefinement()          # è¿­ä»£ç»†åŒ–
        ]
        
        # è¯„åˆ†é€‰æ‹©æœ€ä½³ç­–ç•¥
        best_strategy = max(
            strategies,
            key=lambda s: s.fitness_score(task, capability)
        )
        
        return best_strategy
```

### 2. æ—¶åºåˆ†è§£ç­–ç•¥

```python
class TemporalDecomposition:
    """æŒ‰æ—¶é—´é¡ºåºåˆ†è§£ä»»åŠ¡"""
    
    def decompose(self, task):
        steps = []
        
        # è¯†åˆ«æ—¶åºæ ‡è®°
        temporal_markers = [
            "é¦–å…ˆ", "ç„¶å", "æ¥ä¸‹æ¥", "æœ€å",
            "ç¬¬ä¸€æ­¥", "ç¬¬äºŒæ­¥", "æ­¥éª¤1", "æ­¥éª¤2",
            "before", "after", "then", "finally"
        ]
        
        # æå–æ—¶åºæ­¥éª¤
        segments = self._split_by_markers(task.description, temporal_markers)
        
        for i, segment in enumerate(segments):
            steps.append({
                "id": f"step_{i+1}",
                "description": segment,
                "dependencies": [f"step_{i}"] if i > 0 else [],
                "type": "sequential"
            })
        
        return steps
```

### 3. åŠŸèƒ½åˆ†è§£ç­–ç•¥

```python
class FunctionalDecomposition:
    """æŒ‰åŠŸèƒ½æ¨¡å—åˆ†è§£ä»»åŠ¡"""
    
    def decompose(self, task):
        modules = []
        
        # è¯†åˆ«åŠŸèƒ½åŠ¨è¯
        functional_verbs = [
            "åˆ›å»º", "ç”Ÿæˆ", "éªŒè¯", "æµ‹è¯•", "éƒ¨ç½²",
            "åˆ†æ", "è®¾è®¡", "å®ç°", "ä¼˜åŒ–", "é…ç½®",
            "create", "generate", "validate", "test", "deploy"
        ]
        
        # æå–åŠŸèƒ½æ¨¡å—
        functions = self._extract_functions(task.description, functional_verbs)
        
        for func in functions:
            modules.append({
                "id": f"func_{func.name}",
                "function": func.name,
                "inputs": func.inputs,
                "outputs": func.outputs,
                "description": func.description,
                "type": "functional"
            })
        
        return modules
```

### 4. é€’å½’åˆ†è§£ç­–ç•¥

```python
class RecursiveDecomposition:
    """é€’å½’åˆ†è§£ç›´åˆ°è¾¾åˆ°å¯å¤„ç†ç²’åº¦"""
    
    def decompose(self, task, max_depth=5):
        if max_depth == 0:
            return [task]
        
        # è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦
        complexity = self._assess_complexity(task)
        
        if complexity <= self.threshold:
            return [task]
        
        # åˆ†è§£ä¸ºå­ä»»åŠ¡
        subtasks = self._split_task(task)
        
        result = []
        for subtask in subtasks:
            # é€’å½’åˆ†è§£æ¯ä¸ªå­ä»»åŠ¡
            decomposed = self.decompose(subtask, max_depth - 1)
            result.extend(decomposed)
        
        return result
    
    def _split_task(self, task):
        """å°†ä»»åŠ¡åˆ†å‰²ä¸º2-4ä¸ªå­ä»»åŠ¡"""
        
        # å°è¯•ä¸åŒçš„åˆ†å‰²æ–¹æ³•
        split_methods = [
            self._split_by_conjunctions,    # æŒ‰è¿è¯åˆ†å‰²
            self._split_by_sentences,        # æŒ‰å¥å­åˆ†å‰²
            self._split_by_paragraphs,       # æŒ‰æ®µè½åˆ†å‰²
            self._split_by_concepts          # æŒ‰æ¦‚å¿µåˆ†å‰²
        ]
        
        for method in split_methods:
            subtasks = method(task)
            if 2 <= len(subtasks) <= 4:
                return subtasks
        
        # å¼ºåˆ¶äºŒåˆ†
        return self._binary_split(task)
```

## è‡ªé€‚åº”åˆ†è§£æ¡†æ¶

### 1. æ¨¡å‹èƒ½åŠ›æ„ŸçŸ¥

```python
class ModelCapabilityProfile:
    """æ¨¡å‹èƒ½åŠ›ç”»åƒ"""
    
    def __init__(self, model_name):
        self.model_name = model_name
        self.capabilities = self._load_profile(model_name)
    
    def _load_profile(self, model_name):
        """åŠ è½½æ¨¡å‹èƒ½åŠ›é…ç½®"""
        
        profiles = {
            "gemini-2.5-pro": {
                "max_tokens": 32000,
                "complexity_threshold": 0.9,
                "parallel_capacity": 10,
                "domain_expertise": ["code", "analysis", "reasoning"],
                "strengths": ["complex_generation", "multi_step_reasoning"],
                "weaknesses": []
            },
            "kimi-k2-turbo": {
                "max_tokens": 128000,
                "complexity_threshold": 0.6,
                "parallel_capacity": 5,
                "domain_expertise": ["general", "search"],
                "strengths": ["long_context", "information_retrieval"],
                "weaknesses": ["complex_generation", "deep_reasoning"]
            },
            "gpt-4": {
                "max_tokens": 8000,
                "complexity_threshold": 0.8,
                "parallel_capacity": 8,
                "domain_expertise": ["general", "code", "creative"],
                "strengths": ["reasoning", "creativity"],
                "weaknesses": ["long_output"]
            }
        }
        
        return profiles.get(model_name, self._default_profile())
    
    def can_handle(self, task_complexity):
        """åˆ¤æ–­æ¨¡å‹æ˜¯å¦èƒ½å¤„ç†ä»»åŠ¡"""
        return task_complexity.score <= self.capabilities["complexity_threshold"]
```

### 2. åŠ¨æ€åˆ†è§£è°ƒæ•´

```python
class AdaptiveDecomposer:
    """è‡ªé€‚åº”ä»»åŠ¡åˆ†è§£å™¨"""
    
    def __init__(self, model_profile):
        self.model = model_profile
        self.decomposition_history = []
    
    def decompose_with_feedback(self, task):
        """å¸¦åé¦ˆçš„åˆ†è§£"""
        
        # åˆå§‹åˆ†è§£
        subtasks = self._initial_decomposition(task)
        
        # æµ‹è¯•æ‰§è¡Œ
        for subtask in subtasks[:1]:  # æµ‹è¯•ç¬¬ä¸€ä¸ªå­ä»»åŠ¡
            success, feedback = self._test_execution(subtask)
            
            if not success:
                # æ ¹æ®åé¦ˆè°ƒæ•´åˆ†è§£ç²’åº¦
                subtasks = self._refine_decomposition(
                    task, 
                    subtasks, 
                    feedback
                )
        
        return subtasks
    
    def _refine_decomposition(self, task, current_subtasks, feedback):
        """æ ¹æ®åé¦ˆç»†åŒ–åˆ†è§£"""
        
        if "too_complex" in feedback:
            # è¿›ä¸€æ­¥ç»†åˆ†
            refined = []
            for subtask in current_subtasks:
                refined.extend(self._split_further(subtask))
            return refined
        
        elif "missing_context" in feedback:
            # å¢åŠ ä¸Šä¸‹æ–‡
            return self._add_context(current_subtasks)
        
        elif "wrong_order" in feedback:
            # è°ƒæ•´é¡ºåº
            return self._reorder_subtasks(current_subtasks)
        
        return current_subtasks
```

## æ‰§è¡Œä¸ç›‘æ§

### 1. æ£€æŸ¥ç‚¹æœºåˆ¶

```python
class CheckpointExecutor:
    """å¸¦æ£€æŸ¥ç‚¹çš„æ‰§è¡Œå™¨"""
    
    def execute_with_checkpoints(self, subtasks):
        """æ‰§è¡Œå¹¶ä¿å­˜æ£€æŸ¥ç‚¹"""
        
        completed = []
        checkpoint_file = "execution_checkpoint.json"
        
        # æ¢å¤ä¹‹å‰çš„è¿›åº¦
        if os.path.exists(checkpoint_file):
            completed = self._load_checkpoint(checkpoint_file)
        
        for i, subtask in enumerate(subtasks):
            if subtask.id in completed:
                continue  # è·³è¿‡å·²å®Œæˆçš„
            
            try:
                # æ‰§è¡Œå­ä»»åŠ¡
                result = self._execute_subtask(subtask)
                
                # éªŒè¯ç»“æœ
                if self._validate_result(result, subtask):
                    completed.append(subtask.id)
                    self._save_checkpoint(checkpoint_file, completed)
                else:
                    # å¤±è´¥å¤„ç†
                    self._handle_failure(subtask, result)
                    
            except Exception as e:
                # å¼‚å¸¸å¤„ç†
                self._handle_exception(subtask, e)
                break
        
        return completed
```

### 2. è¿›åº¦è¿½è¸ª

```python
class ProgressTracker:
    """è¿›åº¦è¿½è¸ªå™¨"""
    
    def __init__(self, total_subtasks):
        self.total = total_subtasks
        self.completed = 0
        self.failed = 0
        self.in_progress = None
        self.start_time = time.time()
    
    def update(self, subtask_id, status):
        """æ›´æ–°è¿›åº¦"""
        
        if status == "completed":
            self.completed += 1
        elif status == "failed":
            self.failed += 1
        elif status == "in_progress":
            self.in_progress = subtask_id
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.progress_percentage = (self.completed / self.total) * 100
        self.success_rate = self.completed / (self.completed + self.failed) if (self.completed + self.failed) > 0 else 0
        self.estimated_completion = self._estimate_completion()
        
        # ç”ŸæˆæŠ¥å‘Š
        return self._generate_report()
    
    def _generate_report(self):
        """ç”Ÿæˆè¿›åº¦æŠ¥å‘Š"""
        return {
            "æ€»ä»»åŠ¡æ•°": self.total,
            "å·²å®Œæˆ": self.completed,
            "å¤±è´¥": self.failed,
            "è¿›åº¦": f"{self.progress_percentage:.1f}%",
            "æˆåŠŸç‡": f"{self.success_rate:.1%}",
            "å½“å‰ä»»åŠ¡": self.in_progress,
            "é¢„è®¡å®Œæˆæ—¶é—´": self.estimated_completion
        }
```

## å®ç°ç¤ºä¾‹

### 1. å®Œæ•´çš„å…ƒè®¤çŸ¥Agent

```python
class MetacognitiveAgent(GenericReactAgent):
    """å…·æœ‰å…ƒè®¤çŸ¥èƒ½åŠ›çš„Agent"""
    
    def __init__(self, config, **kwargs):
        super().__init__(config, **kwargs)
        
        # åˆå§‹åŒ–å…ƒè®¤çŸ¥ç»„ä»¶
        self.detector = MetacognitiveDetector()
        self.analyzer = ComplexityAnalyzer()
        self.decomposer = UniversalDecomposer()
        self.executor = CheckpointExecutor()
        
        # æ¨¡å‹èƒ½åŠ›ç”»åƒ
        self.model_profile = ModelCapabilityProfile(config.llm_model)
    
    def execute_task(self, task_description):
        """æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦å…ƒè®¤çŸ¥ï¼‰"""
        
        # 1. å¤æ‚åº¦åˆ†æ
        complexity = self.analyzer.analyze_task_complexity(task_description)
        
        if not complexity["decomposition_needed"]:
            # ç›´æ¥æ‰§è¡Œ
            return super().execute_task(task_description)
        
        # 2. ä»»åŠ¡åˆ†è§£
        print(f"ğŸ§  ä»»åŠ¡å¤æ‚åº¦ {complexity['score']:.2f} è¶…è¿‡é˜ˆå€¼ï¼Œå¯åŠ¨åˆ†è§£...")
        
        subtasks = self.decomposer.decompose(
            task_description,
            self.model_profile
        )
        
        print(f"ğŸ“ åˆ†è§£ä¸º {len(subtasks)} ä¸ªå­ä»»åŠ¡")
        
        # 3. é€æ­¥æ‰§è¡Œ
        results = []
        tracker = ProgressTracker(len(subtasks))
        
        for subtask in subtasks:
            tracker.update(subtask.id, "in_progress")
            
            try:
                # æ‰§è¡Œå­ä»»åŠ¡
                result = super().execute_task(subtask.description)
                
                # æ£€æµ‹å¤±è´¥
                if self._detect_failure(result):
                    # è¿›ä¸€æ­¥åˆ†è§£
                    print(f"âš ï¸ å­ä»»åŠ¡ {subtask.id} å¤±è´¥ï¼Œè¿›ä¸€æ­¥åˆ†è§£...")
                    sub_subtasks = self.decomposer.decompose(
                        subtask,
                        self.model_profile
                    )
                    
                    # é€’å½’æ‰§è¡Œ
                    for sst in sub_subtasks:
                        sub_result = super().execute_task(sst.description)
                        results.append(sub_result)
                else:
                    results.append(result)
                    tracker.update(subtask.id, "completed")
                    
            except Exception as e:
                print(f"âŒ å­ä»»åŠ¡ {subtask.id} æ‰§è¡Œå¤±è´¥: {e}")
                tracker.update(subtask.id, "failed")
                
                # å†³å®šæ˜¯å¦ç»§ç»­
                if not self._should_continue_after_failure(e):
                    break
        
        # 4. åˆå¹¶ç»“æœ
        return self._merge_results(results)
    
    def _detect_failure(self, execution_result):
        """æ£€æµ‹æ‰§è¡Œæ˜¯å¦å¤±è´¥"""
        
        # å¤šç»´åº¦æ£€æµ‹
        checks = {
            "ç©ºç»“æœ": execution_result is None,
            "é”™è¯¯æ ‡è®°": "error" in str(execution_result).lower(),
            "ä¸å®Œæ•´": self._is_incomplete(execution_result),
            "è´¨é‡å·®": self._is_low_quality(execution_result)
        }
        
        return any(checks.values())
```

### 2. ä½¿ç”¨ç¤ºä¾‹

```python
# é…ç½®å…ƒè®¤çŸ¥Agent
config = ReactAgentConfig(
    work_dir=work_dir,
    memory_level=MemoryLevel.SMART,
    enable_metacognition=True,  # å¯ç”¨å…ƒè®¤çŸ¥
    decomposition_threshold=0.7,  # åˆ†è§£é˜ˆå€¼
    **llm_config
)

# åˆ›å»ºAgent
agent = MetacognitiveAgent(config, name="smart_agent")

# æ‰§è¡Œå¤æ‚ä»»åŠ¡
task = """
åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ç”µå•†ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
1. ç”¨æˆ·ç®¡ç†ç³»ç»Ÿï¼ˆæ³¨å†Œã€ç™»å½•ã€æƒé™ï¼‰
2. å•†å“ç®¡ç†ï¼ˆCRUDã€åˆ†ç±»ã€æœç´¢ï¼‰
3. è´­ç‰©è½¦åŠŸèƒ½
4. è®¢å•ç³»ç»Ÿ
5. æ”¯ä»˜é›†æˆ
6. ç‰©æµè·Ÿè¸ª
ç¡®ä¿æ‰€æœ‰åŠŸèƒ½éƒ½æœ‰å®Œæ•´çš„APIå’Œæµ‹è¯•
"""

# Agentä¼šè‡ªåŠ¨ï¼š
# 1. æ£€æµ‹åˆ°ä»»åŠ¡å¤æ‚
# 2. åˆ†è§£ä¸º6ä¸ªä¸»è¦æ¨¡å—
# 3. æ¯ä¸ªæ¨¡å—è¿›ä¸€æ­¥åˆ†è§£
# 4. é€æ­¥å®ç°æ¯ä¸ªå­åŠŸèƒ½
# 5. æ•´åˆæœ€ç»ˆç»“æœ

result = agent.execute_task(task)
```

## é›†æˆåˆ°React Agent

### 1. æ‰©å±•é…ç½®

```python
class ReactAgentConfig:
    """æ‰©å±•é…ç½®æ”¯æŒå…ƒè®¤çŸ¥"""
    
    # å…ƒè®¤çŸ¥é…ç½®
    enable_metacognition: bool = False
    decomposition_threshold: float = 0.7
    max_decomposition_depth: int = 3
    checkpoint_enabled: bool = True
    
    # å¤±è´¥æ£€æµ‹é…ç½®
    failure_detection: Dict = {
        "max_retries": 3,
        "timeout_seconds": 300,
        "quality_threshold": 0.6
    }
    
    # åˆ†è§£ç­–ç•¥é…ç½®
    decomposition_strategies: List[str] = [
        "temporal",
        "functional", 
        "recursive",
        "hierarchical"
    ]
```

### 2. çŸ¥è¯†æ–‡ä»¶

åˆ›å»º `knowledge/metacognition/decomposition_patterns.md`:

```markdown
# ä»»åŠ¡åˆ†è§£æ¨¡å¼

## æ—¶åºåˆ†è§£
é€‚ç”¨äºæœ‰æ˜ç¡®æ­¥éª¤é¡ºåºçš„ä»»åŠ¡
å…³é”®è¯ï¼šé¦–å…ˆã€ç„¶åã€æœ€åã€æ­¥éª¤

## åŠŸèƒ½åˆ†è§£
é€‚ç”¨äºå¯ä»¥æŒ‰åŠŸèƒ½æ¨¡å—åˆ’åˆ†çš„ä»»åŠ¡
å…³é”®è¯ï¼šæ¨¡å—ã€åŠŸèƒ½ã€ç»„ä»¶ã€ç³»ç»Ÿ

## æ•°æ®æµåˆ†è§£
é€‚ç”¨äºæ•°æ®å¤„ç†ä»»åŠ¡
å…³é”®è¯ï¼šè¾“å…¥ã€å¤„ç†ã€è¾“å‡ºã€è½¬æ¢

## é€’å½’åˆ†è§£
é€‚ç”¨äºå¯ä»¥é€’å½’ç»†åˆ†çš„ä»»åŠ¡
æ–¹æ³•ï¼šä¸æ–­ç»†åˆ†ç›´åˆ°åŸå­ä»»åŠ¡
```

## ä¼˜åŠ¿ä¸ä»·å€¼

### 1. çªç ´æ¨¡å‹èƒ½åŠ›è¾¹ç•Œ
- è®©å¼±æ¨¡å‹å®Œæˆå¼ºæ¨¡å‹çš„ä»»åŠ¡
- é€šè¿‡åˆ†è§£é™ä½å•æ­¥å¤æ‚åº¦
- å®ç°æ¸è¿›å¼é—®é¢˜è§£å†³

### 2. æé«˜æˆåŠŸç‡
- å¤±è´¥å¯ä»¥å±€éƒ¨é‡è¯•
- æ£€æŸ¥ç‚¹æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- é™ä½æ•´ä½“å¤±è´¥é£é™©

### 3. é¢†åŸŸæ— å…³æ€§
- ä¸ä¾èµ–ç‰¹å®šé¢†åŸŸçŸ¥è¯†
- é€šç”¨åˆ†è§£ç­–ç•¥
- å¯æ‰©å±•åˆ°ä»»ä½•ä»»åŠ¡ç±»å‹

### 4. å¯è§£é‡Šæ€§
- æ¸…æ™°çš„ä»»åŠ¡åˆ†è§£æ ‘
- æ¯æ­¥éƒ½å¯è¿½è¸ª
- ä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–

## æœ€ä½³å®è·µ

### 1. åˆ†è§£ç²’åº¦æ§åˆ¶
```python
# å¤ªç²—ï¼šä»ç„¶å¤æ‚
"ç”Ÿæˆå®Œæ•´çš„Webåº”ç”¨"

# å¤ªç»†ï¼šæ•ˆç‡ä½ä¸‹
"åˆ›å»ºä¸€ä¸ªå˜é‡"

# åˆé€‚ï¼šå¯ç‹¬ç«‹å®Œæˆ
"å®ç°ç”¨æˆ·æ³¨å†ŒAPIç«¯ç‚¹"
```

### 2. ä¾èµ–ç®¡ç†
```python
# æ˜ç¡®å­ä»»åŠ¡ä¾èµ–
subtasks = [
    {"id": "1", "task": "è®¾è®¡æ•°æ®æ¨¡å‹", "depends_on": []},
    {"id": "2", "task": "åˆ›å»ºæ•°æ®åº“è¡¨", "depends_on": ["1"]},
    {"id": "3", "task": "å®ç°API", "depends_on": ["2"]},
    {"id": "4", "task": "ç¼–å†™æµ‹è¯•", "depends_on": ["3"]}
]
```

### 3. å¤±è´¥æ¢å¤
```python
# æ™ºèƒ½é‡è¯•ç­–ç•¥
if failure_type == "timeout":
    # è¿›ä¸€æ­¥åˆ†è§£
    new_subtasks = decompose_further(failed_task)
elif failure_type == "error":
    # ä¿®å¤åé‡è¯•
    fixed_task = apply_fix(failed_task, error_info)
elif failure_type == "quality":
    # æ¢ç­–ç•¥é‡åš
    alternative_task = use_alternative_approach(failed_task)
```

## æœªæ¥æ‰©å±•

### 1. å­¦ä¹ ä¼˜åŒ–
- è®°å½•æˆåŠŸçš„åˆ†è§£æ¨¡å¼
- å­¦ä¹ æœ€ä¼˜åˆ†è§£ç²’åº¦
- ä¸ªæ€§åŒ–æ¨¡å‹èƒ½åŠ›ç”»åƒ

### 2. åä½œåˆ†è§£
- å¤šAgentåä½œåˆ†è§£
- ä¸“å®¶Agentæä¾›é¢†åŸŸåˆ†è§£å»ºè®®
- åˆ†å¸ƒå¼æ‰§è¡Œå­ä»»åŠ¡

### 3. æ™ºèƒ½è°ƒåº¦
- å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹å­ä»»åŠ¡
- åŠ¨æ€èµ„æºåˆ†é…
- ä¼˜å…ˆçº§è°ƒåº¦

## æ€»ç»“

å…ƒè®¤çŸ¥ä»»åŠ¡åˆ†è§£æ¶æ„é€šè¿‡ï¼š

1. **å…ƒè®¤çŸ¥æ£€æµ‹**ï¼šè¯†åˆ«ä»»åŠ¡å¤±è´¥å’Œå¤æ‚åº¦
2. **æ™ºèƒ½åˆ†è§£**ï¼šé¢†åŸŸæ— å…³çš„ä»»åŠ¡æ‹†åˆ†
3. **è‡ªé€‚åº”æ‰§è¡Œ**ï¼šæ ¹æ®èƒ½åŠ›è°ƒæ•´ç²’åº¦
4. **æ£€æŸ¥ç‚¹æœºåˆ¶**ï¼šæ”¯æŒæ–­ç‚¹ç»­ä¼ 
5. **è¿›åº¦è¿½è¸ª**ï¼šå®æ—¶ç›‘æ§æ‰§è¡ŒçŠ¶æ€

å®ç°äº†è®©Agentå…·å¤‡"**é‡åˆ°å›°éš¾å°±åˆ†è§£**"çš„äººç±»è®¤çŸ¥èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†å¤„ç†å¤æ‚ä»»åŠ¡çš„æˆåŠŸç‡ã€‚

è¿™ä¸ä»…æ˜¯æŠ€æœ¯å®ç°ï¼Œæ›´æ˜¯å‘é€šç”¨äººå·¥æ™ºèƒ½è¿ˆè¿›çš„é‡è¦ä¸€æ­¥â€”â€”è®©AIå­¦ä¼šå¦‚ä½•å­¦ä¹ å’Œè§£å†³é—®é¢˜ï¼Œè€Œä¸ä»…ä»…æ˜¯æ‰§è¡Œé¢„å®šä¹‰çš„ä»»åŠ¡ã€‚