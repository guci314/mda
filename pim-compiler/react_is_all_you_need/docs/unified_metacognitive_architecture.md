# ç»Ÿä¸€å…ƒè®¤çŸ¥æ¶æ„ï¼šå­¦ä¹ ã€å¤æ‚æ€§å¯¹æŠ—ä¸è‡ªæˆ‘æ„è¯†

## æ ¸å¿ƒæ´å¯Ÿ

å…ƒè®¤çŸ¥æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è®¤çŸ¥ç³»ç»Ÿï¼ŒåŒ…å«ä¸‰ä¸ªç›¸äº’ä¾èµ–çš„èƒ½åŠ›ï¼š
1. **è‡ªæˆ‘æ„è¯†**ï¼šçŸ¥é“è‡ªå·±çŸ¥é“ä»€ä¹ˆã€èƒ½åšä»€ä¹ˆ
2. **å¤æ‚æ€§å¯¹æŠ—**ï¼šé‡åˆ°è¶…å‡ºèƒ½åŠ›çš„ä»»åŠ¡æ—¶åˆ†è§£å¤„ç†
3. **æŒç»­å­¦ä¹ **ï¼šä»ç»éªŒä¸­æå–çŸ¥è¯†ï¼Œæ”¹è¿›æœªæ¥è¡¨ç°

è¿™ä¸‰è€…ä¸æ˜¯ç‹¬ç«‹çš„åŠŸèƒ½ï¼Œè€Œæ˜¯**åŒä¸€ä¸ªè®¤çŸ¥å¾ªç¯çš„ä¸åŒæ–¹é¢**ã€‚

## ç»Ÿä¸€è®¤çŸ¥å¾ªç¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚         ç»Ÿä¸€å…ƒè®¤çŸ¥ç³»ç»Ÿ                    â”‚
â”‚                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚      1. è‡ªæˆ‘è¯„ä¼°             â”‚      â”‚
â”‚   â”‚   - æˆ‘çŸ¥é“ä»€ä¹ˆï¼Ÿ             â”‚      â”‚
â”‚   â”‚   - æˆ‘èƒ½å¤„ç†è¿™ä¸ªä»»åŠ¡å—ï¼Ÿ      â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â†“                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚      2. ç­–ç•¥é€‰æ‹©             â”‚      â”‚
â”‚   â”‚   - ç›´æ¥æ‰§è¡Œï¼Ÿ               â”‚      â”‚
â”‚   â”‚   - éœ€è¦åˆ†è§£ï¼Ÿ               â”‚      â”‚
â”‚   â”‚   - è°ƒç”¨ä»€ä¹ˆçŸ¥è¯†ï¼Ÿ           â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â†“                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚      3. æ‰§è¡Œç›‘æ§             â”‚      â”‚
â”‚   â”‚   - è¿›å±•å¦‚ä½•ï¼Ÿ               â”‚      â”‚
â”‚   â”‚   - é‡åˆ°ä»€ä¹ˆé—®é¢˜ï¼Ÿ           â”‚      â”‚
â”‚   â”‚   - å­¦åˆ°ä»€ä¹ˆï¼Ÿ               â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â†“                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚      4. åæ€æ•´åˆ             â”‚      â”‚
â”‚   â”‚   - æˆåŠŸ/å¤±è´¥åŸå› ï¼Ÿ          â”‚      â”‚
â”‚   â”‚   - æ›´æ–°çŸ¥è¯†åº“               â”‚      â”‚
â”‚   â”‚   - è°ƒæ•´èƒ½åŠ›è¾¹ç•Œ             â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å®Œæ•´çš„ç»Ÿä¸€å®ç°

### 1. æ ¸å¿ƒå…ƒè®¤çŸ¥å¼•æ“

```python
class UnifiedMetacognitiveEngine:
    """ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å¼•æ“ï¼šæ•´åˆå­¦ä¹ ã€å¤æ‚æ€§å¯¹æŠ—å’Œè‡ªæˆ‘æ„è¯†"""
    
    def __init__(self, llm):
        self.llm = llm
        
        # ç»Ÿä¸€çš„è®¤çŸ¥çŠ¶æ€
        self.cognitive_state = {
            "knowledge_base": {},        # æˆ‘çŸ¥é“ä»€ä¹ˆ
            "capability_boundary": {},   # æˆ‘èƒ½åšä»€ä¹ˆ
            "experience_memory": [],     # æˆ‘çš„ç»å†
            "learning_insights": [],     # æˆ‘å­¦åˆ°çš„
            "failure_patterns": [],      # å¤±è´¥æ¨¡å¼
            "success_patterns": []       # æˆåŠŸæ¨¡å¼
        }
    
    def process_task(self, task):
        """ç»Ÿä¸€çš„ä»»åŠ¡å¤„ç†æµç¨‹"""
        
        # Step 1: å…ƒè®¤çŸ¥è¯„ä¼°
        assessment = self.metacognitive_assessment(task)
        
        # Step 2: åŸºäºè¯„ä¼°é€‰æ‹©ç­–ç•¥
        strategy = self.select_strategy(assessment)
        
        # Step 3: æ‰§è¡Œwithå®æ—¶å­¦ä¹ 
        execution = self.execute_with_learning(task, strategy)
        
        # Step 4: åæ€å’ŒçŸ¥è¯†æ›´æ–°
        self.reflect_and_update(task, execution)
        
        return execution.result
```

### 2. ç»Ÿä¸€çš„å…ƒè®¤çŸ¥è¯„ä¼°

```python
class MetacognitiveAssessment:
    """ç»Ÿä¸€è¯„ä¼°ï¼šçŸ¥è¯†ã€èƒ½åŠ›ã€å¤æ‚åº¦"""
    
    UNIFIED_ASSESSMENT_PROMPT = """
è¿›è¡Œå…¨é¢çš„å…ƒè®¤çŸ¥è¯„ä¼°ã€‚

## ä»»åŠ¡
{task}

## æˆ‘çš„è®¤çŸ¥çŠ¶æ€
- çŸ¥è¯†åº“æ¦‚è¦ï¼š{knowledge_summary}
- èƒ½åŠ›è¾¹ç•Œï¼š{capability_summary}
- ç›¸å…³ç»éªŒï¼š{relevant_experience}

## å…ƒè®¤çŸ¥è¯„ä¼°

### 1. çŸ¥è¯†è¯„ä¼°
- æˆ‘æœ‰ç›¸å…³çŸ¥è¯†å—ï¼Ÿ
- çŸ¥è¯†å®Œæ•´åº¦å¦‚ä½•ï¼Ÿ
- éœ€è¦ä»€ä¹ˆæ–°çŸ¥è¯†ï¼Ÿ

### 2. èƒ½åŠ›è¯„ä¼°
- è¿™ä¸ªä»»åŠ¡åœ¨æˆ‘çš„èƒ½åŠ›èŒƒå›´å†…å—ï¼Ÿ
- å¤æ‚åº¦è¯„åˆ†ï¼ˆ1-10ï¼‰ï¼Ÿ
- ä¸»è¦æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ

### 3. ç»éªŒè¯„ä¼°
- æˆ‘åšè¿‡ç±»ä¼¼ä»»åŠ¡å—ï¼Ÿ
- ä»¥å‰çš„æˆåŠŸ/å¤±è´¥ç»éªŒï¼Ÿ
- å¯ä»¥å¤ç”¨ä»€ä¹ˆï¼Ÿ

### 4. ç­–ç•¥å»ºè®®
- å»ºè®®çš„æ‰§è¡Œç­–ç•¥ï¼Ÿ
- æ˜¯å¦éœ€è¦åˆ†è§£ï¼Ÿ
- éœ€è¦å­¦ä¹ ä»€ä¹ˆï¼Ÿ

JSONæ ¼å¼ï¼š
{
  "knowledge_assessment": {
    "has_knowledge": boolean,
    "knowledge_gaps": ["gap1", "gap2"],
    "completeness": 0.7
  },
  "capability_assessment": {
    "within_capability": boolean,
    "complexity_score": 8,
    "main_challenges": ["challenge1", "challenge2"]
  },
  "experience_assessment": {
    "similar_tasks": ["task1", "task2"],
    "applicable_patterns": ["pattern1", "pattern2"],
    "lessons_learned": ["lesson1", "lesson2"]
  },
  "strategy_recommendation": {
    "approach": "direct|decompose|learn_first",
    "decomposition_needed": boolean,
    "learning_needs": ["need1", "need2"],
    "confidence": 0.6
  }
}
"""
    
    def assess(self, task, cognitive_state):
        """å…¨é¢çš„å…ƒè®¤çŸ¥è¯„ä¼°"""
        
        response = self.llm.complete(
            self.UNIFIED_ASSESSMENT_PROMPT.format(
                task=task,
                knowledge_summary=self.summarize_knowledge(cognitive_state),
                capability_summary=self.summarize_capability(cognitive_state),
                relevant_experience=self.find_relevant_experience(task, cognitive_state)
            )
        )
        
        return json.loads(response)
```

### 3. åŠ¨æ€ç­–ç•¥é€‰æ‹©

```python
class DynamicStrategySelection:
    """åŸºäºå…ƒè®¤çŸ¥è¯„ä¼°åŠ¨æ€é€‰æ‹©ç­–ç•¥"""
    
    def select_strategy(self, assessment):
        """ç»Ÿä¸€çš„ç­–ç•¥é€‰æ‹©"""
        
        strategy_prompt = """
åŸºäºå…ƒè®¤çŸ¥è¯„ä¼°é€‰æ‹©æœ€ä½³ç­–ç•¥ã€‚

## è¯„ä¼°ç»“æœ
{assessment}

## å¯ç”¨ç­–ç•¥

### A. ç›´æ¥æ‰§è¡Œ
- é€‚ç”¨ï¼šä»»åŠ¡åœ¨èƒ½åŠ›èŒƒå›´å†…ï¼Œæœ‰è¶³å¤ŸçŸ¥è¯†
- æ–¹æ³•ï¼šè°ƒç”¨å·²æœ‰çŸ¥è¯†ç›´æ¥æ‰§è¡Œ

### B. åˆ†è§£æ‰§è¡Œ
- é€‚ç”¨ï¼šä»»åŠ¡å¤æ‚ä½†å¯åˆ†è§£
- æ–¹æ³•ï¼šåˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œé€’å½’å¤„ç†

### C. å­¦ä¹ åæ‰§è¡Œ
- é€‚ç”¨ï¼šç¼ºå°‘å…³é”®çŸ¥è¯†
- æ–¹æ³•ï¼šå…ˆå­¦ä¹ å¿…è¦çŸ¥è¯†ï¼Œå†æ‰§è¡Œ

### D. æ¢ç´¢æ€§æ‰§è¡Œ
- é€‚ç”¨ï¼šä»»åŠ¡æ–°é¢–ï¼Œæ— ç»éªŒ
- æ–¹æ³•ï¼šå°æ­¥è¯•æ¢ï¼Œè¾¹åšè¾¹å­¦

### E. åä½œæ‰§è¡Œ
- é€‚ç”¨ï¼šè¶…å‡ºå•ä¸€èƒ½åŠ›
- æ–¹æ³•ï¼šè°ƒç”¨å…¶ä»–Agentåä½œ

## é€‰æ‹©ç­–ç•¥å¹¶è¯¦ç»†è§„åˆ’

JSONæ ¼å¼ï¼š
{
  "selected_strategy": "A|B|C|D|E",
  "reasoning": "é€‰æ‹©ç†ç”±",
  "execution_plan": {
    "steps": ["step1", "step2"],
    "contingencies": ["plan_b1", "plan_b2"],
    "learning_objectives": ["objective1", "objective2"],
    "success_criteria": ["criterion1", "criterion2"]
  }
}
"""
        
        response = self.llm.complete(
            strategy_prompt.format(assessment=assessment)
        )
        
        return json.loads(response)
```

### 4. æ‰§è¡Œä¸­çš„ç»Ÿä¸€ç›‘æ§

```python
class UnifiedExecutionMonitor:
    """ç»Ÿä¸€ç›‘æ§ï¼šè¿›åº¦ã€å­¦ä¹ ã€å¤æ‚æ€§"""
    
    MONITORING_PROMPT = """
æ‰§è¡Œä¸­çš„å…ƒè®¤çŸ¥ç›‘æ§ã€‚

## ä»»åŠ¡
{task}

## å½“å‰æ‰§è¡ŒçŠ¶æ€
- ç­–ç•¥ï¼š{strategy}
- å·²å®Œæˆï¼š{completed}
- å½“å‰æ­¥éª¤ï¼š{current_step}
- ç»“æœï¼š{current_result}

## å…ƒè®¤çŸ¥ç›‘æ§

### 1. è¿›åº¦ç›‘æ§
- æ˜¯å¦æŒ‰è®¡åˆ’è¿›è¡Œï¼Ÿ
- å®Œæˆåº¦å¦‚ä½•ï¼Ÿ
- é‡åˆ°é˜»ç¢äº†å—ï¼Ÿ

### 2. å­¦ä¹ ç›‘æ§
- å­¦åˆ°äº†ä»€ä¹ˆæ–°ä¸œè¥¿ï¼Ÿ
- å‘ç°äº†ä»€ä¹ˆæ¨¡å¼ï¼Ÿ
- æœ‰ä»€ä¹ˆæ„å¤–å‘ç°ï¼Ÿ

### 3. å¤æ‚æ€§ç›‘æ§
- å½“å‰æ­¥éª¤çš„å®é™…å¤æ‚åº¦ï¼Ÿ
- æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥åˆ†è§£ï¼Ÿ
- æ˜¯å¦éœ€è¦è°ƒæ•´ç­–ç•¥ï¼Ÿ

### 4. è‡ªæˆ‘è°ƒèŠ‚
- éœ€è¦è°ƒæ•´ä»€ä¹ˆï¼Ÿ
- å¦‚ä½•æ”¹è¿›æ‰§è¡Œï¼Ÿ
- æ˜¯å¦éœ€è¦æ±‚åŠ©ï¼Ÿ

JSONæ ¼å¼ï¼š
{
  "progress": {
    "on_track": boolean,
    "completion_rate": 0.6,
    "blockers": ["blocker1"]
  },
  "learning": {
    "new_insights": ["insight1", "insight2"],
    "patterns_discovered": ["pattern1"],
    "surprises": ["surprise1"]
  },
  "complexity": {
    "actual_complexity": 7,
    "needs_further_decomposition": boolean,
    "complexity_mismatch": "higher|lower|as_expected"
  },
  "self_regulation": {
    "adjustments_needed": ["adjustment1"],
    "strategy_change": "continue|modify|switch",
    "help_needed": boolean
  }
}
"""
    
    def monitor(self, task, execution_state):
        """ç»Ÿä¸€çš„æ‰§è¡Œç›‘æ§"""
        
        response = self.llm.complete(
            self.MONITORING_PROMPT.format(
                task=task,
                strategy=execution_state['strategy'],
                completed=execution_state['completed'],
                current_step=execution_state['current'],
                current_result=execution_state['result']
            )
        )
        
        monitoring = json.loads(response)
        
        # å®æ—¶å¤„ç†ç›‘æ§ç»“æœ
        self.process_monitoring_results(monitoring)
        
        return monitoring
```

### 5. æ·±åº¦åæ€ä¸çŸ¥è¯†æ•´åˆ

```python
class DeepReflection:
    """æ·±åº¦åæ€ï¼šæ•´åˆå­¦ä¹ ã€èƒ½åŠ›æ›´æ–°ã€æ¨¡å¼æå–"""
    
    REFLECTION_PROMPT = """
ä»»åŠ¡å®Œæˆåçš„æ·±åº¦å…ƒè®¤çŸ¥åæ€ã€‚

## ä»»åŠ¡
{task}

## æ‰§è¡Œè¿‡ç¨‹
{execution_trace}

## ç»“æœ
{result}

## æ·±åº¦åæ€

### 1. çŸ¥è¯†å±‚é¢
- éªŒè¯äº†å“ªäº›å·²æœ‰çŸ¥è¯†ï¼Ÿ
- å­¦åˆ°äº†å“ªäº›æ–°çŸ¥è¯†ï¼Ÿ
- å‘ç°äº†å“ªäº›çŸ¥è¯†é”™è¯¯ï¼Ÿ
- çŸ¥è¯†å¦‚ä½•è¿æ¥ï¼Ÿ

### 2. èƒ½åŠ›å±‚é¢
- å‘ç°äº†æ–°çš„èƒ½åŠ›è¾¹ç•Œï¼Ÿ
- å“ªäº›èƒ½åŠ›å¾—åˆ°äº†æå‡ï¼Ÿ
- å“ªäº›èƒ½åŠ›ä¸è¶³ï¼Ÿ
- å¦‚ä½•æ‰©å±•èƒ½åŠ›ï¼Ÿ

### 3. ç­–ç•¥å±‚é¢
- ç­–ç•¥é€‰æ‹©æ˜¯å¦æ­£ç¡®ï¼Ÿ
- æ‰§è¡Œä¸­çš„è°ƒæ•´æ˜¯å¦æœ‰æ•ˆï¼Ÿ
- æœ‰æ›´å¥½çš„ç­–ç•¥å—ï¼Ÿ
- ç­–ç•¥çš„é€‚ç”¨æ¡ä»¶ï¼Ÿ

### 4. æ¨¡å¼å±‚é¢
- æˆåŠŸçš„å…³é”®æ¨¡å¼ï¼Ÿ
- å¤±è´¥çš„æ ¹æœ¬åŸå› ï¼Ÿ
- å¯æ¨å¹¿çš„ç»éªŒï¼Ÿ
- é¢†åŸŸç‰¹å®švsé€šç”¨ï¼Ÿ

### 5. å…ƒè®¤çŸ¥å±‚é¢
- è‡ªæˆ‘è¯„ä¼°å‡†ç¡®å—ï¼Ÿ
- ç›‘æ§åŠæ—¶å—ï¼Ÿ
- å­¦ä¹ æœ‰æ•ˆå—ï¼Ÿ
- å¦‚ä½•æ”¹è¿›å…ƒè®¤çŸ¥ï¼Ÿ

JSONæ ¼å¼ï¼š
{
  "knowledge_updates": {
    "validated": ["knowledge1"],
    "new": ["knowledge2"],
    "corrected": ["knowledge3"],
    "connections": [["k1", "relates_to", "k2"]]
  },
  "capability_updates": {
    "new_boundaries": ["boundary1"],
    "improvements": ["skill1"],
    "gaps": ["gap1"],
    "expansion_plans": ["plan1"]
  },
  "strategy_insights": {
    "effectiveness": "high|medium|low",
    "adjustments_made": ["adj1"],
    "better_strategies": ["strategy1"],
    "applicability_conditions": ["condition1"]
  },
  "pattern_extraction": {
    "success_patterns": ["pattern1"],
    "failure_patterns": ["pattern2"],
    "generalizable": ["pattern3"],
    "domain_specific": ["pattern4"]
  },
  "metacognitive_insights": {
    "assessment_accuracy": 0.8,
    "monitoring_effectiveness": 0.7,
    "learning_efficiency": 0.9,
    "improvement_areas": ["area1"]
  }
}
"""
    
    def reflect(self, task, execution_trace, result):
        """æ·±åº¦åæ€å’Œå­¦ä¹ """
        
        response = self.llm.complete(
            self.REFLECTION_PROMPT.format(
                task=task,
                execution_trace=execution_trace,
                result=result
            )
        )
        
        return json.loads(response)
```

## ä¸‰ä½ä¸€ä½“çš„ååŒ

### 1. å­¦ä¹ å¢å¼ºå¤æ‚æ€§å¯¹æŠ—

```python
class LearningEnhancedDecomposition:
    """ç”¨å­¦ä¹ ç»éªŒæŒ‡å¯¼ä»»åŠ¡åˆ†è§£"""
    
    def decompose_with_experience(self, task, learned_patterns):
        """åŸºäºå·²å­¦æ¨¡å¼åˆ†è§£ä»»åŠ¡"""
        
        prompt = """
åŸºäºå·²å­¦ä¹ çš„æ¨¡å¼åˆ†è§£ä»»åŠ¡ã€‚

## ä»»åŠ¡
{task}

## å·²çŸ¥çš„åˆ†è§£æ¨¡å¼
{patterns}

## åº”ç”¨ç»éªŒåˆ†è§£ä»»åŠ¡

1. è¯†åˆ«ä»»åŠ¡ç±»å‹
2. åŒ¹é…å·²çŸ¥æ¨¡å¼
3. åº”ç”¨æˆåŠŸçš„åˆ†è§£ç­–ç•¥
4. é¿å…å·²çŸ¥çš„å¤±è´¥æ¨¡å¼

JSONæ ¼å¼ï¼š
{
  "task_type": "identified_type",
  "matched_patterns": ["pattern1"],
  "decomposition": [...],
  "avoided_pitfalls": ["pitfall1"]
}
"""
        
        return self.llm.complete(prompt)
```

### 2. å¤æ‚æ€§é©±åŠ¨å­¦ä¹ 

```python
class ComplexityDrivenLearning:
    """ä»å¤æ‚æ€§å¯¹æŠ—ä¸­å­¦ä¹ """
    
    def learn_from_decomposition(self, original_task, decomposition, results):
        """ä»åˆ†è§£ç»éªŒä¸­å­¦ä¹ """
        
        prompt = """
ä»ä»»åŠ¡åˆ†è§£ç»éªŒä¸­å­¦ä¹ ã€‚

## åŸå§‹ä»»åŠ¡
{original}

## åˆ†è§£æ–¹æ¡ˆ
{decomposition}

## æ‰§è¡Œç»“æœ
{results}

## å­¦ä¹ è¦ç‚¹

1. åˆ†è§£ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Ÿ
2. æœ€ä¼˜åˆ†è§£ç²’åº¦ï¼Ÿ
3. å­ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼Ÿ
4. å¯å¤ç”¨çš„åˆ†è§£æ¨¡å¼ï¼Ÿ

æå–é€šç”¨çŸ¥è¯†ã€‚
"""
        
        return self.llm.complete(prompt)
```

### 3. å…ƒè®¤çŸ¥åè°ƒä¸€åˆ‡

```python
class MetacognitiveCoordinator:
    """å…ƒè®¤çŸ¥åè°ƒå­¦ä¹ å’Œå¤æ‚æ€§å¯¹æŠ—"""
    
    def coordinate_cognitive_functions(self, task):
        """åè°ƒæ‰€æœ‰è®¤çŸ¥åŠŸèƒ½"""
        
        # å…ƒè®¤çŸ¥è¯„ä¼°è§¦å‘ä¸€åˆ‡
        assessment = self.assess_task(task)
        
        # æ ¹æ®è¯„ä¼°ç»“æœåè°ƒå…¶ä»–åŠŸèƒ½
        if assessment['too_complex']:
            # è§¦å‘å¤æ‚æ€§å¯¹æŠ—
            decomposition = self.trigger_decomposition(task)
            # ä»åˆ†è§£ä¸­å­¦ä¹ 
            self.learn_from_decomposition(decomposition)
            
        if assessment['knowledge_gaps']:
            # è§¦å‘ä¸»åŠ¨å­¦ä¹ 
            self.trigger_learning(assessment['knowledge_gaps'])
            
        if assessment['similar_experience']:
            # åº”ç”¨å·²æœ‰ç»éªŒ
            self.apply_experience(assessment['experience'])
            
        # æ‰§è¡Œå¹¶æŒç»­åè°ƒ
        result = self.execute_with_coordination(task)
        
        # åæ€æ›´æ–°æ‰€æœ‰æ–¹é¢
        self.comprehensive_update(task, result)
        
        return result
```

## å®è·µï¼šå®Œå…¨ç»Ÿä¸€çš„Agent

```python
class FullyIntegratedMetacognitiveAgent(GenericReactAgent):
    """å®Œå…¨æ•´åˆçš„å…ƒè®¤çŸ¥Agent"""
    
    def __init__(self, config, **kwargs):
        super().__init__(config, **kwargs)
        
        # ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å¼•æ“
        self.metacognitive_engine = UnifiedMetacognitiveEngine(self.llm)
        
        # ç»Ÿä¸€çš„ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å®Œæ•´å…ƒè®¤çŸ¥èƒ½åŠ›çš„Agentã€‚

ä½ çš„è®¤çŸ¥ç³»ç»ŸåŒ…å«ï¼š
1. è‡ªæˆ‘æ„è¯†ï¼šéšæ—¶çŸ¥é“è‡ªå·±çš„çŸ¥è¯†å’Œèƒ½åŠ›è¾¹ç•Œ
2. å¤æ‚æ€§å¯¹æŠ—ï¼šé‡åˆ°å›°éš¾è‡ªåŠ¨åˆ†è§£ä»»åŠ¡
3. æŒç»­å­¦ä¹ ï¼šä»æ¯æ¬¡ç»éªŒä¸­æå–çŸ¥è¯†

æ‰§è¡Œä»»ä½•ä»»åŠ¡æ—¶ï¼š
- å…ˆè¯„ä¼°ï¼šæˆ‘èƒ½åšè¿™ä¸ªå—ï¼Ÿæˆ‘çŸ¥é“æ€ä¹ˆåšå—ï¼Ÿ
- ç­–ç•¥é€‰æ‹©ï¼šç›´æ¥åšï¼Ÿåˆ†è§£ï¼Ÿå…ˆå­¦ä¹ ï¼Ÿ
- æ‰§è¡Œç›‘æ§ï¼šæˆ‘åœ¨å­¦ä»€ä¹ˆï¼Ÿé‡åˆ°ä»€ä¹ˆå›°éš¾ï¼Ÿ
- åæ€æ•´åˆï¼šæˆ‘å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿå¦‚ä½•æ”¹è¿›ï¼Ÿ

è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è®¤çŸ¥å¾ªç¯ï¼Œä¸æ˜¯ç‹¬ç«‹çš„åŠŸèƒ½ã€‚
"""
    
    def execute_task(self, task_description):
        """ç»Ÿä¸€çš„å…ƒè®¤çŸ¥æ‰§è¡Œ"""
        
        print("ğŸ§  å¯åŠ¨å…ƒè®¤çŸ¥ç³»ç»Ÿ...")
        
        # 1. ç»Ÿä¸€è¯„ä¼°
        print("\nğŸ“Š å…ƒè®¤çŸ¥è¯„ä¼°...")
        assessment = self.metacognitive_engine.assess(task_description)
        
        self._display_assessment(assessment)
        
        # 2. åŠ¨æ€ç­–ç•¥
        print("\nğŸ¯ ç­–ç•¥é€‰æ‹©...")
        strategy = self.metacognitive_engine.select_strategy(assessment)
        
        print(f"ç­–ç•¥: {strategy['selected_strategy']}")
        print(f"ç†ç”±: {strategy['reasoning']}")
        
        # 3. æ‰§è¡Œä¸ç›‘æ§
        print("\nğŸš€ æ‰§è¡Œä¸å­¦ä¹ ...")
        execution_result = self._execute_with_strategy(
            task_description,
            strategy,
            assessment
        )
        
        # 4. æ·±åº¦åæ€
        print("\nğŸ¤” æ·±åº¦åæ€...")
        reflection = self.metacognitive_engine.reflect(
            task_description,
            execution_result
        )
        
        self._display_reflection(reflection)
        
        # 5. çŸ¥è¯†æ•´åˆ
        print("\nğŸ“ æ›´æ–°è®¤çŸ¥çŠ¶æ€...")
        self.metacognitive_engine.update_cognitive_state(reflection)
        
        return execution_result['final_result']
    
    def _execute_with_strategy(self, task, strategy, assessment):
        """æ ¹æ®ç­–ç•¥æ‰§è¡Œ"""
        
        if strategy['selected_strategy'] == 'A':
            # ç›´æ¥æ‰§è¡Œ
            return self._direct_execution(task, assessment)
            
        elif strategy['selected_strategy'] == 'B':
            # åˆ†è§£æ‰§è¡Œ
            return self._decomposed_execution(task, strategy)
            
        elif strategy['selected_strategy'] == 'C':
            # å­¦ä¹ åæ‰§è¡Œ
            return self._learn_then_execute(task, strategy)
            
        elif strategy['selected_strategy'] == 'D':
            # æ¢ç´¢æ€§æ‰§è¡Œ
            return self._exploratory_execution(task)
            
        elif strategy['selected_strategy'] == 'E':
            # åä½œæ‰§è¡Œ
            return self._collaborative_execution(task)
    
    def _decomposed_execution(self, task, strategy):
        """åˆ†è§£æ‰§è¡Œwithå­¦ä¹ """
        
        # åŸºäºç»éªŒåˆ†è§£
        decomposition = self.metacognitive_engine.decompose_with_experience(
            task,
            self.metacognitive_engine.cognitive_state['success_patterns']
        )
        
        results = []
        for subtask in decomposition['subtasks']:
            # é€’å½’å…ƒè®¤çŸ¥æ‰§è¡Œ
            sub_result = self.execute_task(subtask)
            
            # å®æ—¶å­¦ä¹ 
            self.metacognitive_engine.learn_from_step(subtask, sub_result)
            
            results.append(sub_result)
        
        # åˆå¹¶ç»“æœ
        final_result = self.metacognitive_engine.merge_results(results)
        
        # å­¦ä¹ åˆ†è§£ç»éªŒ
        self.metacognitive_engine.learn_decomposition_pattern(
            task,
            decomposition,
            final_result
        )
        
        return {
            'final_result': final_result,
            'decomposition': decomposition,
            'subtask_results': results
        }
    
    def _display_assessment(self, assessment):
        """æ˜¾ç¤ºè¯„ä¼°ç»“æœ"""
        
        print(f"çŸ¥è¯†å®Œæ•´åº¦: {assessment['knowledge_assessment']['completeness']:.1%}")
        print(f"å¤æ‚åº¦è¯„åˆ†: {assessment['capability_assessment']['complexity_score']}/10")
        print(f"æ‰§è¡Œä¿¡å¿ƒ: {assessment['strategy_recommendation']['confidence']:.1%}")
        
        if assessment['knowledge_assessment']['knowledge_gaps']:
            print(f"çŸ¥è¯†ç¼ºå£: {', '.join(assessment['knowledge_assessment']['knowledge_gaps'])}")
            
        if assessment['experience_assessment']['similar_tasks']:
            print(f"ç›¸ä¼¼ç»éªŒ: {', '.join(assessment['experience_assessment']['similar_tasks'])}")
    
    def _display_reflection(self, reflection):
        """æ˜¾ç¤ºåæ€ç»“æœ"""
        
        if reflection['knowledge_updates']['new']:
            print(f"âœ¨ æ–°çŸ¥è¯†: {', '.join(reflection['knowledge_updates']['new'])}")
            
        if reflection['pattern_extraction']['success_patterns']:
            print(f"âœ… æˆåŠŸæ¨¡å¼: {', '.join(reflection['pattern_extraction']['success_patterns'])}")
            
        if reflection['metacognitive_insights']['improvement_areas']:
            print(f"ğŸ“ˆ æ”¹è¿›æ–¹å‘: {', '.join(reflection['metacognitive_insights']['improvement_areas'])}")
```

## ç³»ç»Ÿä¼˜åŠ¿

### 1. çœŸæ­£çš„è®¤çŸ¥ç»Ÿä¸€

ä¸å†æ˜¯ä¸‰ä¸ªç‹¬ç«‹åŠŸèƒ½ï¼Œè€Œæ˜¯ä¸€ä¸ªæœ‰æœºæ•´ä½“ï¼š
- è¯„ä¼°è§¦å‘ç­–ç•¥é€‰æ‹©
- ç­–ç•¥å†³å®šæ˜¯å¦åˆ†è§£
- æ‰§è¡Œäº§ç”Ÿå­¦ä¹ 
- å­¦ä¹ æ›´æ–°èƒ½åŠ›è¾¹ç•Œ
- èƒ½åŠ›å½±å“ä¸‹æ¬¡è¯„ä¼°

### 2. è‡ªé€‚åº”èƒ½åŠ›

ç³»ç»Ÿèƒ½å¤Ÿï¼š
- è‡ªåŠ¨è¯†åˆ«è¶…å‡ºèƒ½åŠ›çš„ä»»åŠ¡
- é€‰æ‹©åˆé€‚çš„å¤„ç†ç­–ç•¥
- ä»ç»éªŒä¸­å­¦ä¹ æ›´å¥½çš„ç­–ç•¥
- ä¸æ–­æ‰©å±•èƒ½åŠ›è¾¹ç•Œ

### 3. æŒç»­è¿›åŒ–

æ¯æ¬¡æ‰§è¡Œéƒ½ä¼šï¼š
- éªŒè¯å·²æœ‰çŸ¥è¯†
- å‘ç°æ–°çŸ¥è¯†
- ä¿®æ­£é”™è¯¯è®¤çŸ¥
- æå–é€šç”¨æ¨¡å¼
- æ”¹è¿›å…ƒè®¤çŸ¥æœ¬èº«

## å®ç°è·¯å¾„

### Phase 1: åŸºç¡€æ•´åˆ
```python
# åœ¨ç°æœ‰ReactAgentåŸºç¡€ä¸Šæ·»åŠ ç»Ÿä¸€è¯„ä¼°
def execute_task(self, task):
    assessment = self.unified_assess(task)
    if assessment['too_complex']:
        return self.decompose_and_execute(task)
    else:
        return self.direct_execute(task)
```

### Phase 2: åŠ¨æ€ç­–ç•¥
```python
# æ·»åŠ å¤šç§æ‰§è¡Œç­–ç•¥
strategies = {
    'direct': DirectExecution(),
    'decompose': DecomposeExecution(),
    'learn_first': LearnFirstExecution(),
    'explore': ExploratoryExecution()
}
```

### Phase 3: æ·±åº¦å­¦ä¹ 
```python
# æ•´åˆå­¦ä¹ åˆ°æ¯ä¸ªæ‰§è¡Œæ­¥éª¤
def execute_step(self, step):
    result = super().execute_step(step)
    learning = self.extract_learning(step, result)
    self.update_knowledge(learning)
    return result
```

### Phase 4: å®Œå…¨ç»Ÿä¸€
```python
# ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å¼•æ“
engine = UnifiedMetacognitiveEngine()
result = engine.process_task(task)
```

## æ€»ç»“

è¿™ä¸ªç»Ÿä¸€æ¶æ„å®ç°äº†ï¼š

1. **ä¸€ä¸ªå¼•æ“**ï¼šç»Ÿä¸€çš„å…ƒè®¤çŸ¥å¼•æ“å¤„ç†ä¸€åˆ‡
2. **ä¸€ä¸ªå¾ªç¯**ï¼šè¯„ä¼°â†’ç­–ç•¥â†’æ‰§è¡Œâ†’åæ€
3. **ä¸€ä¸ªç›®æ ‡**ï¼šä¸æ–­æ‰©å±•è®¤çŸ¥è¾¹ç•Œ

æ ¸å¿ƒä»·å€¼ï¼š
- **å­¦ä¹ **è®©Agentè¶Šæ¥è¶Šèªæ˜
- **åˆ†è§£**è®©Agentå¤„ç†è¶Šæ¥è¶Šå¤æ‚çš„ä»»åŠ¡
- **å…ƒè®¤çŸ¥**åè°ƒä¸€åˆ‡ï¼ŒçŸ¥é“ä½•æ—¶å­¦ã€ä½•æ—¶åˆ†è§£

æœ€ç»ˆå®ç°ï¼š**ä¸€ä¸ªçœŸæ­£å…·æœ‰è‡ªä¸»è®¤çŸ¥èƒ½åŠ›çš„Agent**ï¼Œèƒ½å¤Ÿï¼š
- çŸ¥é“è‡ªå·±çš„è¾¹ç•Œ
- è¶…å‡ºè¾¹ç•Œæ—¶è‡ªåŠ¨åˆ†è§£
- ä»ç»éªŒä¸­æŒç»­å­¦ä¹ 
- ä¸æ–­æ‰©å±•èƒ½åŠ›èŒƒå›´

è¿™ä¸æ˜¯ä¸‰ä¸ªåŠŸèƒ½çš„ç®€å•ç›¸åŠ ï¼Œè€Œæ˜¯**è®¤çŸ¥èƒ½åŠ›çš„æ¶Œç°**ã€‚