# ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å­¦ä¹ æ¶æ„

## æ ¸å¿ƒæ´å¯Ÿ

å­¦ä¹ æœ¬è´¨ä¸Šæ˜¯ä¸€ç§å…ƒè®¤çŸ¥æ´»åŠ¨ï¼š
- **å…ƒè®¤çŸ¥**ï¼šçŸ¥é“è‡ªå·±çŸ¥é“ä»€ä¹ˆï¼Œä¸çŸ¥é“ä»€ä¹ˆ
- **å­¦ä¹ **ï¼šä»ç»éªŒä¸­æå–çŸ¥è¯†ï¼Œæ”¹è¿›æœªæ¥è¡¨ç°
- **ç»Ÿä¸€è§†è§’**ï¼šå­¦ä¹ æ˜¯å…ƒè®¤çŸ¥çš„çŸ¥è¯†æ›´æ–°æœºåˆ¶

## ç°çŠ¶åˆ†æ

### å½“å‰React Agentçš„å­¦ä¹ æœºåˆ¶

```python
# ç°æœ‰çš„çŸ¥è¯†æå–ï¼ˆåœ¨ react_agent.py ä¸­ï¼‰
if self.config.memory_level == MemoryLevel.SMART:
    # æå–çŸ¥è¯†
    knowledge = self._extract_knowledge_from_history()
    # ä¿å­˜åˆ°æ–‡ä»¶
    self._save_knowledge(knowledge)
```

é—®é¢˜ï¼š
1. å­¦ä¹ æ˜¯è¢«åŠ¨çš„ï¼ˆä»»åŠ¡ç»“æŸåï¼‰
2. ä¸æ‰§è¡Œè¿‡ç¨‹åˆ†ç¦»
3. æ²¡æœ‰ä¸»åŠ¨åæ€æœºåˆ¶

### ç†æƒ³çš„å…ƒè®¤çŸ¥å­¦ä¹ 

```python
# ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å­¦ä¹ å¾ªç¯
class MetacognitiveLearningAgent:
    """èåˆå…ƒè®¤çŸ¥å’Œå­¦ä¹ çš„Agent"""
    
    def execute_with_learning(self, task):
        # 1. æ‰§è¡Œå‰ï¼šè°ƒç”¨å·²æœ‰çŸ¥è¯†
        prior_knowledge = self.recall_relevant_knowledge(task)
        
        # 2. æ‰§è¡Œä¸­ï¼šå®æ—¶å­¦ä¹ 
        result = self.execute_with_monitoring(task, prior_knowledge)
        
        # 3. æ‰§è¡Œåï¼šåæ€å’Œæ›´æ–°
        new_knowledge = self.reflect_and_learn(task, result)
        
        # 4. çŸ¥è¯†æ•´åˆ
        self.integrate_knowledge(prior_knowledge, new_knowledge)
```

## ç»Ÿä¸€æ¶æ„è®¾è®¡

### 1. å…ƒè®¤çŸ¥å­¦ä¹ å¾ªç¯

```python
class UnifiedMetacognitiveLearning:
    """ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å­¦ä¹ ç³»ç»Ÿ"""
    
    def __init__(self, llm):
        self.llm = llm
        self.knowledge_base = KnowledgeBase()
        
    def metacognitive_loop(self, task):
        """å®Œæ•´çš„å…ƒè®¤çŸ¥å­¦ä¹ å¾ªç¯"""
        
        # Phase 1: è®¤çŸ¥å‡†å¤‡ï¼ˆè°ƒç”¨å·²æœ‰çŸ¥è¯†ï¼‰
        preparation = self.cognitive_preparation(task)
        
        # Phase 2: æ‰§è¡Œç›‘æ§ï¼ˆè¾¹åšè¾¹å­¦ï¼‰
        execution = self.monitored_execution(task, preparation)
        
        # Phase 3: åæ€å­¦ä¹ ï¼ˆæ€»ç»“ç»éªŒï¼‰
        reflection = self.reflective_learning(task, execution)
        
        # Phase 4: çŸ¥è¯†æ›´æ–°ï¼ˆæ•´åˆæ–°çŸ¥ï¼‰
        self.knowledge_integration(reflection)
        
        return execution.result
```

### 2. LLMé©±åŠ¨çš„çŸ¥è¯†è°ƒç”¨

```python
class CognitivePreparation:
    """æ‰§è¡Œå‰çš„è®¤çŸ¥å‡†å¤‡"""
    
    RECALL_PROMPT = """
å‡†å¤‡æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ã€‚å›å¿†ç›¸å…³ç»éªŒã€‚

## å½“å‰ä»»åŠ¡
{task}

## çŸ¥è¯†åº“æ‘˜è¦
{knowledge_summary}

## è¯·å›ç­”
1. æˆ‘ä»¥å‰åšè¿‡ç±»ä¼¼çš„ä»»åŠ¡å—ï¼Ÿ
2. å“ªäº›ç»éªŒå¯èƒ½æœ‰ç”¨ï¼Ÿ
3. å¯èƒ½é‡åˆ°ä»€ä¹ˆé—®é¢˜ï¼Ÿ
4. å»ºè®®çš„æ‰§è¡Œç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ

JSONæ ¼å¼ï¼š
{
  "similar_experiences": ["ç»éªŒ1", "ç»éªŒ2"],
  "useful_knowledge": ["çŸ¥è¯†ç‚¹1", "çŸ¥è¯†ç‚¹2"],
  "potential_issues": ["é—®é¢˜1", "é—®é¢˜2"],
  "recommended_strategy": "ç­–ç•¥æè¿°",
  "confidence": 0.8
}
"""
    
    def prepare(self, task, knowledge_base):
        """è®©LLMè°ƒç”¨ç›¸å…³çŸ¥è¯†"""
        
        # è·å–å¯èƒ½ç›¸å…³çš„çŸ¥è¯†
        relevant_knowledge = knowledge_base.search(task, top_k=5)
        
        response = self.llm.complete(
            self.RECALL_PROMPT.format(
                task=task,
                knowledge_summary=self.summarize(relevant_knowledge)
            )
        )
        
        return json.loads(response)
```

### 3. æ‰§è¡Œä¸­çš„å®æ—¶å­¦ä¹ 

```python
class MonitoredExecution:
    """è¾¹æ‰§è¡Œè¾¹å­¦ä¹ """
    
    MONITORING_PROMPT = """
æˆ‘æ­£åœ¨æ‰§è¡Œä»»åŠ¡ï¼Œè¯·ç›‘æ§æˆ‘çš„çŠ¶æ€ã€‚

## ä»»åŠ¡
{task}

## å·²å®Œæˆæ­¥éª¤
{completed_steps}

## å½“å‰æ­¥éª¤
{current_step}

## å½“å‰ç»“æœ
{current_result}

## å…ƒè®¤çŸ¥æ£€æŸ¥
1. æˆ‘çš„æ‰§è¡Œæ˜¯å¦åç¦»ç›®æ ‡ï¼Ÿ
2. æˆ‘æ˜¯å¦é‡åˆ°äº†æ„å¤–æƒ…å†µï¼Ÿ
3. æˆ‘å­¦åˆ°äº†ä»€ä¹ˆæ–°ä¸œè¥¿ï¼Ÿ
4. æ˜¯å¦éœ€è¦è°ƒæ•´ç­–ç•¥ï¼Ÿ

JSONæ ¼å¼ï¼š
{
  "on_track": boolean,
  "unexpected_findings": ["å‘ç°1", "å‘ç°2"],
  "learned_insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"],
  "strategy_adjustment": "è°ƒæ•´å»ºè®®æˆ–null",
  "continue": boolean
}
"""
    
    def monitor_step(self, task, step_info):
        """ç›‘æ§å•ä¸ªæ‰§è¡Œæ­¥éª¤"""
        
        response = self.llm.complete(
            self.MONITORING_PROMPT.format(
                task=task,
                completed_steps=step_info['completed'],
                current_step=step_info['current'],
                current_result=step_info['result']
            )
        )
        
        monitoring = json.loads(response)
        
        # å®æ—¶è®°å½•å­¦åˆ°çš„ä¸œè¥¿
        if monitoring['learned_insights']:
            self.record_insights(monitoring['learned_insights'])
        
        return monitoring
```

### 4. åæ€æ€§å­¦ä¹ 

```python
class ReflectiveLearning:
    """æ‰§è¡Œåçš„æ·±åº¦åæ€"""
    
    REFLECTION_PROMPT = """
ä»»åŠ¡å·²å®Œæˆï¼Œè¿›è¡Œæ·±åº¦åæ€å’Œå­¦ä¹ ã€‚

## ä»»åŠ¡æè¿°
{task}

## æ‰§è¡Œè¿‡ç¨‹
{execution_trace}

## æœ€ç»ˆç»“æœ
{result}

## åæ€é—®é¢˜
1. ä»€ä¹ˆåšå¾—å¥½ï¼Ÿä»€ä¹ˆåšå¾—ä¸å¥½ï¼Ÿ
2. æœ€é‡è¦çš„ç»éªŒæ•™è®­æ˜¯ä»€ä¹ˆï¼Ÿ
3. å¦‚æœé‡åšï¼Œä¼šå¦‚ä½•æ”¹è¿›ï¼Ÿ
4. è¿™æ¬¡ç»å†å¦‚ä½•æ”¹å˜äº†æˆ‘çš„è®¤çŸ¥ï¼Ÿ
5. æœ‰ä»€ä¹ˆé€šç”¨æ¨¡å¼å¯ä»¥æå–ï¼Ÿ

## çŸ¥è¯†æå–
è¯·æå–ï¼š
- æˆåŠŸæ¨¡å¼
- å¤±è´¥æ¨¡å¼
- é¢†åŸŸçŸ¥è¯†
- æ–¹æ³•è®ºçŸ¥è¯†
- å…ƒè®¤çŸ¥çŸ¥è¯†

JSONæ ¼å¼ï¼š
{
  "performance_analysis": {
    "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
    "weaknesses": ["ç¼ºç‚¹1", "ç¼ºç‚¹2"],
    "improvements": ["æ”¹è¿›1", "æ”¹è¿›2"]
  },
  "key_lessons": ["æ•™è®­1", "æ•™è®­2"],
  "knowledge_gained": {
    "success_patterns": ["æ¨¡å¼1", "æ¨¡å¼2"],
    "failure_patterns": ["æ¨¡å¼1", "æ¨¡å¼2"],
    "domain_knowledge": ["çŸ¥è¯†1", "çŸ¥è¯†2"],
    "methodology": ["æ–¹æ³•1", "æ–¹æ³•2"],
    "metacognitive": ["å…ƒè®¤çŸ¥1", "å…ƒè®¤çŸ¥2"]
  },
  "cognitive_update": "è¿™æ¬¡ç»å†å¦‚ä½•æ”¹å˜äº†è®¤çŸ¥"
}
"""
    
    def reflect(self, task, execution_trace, result):
        """æ·±åº¦åæ€å­¦ä¹ """
        
        response = self.llm.complete(
            self.REFLECTION_PROMPT.format(
                task=task,
                execution_trace=execution_trace,
                result=result
            )
        )
        
        return json.loads(response)
```

### 5. çŸ¥è¯†æ•´åˆä¸æ›´æ–°

```python
class KnowledgeIntegration:
    """æ•´åˆæ–°æ—§çŸ¥è¯†"""
    
    INTEGRATION_PROMPT = """
æ•´åˆæ–°å­¦åˆ°çš„çŸ¥è¯†ä¸å·²æœ‰çŸ¥è¯†ã€‚

## å·²æœ‰çŸ¥è¯†
{existing_knowledge}

## æ–°å­¦çŸ¥è¯†
{new_knowledge}

## æ•´åˆä»»åŠ¡
1. è¯†åˆ«çŸ¥è¯†å†²çª
2. è§£å†³çŸ›ç›¾
3. åˆå¹¶ç›¸ä¼¼çŸ¥è¯†
4. å»ºç«‹çŸ¥è¯†è¿æ¥
5. æ›´æ–°çŸ¥è¯†ä¼˜å…ˆçº§

JSONæ ¼å¼ï¼š
{
  "conflicts": ["å†²çª1", "å†²çª2"],
  "resolutions": ["è§£å†³1", "è§£å†³2"],
  "merged_knowledge": ["åˆå¹¶åçŸ¥è¯†1", "åˆå¹¶åçŸ¥è¯†2"],
  "knowledge_graph": {
    "nodes": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
    "edges": [["æ¦‚å¿µ1", "å…³ç³»", "æ¦‚å¿µ2"]]
  },
  "priority_updates": {
    "promoted": ["æå‡ä¼˜å…ˆçº§çš„çŸ¥è¯†"],
    "demoted": ["é™ä½ä¼˜å…ˆçº§çš„çŸ¥è¯†"]
  }
}
"""
    
    def integrate(self, existing, new):
        """è®©LLMæ•´åˆçŸ¥è¯†"""
        
        response = self.llm.complete(
            self.INTEGRATION_PROMPT.format(
                existing_knowledge=existing,
                new_knowledge=new
            )
        )
        
        integration = json.loads(response)
        
        # æ›´æ–°çŸ¥è¯†åº“
        self.update_knowledge_base(integration)
        
        return integration
```

## çŸ¥è¯†çš„å±‚æ¬¡ç»“æ„

### ä¸‰å±‚çŸ¥è¯†ä½“ç³»

```python
class HierarchicalKnowledge:
    """åˆ†å±‚çš„çŸ¥è¯†ä½“ç³»"""
    
    def __init__(self):
        # ç¬¬ä¸€å±‚ï¼šäº‹å®æ€§çŸ¥è¯†ï¼ˆWhatï¼‰
        self.factual = {
            "domain_facts": [],      # é¢†åŸŸäº‹å®
            "case_studies": [],      # å…·ä½“æ¡ˆä¾‹
            "examples": []           # ç¤ºä¾‹
        }
        
        # ç¬¬äºŒå±‚ï¼šç¨‹åºæ€§çŸ¥è¯†ï¼ˆHowï¼‰
        self.procedural = {
            "methods": [],           # æ–¹æ³•æ­¥éª¤
            "strategies": [],        # ç­–ç•¥æ¨¡å¼
            "heuristics": []        # ç»éªŒæ³•åˆ™
        }
        
        # ç¬¬ä¸‰å±‚ï¼šå…ƒè®¤çŸ¥çŸ¥è¯†ï¼ˆWhy & Whenï¼‰
        self.metacognitive = {
            "when_to_apply": [],    # ä½•æ—¶ä½¿ç”¨
            "why_it_works": [],     # ä¸ºä½•æœ‰æ•ˆ
            "limitations": [],      # å±€é™æ€§
            "self_knowledge": []    # è‡ªæˆ‘è®¤çŸ¥
        }
```

### çŸ¥è¯†çš„åŠ¨æ€ä¼˜å…ˆçº§

```python
class DynamicKnowledgePriority:
    """åŠ¨æ€è°ƒæ•´çŸ¥è¯†ä¼˜å…ˆçº§"""
    
    def update_priorities(self, knowledge_item, usage_result):
        """æ ¹æ®ä½¿ç”¨æ•ˆæœæ›´æ–°ä¼˜å…ˆçº§"""
        
        update_prompt = """
æ ¹æ®çŸ¥è¯†ä½¿ç”¨æ•ˆæœæ›´æ–°å…¶ä¼˜å…ˆçº§ã€‚

## ä½¿ç”¨çš„çŸ¥è¯†
{knowledge}

## ä½¿ç”¨åœºæ™¯
{context}

## ä½¿ç”¨æ•ˆæœ
{result}

## è¯„ä¼°
1. è¿™ä¸ªçŸ¥è¯†æœ‰å¤šæœ‰ç”¨ï¼Ÿ(0-10)
2. é€‚ç”¨èŒƒå›´æœ‰å¤šå¹¿ï¼Ÿ(0-10)
3. å¯é æ€§å¦‚ä½•ï¼Ÿ(0-10)
4. æ˜¯å¦éœ€è¦ä¿®æ­£ï¼Ÿ

JSONæ ¼å¼ï¼š
{
  "usefulness": number,
  "generality": number,
  "reliability": number,
  "needs_revision": boolean,
  "revision_suggestion": "å»ºè®®æˆ–null",
  "new_priority": number
}
"""
        
        response = self.llm.complete(
            update_prompt.format(
                knowledge=knowledge_item,
                context=usage_result['context'],
                result=usage_result['outcome']
            )
        )
        
        return json.loads(response)
```

## å®è·µï¼šå®Œæ•´çš„å…ƒè®¤çŸ¥å­¦ä¹ Agent

```python
class MetacognitiveLearningAgent(GenericReactAgent):
    """èåˆå…ƒè®¤çŸ¥å’Œå­¦ä¹ çš„Agent"""
    
    def __init__(self, config, **kwargs):
        super().__init__(config, **kwargs)
        
        # ç»Ÿä¸€çš„å…ƒè®¤çŸ¥å­¦ä¹ ç³»ç»Ÿ
        self.metacognitive = UnifiedMetacognitiveLearning(self.llm)
        
    def execute_task(self, task_description):
        """å¸¦å…ƒè®¤çŸ¥å­¦ä¹ çš„ä»»åŠ¡æ‰§è¡Œ"""
        
        # 1. è®¤çŸ¥å‡†å¤‡ï¼šæ¿€æ´»ç›¸å…³çŸ¥è¯†
        print("ğŸ§  è®¤çŸ¥å‡†å¤‡...")
        preparation = self.metacognitive.cognitive_preparation(task_description)
        
        if preparation['similar_experiences']:
            print(f"ğŸ“š è°ƒç”¨ç»éªŒ: {', '.join(preparation['similar_experiences'])}")
        
        if preparation['potential_issues']:
            print(f"âš ï¸ æ½œåœ¨é—®é¢˜: {', '.join(preparation['potential_issues'])}")
        
        # 2. è®¾ç½®æ‰§è¡Œç­–ç•¥
        self.set_strategy(preparation['recommended_strategy'])
        
        # 3. æ‰§è¡Œwithç›‘æ§
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œ...")
        execution_trace = []
        
        # åˆ†æ­¥æ‰§è¡Œ
        steps = self.plan_steps(task_description, preparation)
        
        for i, step in enumerate(steps):
            print(f"\næ­¥éª¤ {i+1}/{len(steps)}: {step['description']}")
            
            # æ‰§è¡Œæ­¥éª¤
            step_result = self.execute_step(step)
            
            # å®æ—¶ç›‘æ§å’Œå­¦ä¹ 
            monitoring = self.metacognitive.monitor_step(
                task_description,
                {
                    'completed': execution_trace,
                    'current': step,
                    'result': step_result
                }
            )
            
            if monitoring['learned_insights']:
                print(f"ğŸ’¡ æ–°å‘ç°: {', '.join(monitoring['learned_insights'])}")
            
            if monitoring['strategy_adjustment']:
                print(f"ğŸ”„ ç­–ç•¥è°ƒæ•´: {monitoring['strategy_adjustment']}")
                self.adjust_strategy(monitoring['strategy_adjustment'])
            
            execution_trace.append({
                'step': step,
                'result': step_result,
                'monitoring': monitoring
            })
            
            if not monitoring['continue']:
                print("ğŸ›‘ å…ƒè®¤çŸ¥å†³å®šåœæ­¢æ‰§è¡Œ")
                break
        
        # 4. åæ€å­¦ä¹ 
        print("\nğŸ¤” åæ€å­¦ä¹ ...")
        reflection = self.metacognitive.reflect(
            task_description,
            execution_trace,
            self.get_final_result()
        )
        
        print(f"âœ¨ å…³é”®ç»éªŒ: {', '.join(reflection['key_lessons'])}")
        
        # 5. çŸ¥è¯†æ•´åˆ
        print("\nğŸ“ æ›´æ–°çŸ¥è¯†åº“...")
        self.metacognitive.integrate_knowledge(reflection['knowledge_gained'])
        
        # 6. è¿”å›ç»“æœ
        return self.get_final_result()
    
    def set_strategy(self, strategy):
        """è®¾ç½®æ‰§è¡Œç­–ç•¥"""
        self.current_strategy = strategy
        
    def adjust_strategy(self, adjustment):
        """åŠ¨æ€è°ƒæ•´ç­–ç•¥"""
        self.current_strategy = adjustment
```

## çŸ¥è¯†åº“çš„è‡ªç„¶è¯­è¨€è¡¨ç¤º

```python
class NaturalLanguageKnowledge:
    """ç”¨è‡ªç„¶è¯­è¨€å­˜å‚¨çŸ¥è¯†"""
    
    def save_knowledge(self, knowledge, file_path):
        """ä¿å­˜ä¸ºMarkdownæ ¼å¼"""
        
        content = f"""# çŸ¥è¯†åº“

## æœ€è¿‘æ›´æ–°
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æˆåŠŸæ¨¡å¼
{self.format_patterns(knowledge['success_patterns'])}

## å¤±è´¥æ¨¡å¼
{self.format_patterns(knowledge['failure_patterns'])}

## é¢†åŸŸçŸ¥è¯†
{self.format_domain(knowledge['domain_knowledge'])}

## æ–¹æ³•è®º
{self.format_methodology(knowledge['methodology'])}

## å…ƒè®¤çŸ¥æ´å¯Ÿ
{self.format_metacognitive(knowledge['metacognitive'])}

## ç»éªŒç´¢å¼•
{self.format_experience_index(knowledge['experiences'])}
"""
        
        with open(file_path, 'w') as f:
            f.write(content)
    
    def load_and_query(self, query):
        """ç”¨LLMæŸ¥è¯¢çŸ¥è¯†åº“"""
        
        query_prompt = """
ä»çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ã€‚

## æŸ¥è¯¢
{query}

## çŸ¥è¯†åº“å†…å®¹
{knowledge_content}

## è¿”å›æœ€ç›¸å…³çš„çŸ¥è¯†
"""
        
        return self.llm.complete(query_prompt)
```

## å…ƒè®¤çŸ¥å­¦ä¹ çš„ä¼˜åŠ¿

### 1. ä¸»åŠ¨å­¦ä¹  vs è¢«åŠ¨è®°å½•

**ä¼ ç»Ÿæ–¹å¼**ï¼š
```python
# è¢«åŠ¨è®°å½•
history.append(action)
# ä»»åŠ¡ç»“æŸåæå–
knowledge = extract_from_history(history)
```

**å…ƒè®¤çŸ¥æ–¹å¼**ï¼š
```python
# ä¸»åŠ¨å­¦ä¹ 
insight = monitor_and_learn(action)
immediately_apply(insight)
reflect_and_integrate(insight)
```

### 2. æ·±åº¦ç†è§£ vs è¡¨é¢è®°å¿†

**ä¼ ç»Ÿæ–¹å¼**ï¼š
- è®°å½•å‘ç”Ÿäº†ä»€ä¹ˆ
- ä¿å­˜æˆåŠŸçš„æ­¥éª¤

**å…ƒè®¤çŸ¥æ–¹å¼**ï¼š
- ç†è§£ä¸ºä»€ä¹ˆæˆåŠŸ/å¤±è´¥
- æå–é€šç”¨åŸåˆ™
- å»ºç«‹çŸ¥è¯†è¿æ¥

### 3. è‡ªé€‚åº” vs å›ºå®š

**ä¼ ç»Ÿæ–¹å¼**ï¼š
- å›ºå®šçš„å­¦ä¹ æ¨¡æ¿
- ç»Ÿä¸€çš„çŸ¥è¯†æ ¼å¼

**å…ƒè®¤çŸ¥æ–¹å¼**ï¼š
- LLMå†³å®šå­¦ä»€ä¹ˆ
- LLMå†³å®šå¦‚ä½•ç»„ç»‡
- LLMå†³å®šä¼˜å…ˆçº§

## å®ç°å»ºè®®

### 1. æ¸è¿›å¼æ•´åˆ

```python
# ç¬¬ä¸€æ­¥ï¼šåœ¨ç°æœ‰åŸºç¡€ä¸Šæ·»åŠ å…ƒè®¤çŸ¥
class EnhancedReactAgent(GenericReactAgent):
    def execute_task(self, task):
        # è°ƒç”¨å·²æœ‰çŸ¥è¯†
        self.prepare_with_knowledge(task)
        
        # æ‰§è¡ŒåŸæœ‰é€»è¾‘
        result = super().execute_task(task)
        
        # åæ€å­¦ä¹ 
        self.reflect_and_learn(task, result)
        
        return result
```

### 2. ç»Ÿä¸€çš„çŸ¥è¯†è¡¨ç¤º

```python
# åˆå¹¶ extracted_knowledge.md å’Œå…ƒè®¤çŸ¥æ´å¯Ÿ
knowledge_structure = {
    "factual": {},      # What - äº‹å®
    "procedural": {},   # How - æ–¹æ³•
    "metacognitive": {} # Why/When - å…ƒè®¤çŸ¥
}
```

### 3. æç¤ºè¯æ¨¡æ¿

```python
UNIFIED_LEARNING_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å…ƒè®¤çŸ¥å­¦ä¹ èƒ½åŠ›çš„Agentã€‚

æ‰§è¡Œä»»åŠ¡æ—¶ï¼š
1. å…ˆé—®ï¼šæˆ‘çŸ¥é“ä»€ä¹ˆç›¸å…³çš„ï¼Ÿ
2. æ‰§è¡Œä¸­é—®ï¼šæˆ‘åœ¨å­¦åˆ°ä»€ä¹ˆï¼Ÿ
3. å®Œæˆåé—®ï¼šæˆ‘å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ
4. æœ€åé—®ï¼šè¿™å¦‚ä½•æ”¹å˜æˆ‘çš„è®¤çŸ¥ï¼Ÿ

å°†å­¦ä¹ èå…¥æ‰§è¡Œçš„æ¯ä¸€æ­¥ã€‚
"""
```

## æ€»ç»“

**å­¦ä¹ åº”è¯¥æ˜¯å…ƒè®¤çŸ¥çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†**ï¼Œè€Œä¸æ˜¯ç‹¬ç«‹çš„åŠŸèƒ½ï¼š

1. **å…ƒè®¤çŸ¥åŒ…å«å­¦ä¹ **ï¼šçŸ¥é“è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆâ†’å­¦ä¹ â†’çŸ¥é“äº†
2. **å­¦ä¹ éœ€è¦å…ƒè®¤çŸ¥**ï¼šåæ€ä»€ä¹ˆå€¼å¾—å­¦â†’å¦‚ä½•ç»„ç»‡çŸ¥è¯†â†’ä½•æ—¶åº”ç”¨
3. **ç»Ÿä¸€çš„å¾ªç¯**ï¼šå‡†å¤‡â†’æ‰§è¡Œâ†’ç›‘æ§â†’åæ€â†’æ•´åˆâ†’åº”ç”¨

è¿™ç§æ•´åˆè®©AgentçœŸæ­£å…·å¤‡äº†ï¼š
- **è‡ªæˆ‘æ„è¯†**ï¼šçŸ¥é“è‡ªå·±çš„çŸ¥è¯†è¾¹ç•Œ
- **è‡ªæˆ‘æ”¹è¿›**ï¼šä»ç»éªŒä¸­æŒç»­å­¦ä¹ 
- **è‡ªæˆ‘é€‚åº”**ï¼šæ ¹æ®å­¦åˆ°çš„è°ƒæ•´è¡Œä¸º

æœ€ç»ˆå®ç°ï¼š**ä¸€ä¸ªä¼šæ€è€ƒå¦‚ä½•æ€è€ƒã€ä¼šå­¦ä¹ å¦‚ä½•å­¦ä¹ çš„Agent**ã€‚