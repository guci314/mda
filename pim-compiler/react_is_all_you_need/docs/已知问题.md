# 已知问题

本文档记录了 React Agent 系统中已知的问题和限制。

## 1. 多 Agent 协作中的文件查找问题

### 问题描述
在多 Agent 协作场景中，子 Agent（特别是 code_reviewer）使用 `search_files` 工具时无法找到其他 Agent 创建的文件，即使所有 Agent 配置了相同的工作目录。

### 症状
```
🔧 调用工具: search_files
   参数: {'pattern': 'math_utils.py'}

💬 工具结果 (search_files):
   No files found matching 'math_utils.py' in .
```

### 根本原因
`search_files` 工具默认在当前目录（"."）搜索，而不是在配置的 `work_dir` 中搜索。这导致即使文件存在于共享工作目录中，Agent 也无法找到。

### 当前的变通方案
主协调 Agent 会智能地检测到这个问题，并采用直接传递文件内容的方式：
```python
# 而不是让 reviewer 查找文件
# 直接把代码内容传给 reviewer
code_reviewer({'task': '请评审以下代码并打分（1-10分）：\n\nclass MathUtils:...'})
```

### 已尝试的解决方案
1. **使用绝对路径** - 在所有配置中使用绝对路径，并在 specification 中明确工作目录
2. **添加知识文件** - 创建 `absolute_path_usage.md` 指导 Agent 使用绝对路径
3. **任务描述中包含完整路径** - 明确指定文件的绝对路径

### 解决状态
⚠️ 部分解决 - 已修复工具层面的路径处理，但可能还需要进一步测试

### 已实施的修复
已修改 `tools.py` 中的以下工具，使其能够正确处理绝对路径和相对路径：

1. **write_file** - 现在检测是否传入绝对路径，如果是则直接使用，否则相对于 work_dir
2. **read_file** - 同样支持绝对路径和相对路径
3. **search_files** - directory 参数现在支持绝对路径
4. **list_directory** - 支持绝对路径参数

修复代码示例：
```python
# 检查是否为绝对路径
if Path(file_path).is_absolute():
    file_full_path = Path(file_path)
else:
    file_full_path = Path(work_dir) / file_path
```

### 建议的后续步骤
1. 运行完整的测试用例验证所有工具的路径处理
2. 确保所有 Agent 知识文件中的路径使用指南是最新的
3. 考虑在 Agent 级别添加路径处理的辅助函数

### 影响范围
- 主要影响需要跨 Agent 共享文件的协作场景
- 单个 Agent 独立工作时不受影响
- 通过变通方案可以正常完成任务，但增加了复杂性

### 相关文件
- `/home/guci/aiProjects/mda/pim-compiler/react_is_all_you_need/tools.py` - 工具实现
- `/home/guci/aiProjects/mda/pim-compiler/react_is_all_you_need/demo_agent_coordination_langchain.py` - 问题复现场景

---

## 2. 归档文件的组织问题

### 问题描述
初始实现中，归档文件直接存放在数据目录中，使用 `archive_时间戳_文件名` 的命名方式，导致目录结构混乱。

### 解决状态
✅ 已解决 - 归档文件现在存放在独立的 `archive` 子目录中

### 解决方案
修改了 `_clean_data_directory` 方法，创建专门的归档目录：
```python
archive_dir = self.data_dir / "archive"
archive_dir.mkdir(exist_ok=True)
```

---

## 3. 知识提取中断问题

### 问题描述
程序退出时，异步的知识提取线程可能被中断，导致提取的知识未能保存。

### 解决状态
✅ 已解决 - 使用 `atexit` 和非守护线程确保知识提取完成

### 解决方案
1. 使用非守护线程（`daemon=False`）
2. 注册 `atexit` 处理函数等待所有知识提取线程完成
3. 全局跟踪活跃的知识提取线程

---

## 4. Gemini API 访问不稳定问题

### 问题描述
在中国访问 Gemini API 极其不稳定，经常出现：
- 请求超时
- 连接中断
- 响应延迟过高
- 间歇性服务不可用

### 症状
- Agent 执行任务时长时间无响应
- 任务执行到一半突然中断
- API 调用失败但没有明确的错误处理
- 用户无法判断 Agent 是在思考还是已经卡住

### 影响范围
- 所有使用 Gemini 模型的 Agent
- 特别影响长时间运行的任务
- 多 Agent 协作场景中影响更严重（任何一个 Agent 卡住都会影响整体流程）

### 建议的解决方案

#### 1. 添加元认知层（Metacognitive Layer）
实现一个监控层来：
- 监控每个 API 调用的响应时间
- 检测异常的延迟或无响应状态
- 在检测到问题时主动介入

```python
class MetacognitiveMonitor:
    def __init__(self, timeout_threshold=30, check_interval=5):
        self.timeout_threshold = timeout_threshold
        self.check_interval = check_interval
        self.active_calls = {}
    
    def monitor_api_call(self, call_id, api_func, *args, **kwargs):
        """监控 API 调用，检测超时和卡住情况"""
        start_time = time.time()
        self.active_calls[call_id] = {
            'start_time': start_time,
            'status': 'running',
            'function': api_func.__name__
        }
        
        # 在单独线程中检查超时
        def check_timeout():
            while call_id in self.active_calls:
                elapsed = time.time() - start_time
                if elapsed > self.timeout_threshold:
                    self.handle_timeout(call_id)
                time.sleep(self.check_interval)
        
        Thread(target=check_timeout, daemon=True).start()
```

#### 2. 实现智能重试机制
- 使用指数退避策略
- 在多次失败后自动切换到备用模型
- 保存中间状态以便恢复

#### 3. 添加实时状态反馈
```python
# 定期输出心跳信息
print(f"[{timestamp}] API 调用进行中... 已等待 {elapsed}秒")
print(f"[{timestamp}] 如果长时间无响应，可以按 Ctrl+C 中断并重试")
```

#### 4. 实现断点续传
- 保存任务执行状态
- 支持从中断点恢复执行
- 避免重复已完成的工作

### 临时缓解措施
1. **使用代理服务**
   ```python
   http_client = httpx.Client(
       proxy='socks5://127.0.0.1:7890',
       timeout=30,
       verify=False
   )
   ```

2. **降低并发度**
   - 减少同时运行的 Agent 数量
   - 使用串行执行代替并行执行

3. **选择其他模型**
   - 考虑使用 DeepSeek、OpenAI 等在中国访问更稳定的服务
   - 实现模型自动切换机制

### 相关配置
在 `ReactAgentConfig` 中可以设置：
- `http_client` - 配置代理
- `llm_timeout` - 设置超时时间
- `retry_count` - 重试次数
- `fallback_model` - 备用模型

---

## 5. Agent 基本工具配置问题

### 问题描述
在多 Agent 协作场景中，子 Agent 被创建时往往没有配置基本的文件操作工具（如 read_file、write_file、search_files 等），导致它们无法独立完成文件相关的任务。这类似于计算机的 BIOS 需要配置最小集的 I/O 设备才能正常启动和运行。

### 症状
```
# code_reviewer Agent 尝试读取文件
🔧 调用工具: read_file
   参数: {'file_path': '/path/to/file.py'}

💬 工具结果 (read_file):
   File not found: /path/to/file.py
   
# 实际上是因为 Agent 没有配置基本工具，而不是文件不存在
```

### 根本原因
1. **子 Agent 创建时未配置基本工具集** - 只配置了任务特定的工具
2. **过度依赖主 Agent 传递信息** - 子 Agent 缺乏自主访问文件系统的能力
3. **违背了最小系统原则** - 如同 BIOS 需要基本 I/O，Agent 也需要基本文件操作能力

### 设计原则对比
| 计算机系统 | Agent 系统 | 说明 |
|-----------|-----------|------|
| BIOS | Agent 基础配置 | 提供最小启动环境 |
| 基本 I/O 设备 | 基本工具集 | 文件读写、搜索等 |
| 操作系统 | Agent 知识文件 | 定义高级行为 |
| 应用程序 | 专用工具 | 特定任务能力 |

### 建议的解决方案

#### 1. 定义 Agent 基本工具集
```python
# 每个 Agent 都应该具备的基本工具
AGENT_BASIC_TOOLS = [
    "read_file",      # 读取文件
    "write_file",     # 写入文件
    "search_files",   # 搜索文件
    "list_directory", # 列出目录
]
```

#### 2. 修改 Agent 创建逻辑
```python
# 创建子 Agent 时自动包含基本工具
def create_agent_with_tools(config, name, custom_tools=None):
    # 获取基本工具集
    basic_tools = create_tools(config.work_dir)
    
    # 过滤出必需的基本工具
    essential_tools = [t for t in basic_tools if t.name in AGENT_BASIC_TOOLS]
    
    # 合并自定义工具
    all_tools = essential_tools + (custom_tools or [])
    
    return GenericReactAgent(config, name=name, custom_tools=all_tools)
```

#### 3. 在演示代码中实现
```python
# 为每个子 Agent 配置基本工具
basic_tools = create_tools(str(abs_work_dir))
essential_tools = [t for t in basic_tools if t.name in ["read_file", "write_file", "search_files", "list_directory"]]

# 创建具有基本工具的 code_reviewer
code_review_agent = GenericReactAgent(
    code_review_config, 
    name="code_reviewer",
    custom_tools=essential_tools  # 添加基本工具
)
```

### 影响分析
1. **提高 Agent 自主性** - 子 Agent 可以独立完成文件操作任务
2. **减少协作复杂度** - 不需要主 Agent 传递文件内容
3. **提升系统健壮性** - 每个 Agent 都具备基本生存能力
4. **符合设计原则** - 类似 BIOS 的最小系统设计思想

### 相关文件
- `/home/guci/aiProjects/mda/pim-compiler/react_is_all_you_need/demo_agent_coordination_langchain.py` - 需要修改的演示文件
- `/home/guci/aiProjects/mda/pim-compiler/react_is_all_you_need/react_agent.py` - 可能需要添加默认工具配置

---

## 6. 工作目录安全性问题

### 问题描述
清理工作目录会带来灾难性后果。工作目录代表外部世界（如用户的项目代码库），Agent 如果清理这个目录，可能会删除用户的重要代码、文档和数据。

### 潜在风险
1. **数据丢失** - 删除不可恢复的用户文件
2. **项目损坏** - 破坏项目结构和依赖
3. **信任危机** - 用户将失去对 Agent 系统的信任
4. **法律责任** - 可能因数据损失承担责任

### 解决状态
✅ 已解决 - 已实施多重保护措施

### 已实施的保护措施
1. **工作目录验证** - Agent 初始化时验证工作目录必须存在
2. **禁止清理** - 永久注释掉清理工作目录的代码
3. **目录分离** - Agent 内部状态与工作目录完全隔离

### 建议添加元认知监控
```python
class WorkDirectorySafetyMonitor:
    """元认知层：监控危险的文件操作"""
    
    DANGEROUS_PATTERNS = [
        r'rm\s+-rf',           # 递归删除
        r'shutil\.rmtree',     # Python 递归删除
        r'os\.remove.*\*',     # 批量删除
        r'Path.*unlink.*for',  # 循环删除
    ]
    
    def monitor_operation(self, operation: str, target_path: Path):
        """监控文件操作，阻止危险行为"""
        # 检查是否为批量删除操作
        if any(re.match(pattern, operation) for pattern in self.DANGEROUS_PATTERNS):
            # 检查目标是否为工作目录
            if target_path == self.work_dir or self.work_dir in target_path.parents:
                raise SecurityError(
                    f"危险操作被阻止：尝试在工作目录执行 {operation}\n"
                    "工作目录代表外部世界，不能被清理。"
                )
```

### 相关文件
- `/home/guci/aiProjects/mda/pim-compiler/react_is_all_you_need/WORKDIR_SAFETY.md` - 工作目录安全保证文档
- `/home/guci/aiProjects/mda/pim-compiler/react_is_all_you_need/react_agent.py` - 实施保护的核心代码

---

## 7. 多 Agent 并发访问工作目录的事务问题

### 问题描述
多个 Agent 异步访问工作目录时会出现事务（transaction）问题，可能导致：
- 文件写入冲突
- 读取到不完整的文件
- 更新丢失
- 竞态条件

### 典型场景
```python
# Agent A 和 Agent B 同时修改同一个文件
# Agent A: 读取文件 -> 修改内容 -> 写入文件
# Agent B: 读取文件 -> 修改内容 -> 写入文件
# 结果：Agent A 的修改可能被 Agent B 覆盖
```

### 影响范围
- 多 Agent 协作场景
- 并行任务执行
- 共享资源访问
- 文件密集型操作

### 建议的解决方案

#### 1. 实现乐观锁机制
```python
class OptimisticFileLock:
    """基于文件版本的乐观锁"""
    
    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.version_file = file_path.with_suffix(file_path.suffix + '.version')
    
    def read_with_version(self) -> Tuple[str, int]:
        """读取文件内容和版本号"""
        content = self.file_path.read_text()
        version = self._get_version()
        return content, version
    
    def write_with_version_check(self, content: str, expected_version: int):
        """只有版本匹配时才写入"""
        current_version = self._get_version()
        if current_version != expected_version:
            raise VersionConflictError(
                f"文件已被其他 Agent 修改。"
                f"期望版本: {expected_version}, 当前版本: {current_version}"
            )
        
        # 原子性写入
        temp_file = self.file_path.with_suffix('.tmp')
        temp_file.write_text(content)
        temp_file.replace(self.file_path)
        
        # 更新版本
        self._increment_version()
```

#### 2. 实现悲观锁机制
```python
class PessimisticFileLock:
    """基于文件锁的悲观锁"""
    
    def __init__(self, file_path: Path, agent_name: str):
        self.file_path = file_path
        self.lock_file = file_path.with_suffix('.lock')
        self.agent_name = agent_name
    
    def acquire_lock(self, timeout: float = 30):
        """获取文件锁"""
        start_time = time.time()
        while self.lock_file.exists():
            if time.time() - start_time > timeout:
                # 检查锁是否已过期
                lock_info = json.loads(self.lock_file.read_text())
                if time.time() - lock_info['timestamp'] > 60:  # 60秒过期
                    self.lock_file.unlink()  # 删除过期锁
                    break
                raise LockTimeoutError(f"无法获取锁：{self.file_path}")
            time.sleep(0.1)
        
        # 创建锁文件
        lock_info = {
            'agent': self.agent_name,
            'timestamp': time.time(),
            'pid': os.getpid()
        }
        self.lock_file.write_text(json.dumps(lock_info))
    
    def release_lock(self):
        """释放文件锁"""
        if self.lock_file.exists():
            self.lock_file.unlink()
```

#### 3. 工具层集成
```python
# 修改 write_file 工具以支持并发控制
@tool
def write_file(file_path: str, content: str, use_lock: bool = True) -> str:
    """写入文件（支持并发控制）"""
    if use_lock:
        lock = PessimisticFileLock(Path(file_path), agent_name)
        try:
            lock.acquire_lock()
            # 执行写入
            Path(file_path).write_text(content)
            return "文件写入成功"
        finally:
            lock.release_lock()
    else:
        # 不使用锁的原始写入
        Path(file_path).write_text(content)
        return "文件写入成功（无锁）"
```

### 设计考虑
1. **性能 vs 安全** - 乐观锁性能更好，悲观锁更安全
2. **死锁预防** - 实现锁超时和自动释放机制
3. **向后兼容** - 保持现有 API，通过参数控制锁行为
4. **监控和日志** - 记录锁冲突和等待时间

### 实施优先级
1. 先实现悲观锁（更简单、更安全）
2. 在性能关键场景引入乐观锁
3. 提供配置选项让用户选择锁策略

### 相关组件
- `tools.py` - 需要修改文件操作工具
- `react_agent.py` - 可能需要添加并发控制配置
- 新文件 `file_locks.py` - 实现锁机制

---

## 贡献指南

如果你发现新的问题，请：
1. 在此文档中添加详细描述
2. 包含复现步骤
3. 记录任何已尝试的解决方案
4. 如果问题已解决，更新状态并说明解决方案