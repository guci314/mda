# 理性主义与经验主义：大语言模型的两种认知架构

## 摘要

本文探讨了大语言模型（LLM）架构中的一个基本二分法：对话式 LLM 中盛行的经验主义工作流与推理专用模型中出现的理性主义工作流。通过实证观察和理论分析，我们证明了训练方法从根本上塑造了模型的认知模式，进而决定了最优的工作流表示形式。研究发现，对话式 LLM 自然地遵循经验主义认知模式——通过行动和观察获得知识，而推理模型则表现出理性主义倾向——通过纯粹推理构建完整理论后再执行。这一区别对多智能体系统设计和工作流自动化具有深远影响。

## 1. 引言

大语言模型的快速发展产生了两种截然不同的架构哲学：为交互式对话优化的对话模型（如 GPT-4、Claude）和为深度分析思考训练的推理模型（如 OpenAI o1、DeepSeek-R1）。虽然两种架构都基于 Transformer，但在面对复杂的多步任务时，它们的行为模式显著不同。

这种分歧在一个实际实验中变得明显：为多智能体协调实现 BPMN（业务流程模型和符号）工作流。该工作流需要代码生成、测试和带有重试逻辑的审查，在对话式 LLM 上彻底失败，但在推理模型上自然成功。这一观察引发了对底层认知架构的深入研究。

## 2. 对话式 LLM 中的经验主义范式

### 2.1 理论基础

经验主义工作流（源于 Yao 等人 2022 年提出的 React 框架）体现了通过经验获得知识的哲学传统。这种模式反映了人类通过试错学习的自然方式：

```
思考 → 行动 → 观察 → 思考 → ...
```

### 2.2 在对话模型中的自然涌现

对话式 LLM 自然表现出经验主义模式，因为：

1. **自回归本质**：逐令牌生成鼓励增量决策
2. **交互式训练**：RLHF（基于人类反馈的强化学习）奖励响应性、适应性行为
3. **有限的上下文窗口**：鼓励将问题分解为可管理的块
4. **即时反馈循环**：工具使用和用户交互提供持续的环境信号

### 2.3 实证证据

在我们的 BPMN 实验中，对话式 LLM：
- 创建了工作流文件但未能更新执行状态
- 丢失了重试计数器和循环条件的跟踪
- 在多个工具调用中难以维护全局状态
- 默认立即行动而非全面规划

## 3. 推理模型中的理性主义范式

### 3.1 架构差异

推理模型引入了根本性的架构变化：

```
内部推理阶段 → 完整计划形成 → 执行
```

这种分离通过以下方式强制执行：
1. **专用思考令牌**：在可见输出之前的隐藏推理轨迹
2. **奖励塑造**：仅奖励最终答案正确性的强化学习训练
3. **扩展计算**：能够在不输出的情况下"思考"较长时间

### 3.2 认知含义

理性主义范式创造了这样的模型：
- 在行动前构建完整的心智模型
- 在复杂工作流中保持一致的状态
- 擅长符号操作和形式推理
- 自然地与声明式规范（如 BPMN）对齐

### 3.3 实证成功

DeepSeek-Reasoner 成功执行了相同的 BPMN 工作流，通过：
- 在工作记忆中维护完整的工作流状态
- 内部跟踪所有变量和条件
- 遵循复杂的分支逻辑而无需外部状态管理
- 将 BPMN 视为要解释的声明式规范

## 4. 比较分析

### 4.1 认知架构比较

| 方面 | 经验主义（对话式） | 理性主义（推理式） |
|------|----------------|-------------------|
| 思考方式 | 与行动交织 | 前置加载 |
| 状态管理 | 外部/环境 | 内部/心智 |
| 错误处理 | 反应式适应 | 预防性规划 |
| 工作流亲和力 | 自然语言、基于意图 | 符号化、形式规范 |
| 优势 | 动态环境 | 静态、定义明确的问题 |
| 劣势 | 复杂状态跟踪 | 实时适应 |

### 4.2 工作流模式匹配

我们的实验揭示了一个清晰的模式：

**自然对齐：**
- 对话式 LLM + 意图声明工作流 ✓
- 对话式 LLM + 叙事/剧本工作流 ✓
- 推理模型 + BPMN/状态机 ✓
- 推理模型 + 形式规范 ✓

**不匹配：**
- 对话式 LLM + BPMN ✗
- 推理模型 + 高度交互任务 ✗

## 5. 对多智能体系统的启示

### 5.1 智能体选择策略

根据任务特征选择智能体：
- **动态、探索性任务** → 使用经验主义模式的对话式 LLM
- **定义明确的复杂工作流** → 使用理性主义模式的推理模型

### 5.2 工作流设计原则

对于对话式 LLM：
```markdown
# 基于意图的工作流
目标：创建经过测试的高质量代码
约束：最多 3 次重试
期望：带有质量评分的工作代码
```

对于推理模型：
```xml
<!-- BPMN 工作流 -->
<process id="codeGenProcess">
  <serviceTask id="generate" implementation="code_generator"/>
  <exclusiveGateway id="testResult">
    <outgoing>passed</outgoing>
    <outgoing>failed</outgoing>
  </exclusiveGateway>
  <!-- 完整规范... -->
</process>
```

### 5.3 混合架构

未来的系统可能结合两种范式：
1. **推理模型用于规划** → 生成详细的执行计划
2. **对话模型用于执行** → 处理动态交互
3. **模式切换** → 根据任务阶段动态选择范式

## 6. 相关工作

- **ReAct（Yao 等，2022）**：在 LLM 中建立了推理-行动协同
- **思维链（Wei 等，2022）**：展示了大模型中的涌现推理
- **宪法 AI（Anthropic，2022）**：展示了训练如何塑造模型行为
- **AI 中的过程挖掘（van der Aalst，2016）**：形式化工作流表示

## 7. 局限性和未来工作

### 7.1 当前局限性

1. **二元分类**：模型可能表现出混合行为
2. **任务依赖性**：某些任务可能受益于范式切换
3. **样本量有限**：基于特定模型实现

### 7.2 未来方向

1. **范式检测**：自动分类模型认知模式
2. **自适应工作流**：根据模型类型调整表示的系统
3. **训练方法**：探索混合行为的训练技术
4. **基准开发**：经验主义 vs 理性主义能力的标准化测试

## 8. 结论

LLM 中经验主义和理性主义范式之间的区别不仅仅是学术性的——它对系统设计具有实际意义。我们的主要发现：

1. **训练塑造认知**：RLHF 培养经验主义思维；延迟奖励的 RL 培养理性主义思维
2. **工作流对齐很重要**：将工作流风格与模型范式匹配可显著提高成功率
3. **没有普遍最优**：每种范式在不同环境中表现出色
4. **未来是混合的**：结合范式可能产生更强大的系统

BPMN 在对话式 LLM 上的失败不是限制而是特性——这些模型针对动态、交互式问题解决进行了优化，而不是刚性的工作流执行。认识并接受这些根本差异可以实现更有效的 AI 系统设计。

