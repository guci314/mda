# 自然语言工作流可选方案

## 背景

传统的符号主义工作流（如 BPMN、LangGraph）对语言模型来说过于形式化和复杂。我们需要更自然、更符合 LLM 理解方式的工作流表达方法。

以下是三个可选方案，按照自然性从高到低排列。

## 方案一：剧本式工作流（Script-based Workflow）【推荐】

### 核心理念
像编写剧本或故事一样描述工作流程，使用角色、场景、对话等自然叙事元素。

### 示例

```markdown
# MathUtils 开发剧本

场景：创建一个可靠的数学工具类

角色分配：
- 代码生成器：负责编写代码
- 测试运行器：负责验证质量
- 代码审查员：负责最终评分

剧情发展：
1. 代码生成器创建 MathUtils 类
2. 测试运行器验证功能
   - 如果测试失败 → 告诉代码生成器具体错误，重试（最多3次）
   - 如果测试通过 → 继续下一步
3. 代码审查员给出质量评分

记住：保持对话简洁，专注于结果。
```

### 优势
- **最自然**：符合人类讲故事的天性
- **角色清晰**：每个 Agent 的职责一目了然
- **灵活性高**：可以根据情况即兴调整
- **易于理解**：新手也能快速上手

### 劣势
- **执行一致性**：不同 LLM 可能有不同理解
- **状态追踪**：需要从上下文推断当前进度

### 适用场景
- 多 Agent 协作任务
- 需要创造性解决方案的场景
- 复杂度中等的工作流

## 方案二：对话式工作流（Conversational Workflow）

### 核心理念
通过模拟真实对话来驱动工作流，就像项目经理在协调团队。

### 示例

```markdown
# MathUtils 开发对话

你是项目经理，请按以下对话模式协调团队：

对代码生成器说："请创建 MathUtils 类，包含基本数学运算。"
等待回复...

对测试运行器说："请验证刚创建的代码是否正确。"
等待回复...

如果测试失败：
  记下错误（尝试次数+1）
  对代码生成器说："测试失败了，错误是[具体错误]，请修复。"
  重复测试（最多3次）

如果测试成功：
  对代码审查员说："请评审代码质量。"

结束对话，汇总结果。
```

### 优势
- **直观明了**：像真实对话一样自然
- **反馈即时**：每步都有明确的输入输出
- **易于调试**：可以看到每轮对话内容

### 劣势
- **冗长**：对话形式可能导致内容冗余
- **效率**：步骤之间的等待可能降低效率

### 适用场景
- 需要详细反馈的任务
- 交互式的开发流程
- 教学或演示场景

## 方案三：意图声明式工作流（Intent Declaration Workflow）【最React】

### 核心理念
通过声明意图和约束条件，让 Agent 自主推理和行动。这种方式最符合 React（Reasoning + Acting）模式，因为它鼓励 LLM 进行思考-行动-观察的循环。

### 示例

```markdown
# MathUtils 开发意图

**目标**：获得一个高质量的、经过充分测试的 MathUtils 类

**约束条件**：
- 代码必须通过所有测试
- 如果测试失败，允许最多3次修复机会
- 最终代码需要通过质量审查

**期望结果**：
- 一个可靠的 MathUtils.py 文件
- 所有测试通过的证明
- 代码质量评分和改进建议

**授权**：
- 可以让代码生成器多次尝试
- 可以要求具体的错误修复
- 可以决定何时停止尝试

请根据这些意图，协调各个专家Agent完成任务。
```

### 为什么最适合 LLM

1. **符合 ReAct 模式**
   - **Reasoning**：LLM 根据意图推理下一步
   - **Acting**：执行具体动作（调用工具）
   - **Observing**：观察结果并调整策略

2. **自主性最强**
   - 不需要预定义详细步骤
   - LLM 可以根据情况灵活调整
   - 鼓励创造性解决方案

3. **上下文理解**
   - 意图提供了"为什么"
   - 约束提供了"边界"
   - 结果提供了"目标"

### 优势
- **最灵活**：完全由 LLM 决定执行路径
- **最自然**：像给人类下达任务一样
- **适应性强**：可以处理意外情况
- **减少微管理**：专注于结果而非过程

### 劣势
- **一致性挑战**：不同 LLM 可能有不同执行方式
- **调试困难**：执行路径不可预测
- **需要强大 LLM**：对模型能力要求较高

### 适用场景
- 复杂的、需要创造性的任务
- 情况多变的动态环境
- 信任 LLM 能力的场景

## 方案四：状态机式工作流（State Machine Workflow）

### 核心理念
使用状态和转换规则来描述工作流，保持清晰的状态感知。

### 示例

```markdown
# MathUtils 开发状态机

当前状态：开始
目标状态：完成

状态转换规则：
- 开始 → 生成代码
- 生成代码 → 测试代码
- 测试代码 → [成功] → 审查代码 → 完成
- 测试代码 → [失败且次数<3] → 修复代码 → 测试代码
- 测试代码 → [失败且次数>=3] → 失败结束

执行时保持状态感知：
"我现在在[当前状态]，下一步是[动作]"
```

### 优势
- **状态清晰**：始终知道当前位置
- **路径明确**：转换条件一目了然
- **可追踪**：容易记录和回溯

### 劣势
- **略显形式化**：比前两种方案更接近符号系统
- **灵活性受限**：状态必须预先定义

### 适用场景
- 有明确步骤的流程
- 需要严格状态管理的任务
- 自动化程度高的工作流

## 混合方案：故事+检查清单

实践中，可以结合多种方案的优势：

```markdown
# MathUtils 开发任务

## 故事背景
你是一个项目经理，需要协调团队创建一个数学工具类。

## 执行清单
□ 让代码生成器创建 MathUtils 类
□ 让测试运行器验证代码
□ 如果测试失败：
  □ 记录错误信息
  □ 检查重试次数（最多3次）
  □ 让代码生成器修复
□ 如果测试成功：
  □ 让代码审查员评分
□ 总结并报告结果

## 注意事项
- 保持专业但友好的沟通
- 出错时提供具体信息
- 完成后给出简洁总结
```

## 实施建议

1. **从简单开始**：先用剧本式工作流验证概念
2. **逐步优化**：根据实际效果调整表达方式
3. **保持自然**：避免过度形式化
4. **注重结果**：关注任务完成而非流程完美

## 选择指南

- **创造性任务** → 意图声明式工作流（最 React）
- **团队协作** → 剧本式工作流
- **标准化流程** → 检查清单式工作流
- **复杂决策树** → 状态机式工作流
- **交互式开发** → 对话式工作流

## React 模式的深入思考

语言模型天生适合 React（Reasoning + Acting）模式，因为：

1. **思维链自然**：LLM 本身就是通过 token 序列进行推理
2. **上下文感知**：能够理解意图并据此行动
3. **自我纠正**：观察结果后可以调整策略
4. **涌现能力**：复杂行为从简单规则中涌现

### React 工作流示例

```markdown
# React 模式任务

**意图**：创建并验证一个数学工具类

**React 循环**：
1. 思考：我需要什么？→ 一个包含基本运算的类
2. 行动：调用代码生成器
3. 观察：代码已生成
4. 思考：代码质量如何？→ 需要测试
5. 行动：调用测试运行器
6. 观察：测试失败，错误是 X
7. 思考：如何修复？→ 错误提示需要处理边界情况
8. 行动：调用代码生成器修复
...循环直到满足所有约束
```

## 实践建议

1. **意图优先**：如果 LLM 能力强（如 GPT-4、Claude），优先使用意图声明式
2. **逐步降级**：如果效果不稳定，可以逐步增加结构：
   - 意图声明 → 剧本式 → 对话式 → 状态机
3. **混合使用**：
   - 用意图声明定义"什么"
   - 用剧本式描述"如何"
   - 用检查清单追踪"进度"

## 总结

自然语言工作流的核心是让 LLM 能够像人类一样理解和执行任务。**意图声明式工作流**最符合 LLM 的 React 本质，因为它：
- 给予最大自主权
- 鼓励推理和适应
- 减少不必要的约束
- 让 LLM 发挥最大潜力

建议从意图声明式开始，如果需要更多可预测性，再逐步增加结构。记住：**最好的工作流是 LLM 能够自然理解和执行的工作流**。