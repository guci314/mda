#!/usr/bin/env python3
"""
Gemma 270M æ¡ä»¶åå°„ç³»ç»Ÿ
ä½¿ç”¨å°æ¨¡å‹æ„å»ºå¿«é€Ÿå“åº”çš„æ¡ä»¶åå°„æœºåˆ¶

æ ¸å¿ƒç†å¿µï¼š
- æ¡ä»¶åå°„ = æ¨¡å¼è¯†åˆ« + å³æ—¶å“åº”
- å°æ¨¡å‹ = å¿«é€Ÿååº” + ä½èµ„æºå ç”¨
- ç±»ä¼¼ç”Ÿç‰©ç¥ç»åå°„å¼§ï¼šæ„Ÿå—å™¨â†’ä¼ å…¥ç¥ç»â†’ä¸­æ¢â†’ä¼ å‡ºç¥ç»â†’æ•ˆåº”å™¨
"""

import os
import re
import json
import time
import threading
from typing import Dict, List, Tuple, Optional, Callable
from dataclasses import dataclass
from collections import deque
from datetime import datetime

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM


@dataclass
class Reflex:
    """æ¡ä»¶åå°„å®šä¹‰"""
    pattern: str  # è§¦å‘æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
    response: str  # å“åº”æ¨¡æ¿
    priority: int = 0  # ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
    learning_rate: float = 0.1  # å­¦ä¹ ç‡
    threshold: float = 0.8  # è§¦å‘é˜ˆå€¼
    count: int = 0  # è§¦å‘æ¬¡æ•°
    last_triggered: Optional[float] = None  # ä¸Šæ¬¡è§¦å‘æ—¶é—´


class GemmaReflexSystem:
    """åŸºäºGemma 270Mçš„æ¡ä»¶åå°„ç³»ç»Ÿ"""

    def __init__(self, model_id: str = "unsloth/gemma-3-270m-it"):
        """åˆå§‹åŒ–åå°„ç³»ç»Ÿ"""
        self.model_id = model_id
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # åå°„åº“
        self.reflexes: Dict[str, Reflex] = {}

        # åå°„å†å²ï¼ˆç”¨äºå­¦ä¹ ï¼‰
        self.reflex_history = deque(maxlen=100)

        # æ¨¡å‹å’Œåˆ†è¯å™¨
        self.model = None
        self.tokenizer = None

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_triggers": 0,
            "avg_response_time": 0,
            "fastest_response": float('inf'),
            "slowest_response": 0
        }

        # åˆå§‹åŒ–å†…ç½®åå°„
        self._init_builtin_reflexes()

    def _init_builtin_reflexes(self):
        """åˆå§‹åŒ–å†…ç½®æ¡ä»¶åå°„"""

        # é—®å€™åå°„
        self.add_reflex(
            "greeting",
            pattern=r"(ä½ å¥½|hello|hi|æ—©ä¸Šå¥½|æ™šä¸Šå¥½)",
            response="ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
            priority=10
        )

        # ç´§æ€¥åå°„
        self.add_reflex(
            "emergency",
            pattern=r"(ç´§æ€¥|urgent|help|æ•‘å‘½|å±é™©)",
            response="æ£€æµ‹åˆ°ç´§æ€¥æƒ…å†µï¼ç«‹å³å“åº”ï¼š",
            priority=100
        )

        # æ•°å­¦åå°„
        self.add_reflex(
            "math",
            pattern=r"(\d+)\s*[\+\-\*\/]\s*(\d+)",
            response="è®¡ç®—ç»“æœï¼š",
            priority=5
        )

        # æ—¶é—´åå°„
        self.add_reflex(
            "time",
            pattern=r"(ç°åœ¨å‡ ç‚¹|what time|å½“å‰æ—¶é—´)",
            response=f"å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%H:%M:%S')}",
            priority=8
        )

        # æƒ…ç»ªåå°„
        self.add_reflex(
            "emotion",
            pattern=r"(å¼€å¿ƒ|å¿«ä¹|é«˜å…´|sad|happy|angry)",
            response="æˆ‘æ„Ÿå—åˆ°äº†ä½ çš„æƒ…ç»ªï¼Œ",
            priority=6
        )

    def load_model(self):
        """åŠ è½½Gemmaæ¨¡å‹"""
        print("âš¡ åŠ è½½Gemma 270Måå°„æ¨¡å‹...")

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)

        if self.device == "cpu":
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_id,
                torch_dtype=torch.float32
            )
        else:
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16
            )

        self.model = self.model.to(self.device)
        self.model.eval()

        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device})")

    def add_reflex(self, name: str, pattern: str, response: str,
                   priority: int = 0, threshold: float = 0.8):
        """æ·»åŠ æ¡ä»¶åå°„"""
        self.reflexes[name] = Reflex(
            pattern=pattern,
            response=response,
            priority=priority,
            threshold=threshold
        )
        print(f"â• æ·»åŠ åå°„: {name} (ä¼˜å…ˆçº§: {priority})")

    def remove_reflex(self, name: str):
        """ç§»é™¤æ¡ä»¶åå°„"""
        if name in self.reflexes:
            del self.reflexes[name]
            print(f"â– ç§»é™¤åå°„: {name}")

    def detect_trigger(self, input_text: str) -> List[Tuple[str, Reflex, float]]:
        """æ£€æµ‹è§¦å‘çš„åå°„"""
        triggered = []

        for name, reflex in self.reflexes.items():
            match = re.search(reflex.pattern, input_text, re.IGNORECASE)
            if match:
                # è®¡ç®—åŒ¹é…å¼ºåº¦
                match_strength = len(match.group()) / len(input_text)

                # åŸºäºå†å²è°ƒæ•´å¼ºåº¦
                if reflex.count > 0:
                    match_strength *= (1 + reflex.learning_rate * min(reflex.count, 10))

                if match_strength >= reflex.threshold:
                    triggered.append((name, reflex, match_strength))

        # æŒ‰ä¼˜å…ˆçº§å’ŒåŒ¹é…å¼ºåº¦æ’åº
        triggered.sort(key=lambda x: (x[1].priority, x[2]), reverse=True)

        return triggered

    def execute_reflex(self, reflex: Reflex, input_text: str) -> str:
        """æ‰§è¡Œæ¡ä»¶åå°„"""
        start_time = time.time()

        # æ›´æ–°åå°„ç»Ÿè®¡
        reflex.count += 1
        reflex.last_triggered = time.time()

        # ç‰¹æ®Šå¤„ç†æ•°å­¦åå°„
        if "è®¡ç®—ç»“æœ" in reflex.response:
            match = re.search(r"(\d+)\s*([\+\-\*\/])\s*(\d+)", input_text)
            if match:
                a, op, b = int(match.group(1)), match.group(2), int(match.group(3))
                result = eval(f"{a}{op}{b}")
                response = f"{reflex.response}{result}"
            else:
                response = reflex.response
        else:
            response = reflex.response

        # è®°å½•å“åº”æ—¶é—´
        response_time = time.time() - start_time
        self._update_stats(response_time)

        return response

    def generate_response(self, input_text: str, use_model: bool = True) -> str:
        """ç”Ÿæˆå“åº”ï¼ˆç»“åˆåå°„å’Œæ¨¡å‹ï¼‰"""

        # 1. æ£€æŸ¥æ¡ä»¶åå°„
        triggered = self.detect_trigger(input_text)

        if triggered:
            # æ‰§è¡Œæœ€é«˜ä¼˜å…ˆçº§çš„åå°„
            name, reflex, strength = triggered[0]
            reflex_response = self.execute_reflex(reflex, input_text)

            print(f"âš¡ è§¦å‘åå°„: {name} (å¼ºåº¦: {strength:.2f})")

            # å¦‚æœéœ€è¦ï¼Œä½¿ç”¨æ¨¡å‹å¢å¼ºå“åº”
            if use_model and self.model and "ï¼š" in reflex_response:
                enhanced = self._enhance_with_model(
                    input_text,
                    reflex_response
                )
                return f"{reflex_response}{enhanced}"

            return reflex_response

        # 2. å¦‚æœæ²¡æœ‰è§¦å‘åå°„ï¼Œä½¿ç”¨æ¨¡å‹ç”Ÿæˆ
        if use_model and self.model:
            return self._model_generate(input_text)

        return "æ²¡æœ‰åŒ¹é…çš„åå°„ï¼Œä¹Ÿæ²¡æœ‰åŠ è½½æ¨¡å‹ã€‚"

    def _enhance_with_model(self, input_text: str, reflex_response: str,
                           max_length: int = 50) -> str:
        """ä½¿ç”¨æ¨¡å‹å¢å¼ºåå°„å“åº”"""
        prompt = f"ç”¨æˆ·ï¼š{input_text}\nç³»ç»Ÿåå°„ï¼š{reflex_response}\nå¢å¼ºå“åº”ï¼š"

        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)

        with torch.no_grad():
            outputs = self.model.generate(
                inputs.input_ids,
                max_new_tokens=max_length,
                temperature=0.3,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )

        response = self.tokenizer.decode(
            outputs[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )

        return response

    def _model_generate(self, input_text: str, max_length: int = 100) -> str:
        """çº¯æ¨¡å‹ç”Ÿæˆ"""
        prompt = f"ç”¨æˆ·ï¼š{input_text}\nåŠ©æ‰‹ï¼š"

        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)

        with torch.no_grad():
            outputs = self.model.generate(
                inputs.input_ids,
                max_new_tokens=max_length,
                temperature=0.7,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )

        response = self.tokenizer.decode(
            outputs[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )

        return response

    def _update_stats(self, response_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.stats["total_triggers"] += 1

        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        n = self.stats["total_triggers"]
        old_avg = self.stats["avg_response_time"]
        self.stats["avg_response_time"] = (old_avg * (n-1) + response_time) / n

        # æ›´æ–°æœ€å¿«/æœ€æ…¢
        self.stats["fastest_response"] = min(
            self.stats["fastest_response"],
            response_time
        )
        self.stats["slowest_response"] = max(
            self.stats["slowest_response"],
            response_time
        )

    def learn_from_feedback(self, reflex_name: str, positive: bool):
        """ä»åé¦ˆä¸­å­¦ä¹ ï¼Œè°ƒæ•´åå°„å‚æ•°"""
        if reflex_name in self.reflexes:
            reflex = self.reflexes[reflex_name]

            if positive:
                # æ­£åé¦ˆï¼šé™ä½é˜ˆå€¼ï¼Œæé«˜ä¼˜å…ˆçº§
                reflex.threshold = max(0.5, reflex.threshold - 0.05)
                reflex.priority = min(100, reflex.priority + 1)
            else:
                # è´Ÿåé¦ˆï¼šæé«˜é˜ˆå€¼ï¼Œé™ä½ä¼˜å…ˆçº§
                reflex.threshold = min(1.0, reflex.threshold + 0.05)
                reflex.priority = max(0, reflex.priority - 1)

            print(f"ğŸ“ˆ å­¦ä¹ æ›´æ–°: {reflex_name}")
            print(f"   æ–°é˜ˆå€¼: {reflex.threshold:.2f}")
            print(f"   æ–°ä¼˜å…ˆçº§: {reflex.priority}")

    def train_reflex(self, examples: List[Tuple[str, str]], name: str):
        """è®­ç»ƒæ–°çš„æ¡ä»¶åå°„"""
        print(f"ğŸ¯ è®­ç»ƒæ–°åå°„: {name}")

        # æå–æ¨¡å¼
        patterns = []
        for input_text, expected_response in examples:
            # ç®€å•çš„æ¨¡å¼æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥æ›´å¤æ‚ï¼‰
            words = input_text.lower().split()
            pattern = "|".join(words[:2])  # ä½¿ç”¨å‰ä¸¤ä¸ªè¯ä½œä¸ºæ¨¡å¼
            patterns.append(pattern)

        # åˆ›å»ºç»Ÿä¸€æ¨¡å¼
        unified_pattern = f"({')|(').join(set(patterns))})"

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå“åº”ä½œä¸ºæ¨¡æ¿
        response_template = examples[0][1]

        # æ·»åŠ æ–°åå°„
        self.add_reflex(
            name=name,
            pattern=unified_pattern,
            response=response_template,
            priority=5
        )

        print(f"âœ… è®­ç»ƒå®Œæˆ: æ¨¡å¼='{unified_pattern[:50]}...'")

    def print_stats(self):
        """æ‰“å°æ€§èƒ½ç»Ÿè®¡"""
        print("\nğŸ“Š åå°„ç³»ç»Ÿç»Ÿè®¡")
        print("=" * 40)
        print(f"æ€»è§¦å‘æ¬¡æ•°: {self.stats['total_triggers']}")
        print(f"å¹³å‡å“åº”æ—¶é—´: {self.stats['avg_response_time']*1000:.2f}ms")

        if self.stats['fastest_response'] != float('inf'):
            print(f"æœ€å¿«å“åº”: {self.stats['fastest_response']*1000:.2f}ms")
            print(f"æœ€æ…¢å“åº”: {self.stats['slowest_response']*1000:.2f}ms")

        print("\nåå°„ä½¿ç”¨é¢‘ç‡:")
        for name, reflex in sorted(
            self.reflexes.items(),
            key=lambda x: x[1].count,
            reverse=True
        ):
            if reflex.count > 0:
                print(f"  {name}: {reflex.count}æ¬¡")


class ReflexMonitor:
    """åå°„ç›‘æ§å™¨ - å®æ—¶ç›‘æ§å’Œè§¦å‘åå°„"""

    def __init__(self, reflex_system: GemmaReflexSystem):
        self.system = reflex_system
        self.running = False
        self.monitor_thread = None

        # äº‹ä»¶é˜Ÿåˆ—
        self.event_queue = deque(maxlen=50)

        # ç›‘å¬å™¨
        self.listeners: List[Callable] = []

    def add_listener(self, callback: Callable):
        """æ·»åŠ äº‹ä»¶ç›‘å¬å™¨"""
        self.listeners.append(callback)

    def trigger_event(self, event_type: str, data: str):
        """è§¦å‘äº‹ä»¶"""
        event = {
            "type": event_type,
            "data": data,
            "timestamp": time.time()
        }

        self.event_queue.append(event)

        # å¤„ç†äº‹ä»¶
        response = self.system.generate_response(data, use_model=False)

        # é€šçŸ¥ç›‘å¬å™¨
        for listener in self.listeners:
            listener(event, response)

        return response

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
        print("ğŸ” åå°„ç›‘æ§å™¨å·²å¯åŠ¨")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("ğŸ›‘ åå°„ç›‘æ§å™¨å·²åœæ­¢")

    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            # è¿™é‡Œå¯ä»¥æ·»åŠ å„ç§è§¦å‘æº
            # ä¾‹å¦‚ï¼šæ–‡ä»¶å˜åŒ–ã€ç½‘ç»œè¯·æ±‚ã€ä¼ æ„Ÿå™¨æ•°æ®ç­‰
            time.sleep(0.1)


def demo_basic_reflexes():
    """æ¼”ç¤ºåŸºç¡€æ¡ä»¶åå°„"""
    print("\n" + "="*50)
    print("ğŸ§ª åŸºç¡€æ¡ä»¶åå°„æ¼”ç¤º")
    print("="*50)

    # åˆ›å»ºåå°„ç³»ç»Ÿ
    system = GemmaReflexSystem()

    # æµ‹è¯•è¾“å…¥
    test_inputs = [
        "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "ç´§æ€¥ï¼éœ€è¦å¸®åŠ©ï¼",
        "100 + 200",
        "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ",
        "æˆ‘å¾ˆå¼€å¿ƒï¼",
        "è¿™ä¸ªä¸ä¼šè§¦å‘ä»»ä½•åå°„"
    ]

    for input_text in test_inputs:
        print(f"\nè¾“å…¥: {input_text}")
        response = system.generate_response(input_text, use_model=False)
        print(f"å“åº”: {response}")

    # æ‰“å°ç»Ÿè®¡
    system.print_stats()


def demo_learning():
    """æ¼”ç¤ºå­¦ä¹ æœºåˆ¶"""
    print("\n" + "="*50)
    print("ğŸ§  æ¡ä»¶åå°„å­¦ä¹ æ¼”ç¤º")
    print("="*50)

    system = GemmaReflexSystem()

    # è®­ç»ƒæ–°åå°„
    examples = [
        ("æŸ¥çœ‹å¤©æ°”", "æ­£åœ¨æŸ¥è¯¢å¤©æ°”ä¿¡æ¯..."),
        ("å¤©æ°”é¢„æŠ¥", "æ­£åœ¨æŸ¥è¯¢å¤©æ°”ä¿¡æ¯..."),
        ("ä»Šå¤©å¤©æ°”", "æ­£åœ¨æŸ¥è¯¢å¤©æ°”ä¿¡æ¯...")
    ]

    system.train_reflex(examples, "weather")

    # æµ‹è¯•æ–°åå°„
    print("\næµ‹è¯•æ–°å­¦ä¹ çš„åå°„:")
    test = "æŸ¥çœ‹å¤©æ°”æƒ…å†µ"
    print(f"è¾“å…¥: {test}")
    print(f"å“åº”: {system.generate_response(test, use_model=False)}")

    # å­¦ä¹ è°ƒæ•´
    print("\nå­¦ä¹ è°ƒæ•´æ¼”ç¤º:")
    system.learn_from_feedback("weather", positive=True)
    system.learn_from_feedback("greeting", positive=False)


def demo_with_model():
    """æ¼”ç¤ºæ¨¡å‹å¢å¼ºçš„æ¡ä»¶åå°„"""
    print("\n" + "="*50)
    print("ğŸ¤– æ¨¡å‹å¢å¼ºæ¡ä»¶åå°„æ¼”ç¤º")
    print("="*50)

    system = GemmaReflexSystem()

    print("\nåŠ è½½æ¨¡å‹ä¸­...")
    system.load_model()

    # æµ‹è¯•æ··åˆå“åº”
    test_inputs = [
        "ç´§æ€¥æƒ…å†µï¼æœåŠ¡å™¨å®•æœºäº†",
        "è®¡ç®— 42 * 17",
        "ä»‹ç»ä¸€ä¸‹Python"
    ]

    for input_text in test_inputs:
        print(f"\nè¾“å…¥: {input_text}")

        # çº¯åå°„
        reflex_only = system.generate_response(input_text, use_model=False)
        print(f"çº¯åå°„: {reflex_only}")

        # æ¨¡å‹å¢å¼º
        with_model = system.generate_response(input_text, use_model=True)
        print(f"æ¨¡å‹å¢å¼º: {with_model[:200]}")


def demo_realtime():
    """æ¼”ç¤ºå®æ—¶è§¦å‘"""
    print("\n" + "="*50)
    print("âš¡ å®æ—¶è§¦å‘æ¼”ç¤º")
    print("="*50)

    system = GemmaReflexSystem()
    monitor = ReflexMonitor(system)

    # æ·»åŠ ç›‘å¬å™¨
    def on_event(event, response):
        print(f"\n[{datetime.fromtimestamp(event['timestamp']).strftime('%H:%M:%S')}]")
        print(f"äº‹ä»¶: {event['type']}")
        print(f"æ•°æ®: {event['data']}")
        print(f"åå°„å“åº”: {response}")

    monitor.add_listener(on_event)

    # å¯åŠ¨ç›‘æ§
    monitor.start_monitoring()

    # æ¨¡æ‹Ÿäº‹ä»¶
    events = [
        ("user_input", "ä½ å¥½"),
        ("alert", "ç´§æ€¥é€šçŸ¥"),
        ("calculation", "15 + 25"),
        ("query", "ç°åœ¨å‡ ç‚¹"),
    ]

    for event_type, data in events:
        monitor.trigger_event(event_type, data)
        time.sleep(1)

    # åœæ­¢ç›‘æ§
    monitor.stop_monitoring()


def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print("\n" + "="*50)
    print("ğŸ’¬ äº¤äº’å¼æ¡ä»¶åå°„ç³»ç»Ÿ")
    print("="*50)

    system = GemmaReflexSystem()

    # è¯¢é—®æ˜¯å¦åŠ è½½æ¨¡å‹
    use_model = input("\næ˜¯å¦åŠ è½½Gemmaæ¨¡å‹å¢å¼ºå“åº”ï¼Ÿ(y/n): ").lower() == 'y'

    if use_model:
        system.load_model()

    print("\nç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼")
    print("å‘½ä»¤:")
    print("  /add <name> <pattern> <response> - æ·»åŠ æ–°åå°„")
    print("  /remove <name> - ç§»é™¤åå°„")
    print("  /stats - æŸ¥çœ‹ç»Ÿè®¡")
    print("  /learn <name> +/- - å­¦ä¹ è°ƒæ•´")
    print("  /quit - é€€å‡º")
    print("-" * 40)

    while True:
        user_input = input("\n> ").strip()

        if user_input.startswith("/"):
            # å¤„ç†å‘½ä»¤
            parts = user_input.split()
            cmd = parts[0]

            if cmd == "/quit":
                break
            elif cmd == "/stats":
                system.print_stats()
            elif cmd == "/add" and len(parts) >= 4:
                name = parts[1]
                pattern = parts[2]
                response = " ".join(parts[3:])
                system.add_reflex(name, pattern, response)
            elif cmd == "/remove" and len(parts) >= 2:
                system.remove_reflex(parts[1])
            elif cmd == "/learn" and len(parts) >= 3:
                name = parts[1]
                positive = parts[2] == "+"
                system.learn_from_feedback(name, positive)
            else:
                print("æœªçŸ¥å‘½ä»¤")
        else:
            # å¤„ç†è¾“å…¥
            response = system.generate_response(user_input, use_model=use_model)
            print(f"ğŸ’­ {response}")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ§  Gemma 270M æ¡ä»¶åå°„ç³»ç»Ÿ")
    print("="*60)
    print("\næ¡ä»¶åå°„åŸç†ï¼š")
    print("1. æ¨¡å¼è¯†åˆ« - å¿«é€ŸåŒ¹é…è¾“å…¥æ¨¡å¼")
    print("2. ä¼˜å…ˆå“åº” - åŸºäºä¼˜å…ˆçº§é€‰æ‹©åå°„")
    print("3. å³æ—¶ååº” - æ¯«ç§’çº§å“åº”é€Ÿåº¦")
    print("4. è‡ªä¸»å­¦ä¹  - æ ¹æ®åé¦ˆè°ƒæ•´å‚æ•°")

    while True:
        print("\n" + "="*60)
        print("ğŸ“‹ æ¼”ç¤ºèœå•")
        print("="*60)
        print("1. åŸºç¡€åå°„æ¼”ç¤º")
        print("2. å­¦ä¹ æœºåˆ¶æ¼”ç¤º")
        print("3. æ¨¡å‹å¢å¼ºæ¼”ç¤ºï¼ˆéœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰")
        print("4. å®æ—¶è§¦å‘æ¼”ç¤º")
        print("5. äº¤äº’å¼ç³»ç»Ÿ")
        print("0. é€€å‡º")

        choice = input("\né€‰æ‹©æ¼”ç¤º (0-5): ").strip()

        if choice == "0":
            break
        elif choice == "1":
            demo_basic_reflexes()
        elif choice == "2":
            demo_learning()
        elif choice == "3":
            demo_with_model()
        elif choice == "4":
            demo_realtime()
        elif choice == "5":
            interactive_demo()
        else:
            print("æ— æ•ˆé€‰æ‹©")

    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ¡ä»¶åå°„ç³»ç»Ÿï¼")


if __name__ == "__main__":
    main()