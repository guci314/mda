{
  "id": "tool_write_file_20250818_192312",
  "timestamp": "2025-08-18T19:23:12.734411",
  "event": "tool_write_file",
  "data": {
    "tool": "write_file",
    "arguments": {
      "content": "\"\"\"\n数据处理工具使用示例\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom data_processor import DataProcessor\n\ndef create_sample_data():\n    \"\"\"创建示例数据\"\"\"\n    # 创建包含各种数据质量问题的示例数据\n    data = pd.DataFrame({\n        'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n        'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Henry', 'Ivy', 'Jack'],\n        'age': [25, 30, np.nan, 40, 35, 28, 33, np.nan, 29, 31],\n        'city': ['New York', 'London', 'Paris', 'New York', 'Tokyo', 'Berlin', 'London', 'Paris', 'New York', 'Tokyo'],\n        'salary': [50000, 60000, 55000, np.nan, 70000, 52000, np.nan, 58000, 54000, 61000],\n        'department': ['IT', 'HR', 'Finance', 'IT', 'Marketing', 'IT', 'HR', 'Finance', 'Marketing', 'IT']\n    })\n    \n    # 添加一些重复行\n    duplicate_row = pd.DataFrame({\n        'id': [11],\n        'name': ['Alice'],\n        'age': [25],\n        'city': ['New York'],\n        'salary': [50000],\n        'department': ['IT']\n    })\n    \n    data = pd.concat([data, duplicate_row], ignore_index=True)\n    \n    # 保存到CSV文件\n    data.to_csv('employee_data.csv', index=False)\n    print(\"示例数据已创建并保存到 'employee_data.csv'\")\n    return data\n\ndef main():\n    \"\"\"主函数 - 演示数据处理工具的使用\"\"\"\n    print(\"=== 数据处理工具使用示例 ===\\n\")\n    \n    # 创建示例数据\n    sample_data = create_sample_data()\n    print(\"原始数据:\")\n    print(sample_data)\n    print(f\"\\n数据形状: {sample_data.shape}\")\n    print(f\"缺失值统计:\\n{sample_data.isnull().sum()}\")\n    print(f\"重复行数量: {sample_data.duplicated().sum()}\")\n    \n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n    \n    # 使用数据处理器\n    processor = DataProcessor()\n    \n    # 1. 读取数据\n    print(\"1. 读取CSV数据...\")\n    data = processor.read_csv('employee_data.csv')\n    \n    # 2. 查看数据信息\n    print(\"\\n2. 数据信息:\")\n    info = processor.get_data_info()\n    for key, value in info.items():\n        print(f\"  {key}: {value}\")\n    \n    print(\"\\n3. 清洗数据...\")\n    # 3. 清洗数据 - 删除重复项，用均值填充缺失值\n    cleaned_data = processor.clean_data(\n        remove_duplicates=True,\n        handle_missing='fill_mean'\n    )\n    \n    print(\"\\n4. 清洗后的数据:\")\n    print(cleaned_data)\n    print(f\"\\n清洗后数据形状: {cleaned_data.shape}\")\n    \n    # 4. 保存清洗后的数据\n    print(\"\\n5. 保存清洗后的数据...\")\n    processor.save_data('cleaned_employee_data.csv')\n    \n    print(\"\\n数据处理完成！清洗后的数据已保存到 'cleaned_employee_data.csv'\")\n    \n    # 5. 演示其他清洗选项\n    print(\"\\n\" + \"=\"*50)\n    print(\"其他清洗选项演示:\")\n    \n    # 重新读取原始数据\n    processor2 = DataProcessor()\n    processor2.read_csv('employee_data.csv')\n    \n    # 用中位数填充\n    print(\"\\n用中位数填充缺失值:\")\n    cleaned_with_median = processor2.clean_data(\n        remove_duplicates=False,\n        handle_missing='fill_median'\n    )\n    print(cleaned_with_median)\n    \n    # 删除指定列\n    print(\"\\n删除 'department' 列:\")\n    processor3 = DataProcessor()\n    processor3.read_csv('employee_data.csv')\n    cleaned_drop_columns = processor3.clean_data(\n        remove_columns=['department']\n    )\n    print(cleaned_drop_columns.columns.tolist())\n\nif __name__ == \"__main__\":\n    main()",
      "file_path": "example_usage.py"
    },
    "round": 6
  }
}