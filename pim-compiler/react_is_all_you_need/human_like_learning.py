#!/usr/bin/env python3
"""
äººç±»å¼å­¦ä¹ ä¼˜åŒ– - å¿«é€Ÿã€ç›´è§‰ã€æ¨¡å¼é©±åŠ¨
"""

import json
from pathlib import Path
from core.react_agent_minimal import ReactAgentMinimal

class HumanLikeLearning:
    """æ¨¡æ‹Ÿäººç±»å­¦ä¹ æ–¹å¼ï¼šå¿«é€Ÿè¯†åˆ«æ¨¡å¼ï¼Œç›´æ¥åº”ç”¨ç»éªŒ"""
    
    def __init__(self):
        self.experience_bank = {
            "è°ƒè¯•å¤ªæ…¢": "å…ˆè¿è¡Œpytest --tb=shortè·å–æ‰€æœ‰é”™è¯¯ï¼Œç„¶åæ‰¹é‡ä¿®å¤",
            "ç”Ÿæˆå¤ªæ…¢": "ä½¿ç”¨é¢„æ„å»ºæ¨¡æ¿ï¼Œåªå¡«å……å˜åŒ–éƒ¨åˆ†",
            "é‡å¤é”™è¯¯": "åˆ›å»ºé”™è¯¯æ¨¡å¼åº“ï¼Œç›´æ¥åŒ¹é…è§£å†³æ–¹æ¡ˆ",
            "ä¸²è¡Œå¤„ç†": "è¯†åˆ«ç‹¬ç«‹ä»»åŠ¡ï¼Œå¹¶è¡Œæ‰§è¡Œ"
        }
        
    def learn_from_single_case(self, case_file="debug_log.md"):
        """ä»å•ä¸ªæ¡ˆä¾‹ä¸­å­¦ä¹ ï¼ˆåƒäººç±»ä¸€æ ·ï¼‰"""
        print("ğŸ§  äººç±»å¼å­¦ä¹ ï¼šåˆ†æå•ä¸ªæ¡ˆä¾‹")
        
        # ä¸éœ€è¦è¿è¡Œä»£ç ï¼Œç›´æ¥åˆ†ææ—¥å¿—
        meta_agent = ReactAgentMinimal(
            work_dir=".",
            name="human_learner",
            model="kimi-k2-turbo-preview",
            knowledge_files=["knowledge/meta_cognitive_simple.md"]
        )
        
        task = f"""
        # å¿«é€Ÿå­¦ä¹ ä»»åŠ¡ï¼ˆäººç±»æ–¹å¼ï¼‰
        
        åˆ†ææ–‡ä»¶ï¼š{case_file}
        
        ## å­¦ä¹ è¦æ±‚ï¼ˆåƒäººç±»ä¸€æ ·æ€è€ƒï¼‰
        1. **æ¨¡å¼è¯†åˆ«**ï¼šæ‰¾å‡ºé‡å¤å‡ºç°çš„æ¨¡å¼
        2. **ç“¶é¢ˆå®šä½**ï¼šå“ªä¸€æ­¥æœ€æ…¢ï¼Ÿ
        3. **ç»éªŒè¿ç§»**ï¼šæœ‰æ²¡æœ‰ç±»ä¼¼é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼Ÿ
        4. **ç›´è§‰åˆ¤æ–­**ï¼šå¦‚æœä½ æ˜¯äººç±»ï¼Œä¼šæ€ä¹ˆåšï¼Ÿ
        
        ## è¾“å‡ºæ ¼å¼
        ç›´æ¥ä¿®æ”¹ knowledge/mda/debugging_unified.mdï¼Œæ·»åŠ ï¼š
        
        ### ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼ˆäººç±»ç»éªŒï¼‰
        ```
        å¦‚æœçœ‹åˆ°Xé”™è¯¯ â†’ ç›´æ¥åšY
        å¦‚æœé‡åˆ°Zæƒ…å†µ â†’ ç«‹å³æ‰§è¡ŒW
        ```
        
        ä¸è¦ç”Ÿæˆä»£ç æµ‹è¯•ï¼Œç›´æ¥åŸºäºç»éªŒåˆ¤æ–­ã€‚
        """
        
        result = meta_agent.execute(task)
        print("âœ… å­¦ä¹ å®Œæˆï¼ˆ1åˆ†é’Ÿå†…ï¼‰")
        return result
    
    def apply_pattern_library(self):
        """åº”ç”¨æ¨¡å¼åº“ï¼ˆé¢„è®¾çš„æˆåŠŸæ¨¡å¼ï¼‰"""
        print("ğŸ“š åº”ç”¨å·²çŸ¥æˆåŠŸæ¨¡å¼")
        
        patterns = {
            "Pydanticé”™è¯¯": {
                "è¯†åˆ«": "pydantic.ValidationError",
                "è§£å†³": "æ‰¹é‡æ›¿æ¢ Optional[str] ä¸º Union[str, None]"
            },
            "å¯¼å…¥é”™è¯¯": {
                "è¯†åˆ«": "ImportError|ModuleNotFoundError", 
                "è§£å†³": "æ£€æŸ¥requirements.txtï¼Œæ‰¹é‡å®‰è£…"
            },
            "ç±»å‹é”™è¯¯": {
                "è¯†åˆ«": "TypeError|type checking",
                "è§£å†³": "ä½¿ç”¨ # type: ignore æˆ–ä¿®å¤ç±»å‹æ³¨è§£"
            },
            "æµ‹è¯•å¤±è´¥": {
                "è¯†åˆ«": "AssertionError|test_.*failed",
                "è§£å†³": "å…ˆçœ‹æ–­è¨€å†…å®¹ï¼Œé€šå¸¸æ˜¯è¿”å›æ ¼å¼é—®é¢˜"
            }
        }
        
        # ç›´æ¥å†™å…¥çŸ¥è¯†æ–‡ä»¶
        knowledge_update = """
## ğŸ¯ å³æ—¶è§£å†³æ–¹æ¡ˆï¼ˆæ— éœ€åˆ†æï¼‰

### é”™è¯¯æ¨¡å¼å¿«é€ŸåŒ¹é…
"""
        for name, pattern in patterns.items():
            knowledge_update += f"""
#### {name}
- **è¯†åˆ«**: `{pattern['è¯†åˆ«']}`
- **è¡ŒåŠ¨**: {pattern['è§£å†³']}
- **è€—æ—¶**: <5ç§’
"""
        
        # æ›´æ–°çŸ¥è¯†æ–‡ä»¶
        with open("knowledge/mda/debugging_patterns.md", "w") as f:
            f.write(knowledge_update)
        
        print("âœ… æ¨¡å¼åº“å·²åº”ç”¨")
        
    def simulate_human_debugging(self):
        """æ¨¡æ‹Ÿäººç±»è°ƒè¯•è¿‡ç¨‹ï¼ˆä¸è¿è¡Œå®é™…ä»£ç ï¼‰"""
        print("ğŸ® æ¨¡æ‹Ÿäººç±»è°ƒè¯•æ€ç»´")
        
        human_process = """
        # äººç±»è°ƒè¯•æµç¨‹ï¼ˆç»éªŒé©±åŠ¨ï¼‰
        
        1. **å¿«é€Ÿæ‰«æ**ï¼ˆ10ç§’ï¼‰
           - pytest --collect-only  # çœ‹æœ‰å¤šå°‘æµ‹è¯•
           - ls -la app/ tests/    # äº†è§£ä»£ç ç»“æ„
        
        2. **æ‰¹é‡è¯†åˆ«**ï¼ˆ20ç§’ï¼‰
           - pytest --tb=no  # åªçœ‹å“ªäº›æµ‹è¯•å¤±è´¥
           - å°†å¤±è´¥åˆ†ç±»ï¼ˆå¯¼å…¥/ç±»å‹/é€»è¾‘ï¼‰
        
        3. **æ¨¡å¼åŒ¹é…**ï¼ˆ10ç§’ï¼‰
           - 90%çš„é”™è¯¯éƒ½æ˜¯å·²çŸ¥æ¨¡å¼
           - ç›´æ¥åº”ç”¨è§£å†³æ–¹æ¡ˆ
        
        4. **æ‰¹é‡ä¿®å¤**ï¼ˆ30ç§’ï¼‰
           - ç›¸åŒé”™è¯¯ä¸€æ¬¡ä¿®å¤
           - ä½¿ç”¨æŸ¥æ‰¾æ›¿æ¢
           - å¤åˆ¶ç²˜è´´å·²çŸ¥è§£å†³æ–¹æ¡ˆ
        
        æ€»è®¡ï¼š70ç§’ = çº¦7è½®ï¼ˆå¯¹æ¯”æœºå™¨86è½®ï¼‰
        """
        
        print(human_process)
        return 7  # äººç±»åªéœ€è¦7è½®
    
    def transfer_experience(self, from_domain="web", to_domain="cli"):
        """ç»éªŒè¿ç§»ï¼ˆè·¨é¢†åŸŸåº”ç”¨ï¼‰"""
        print(f"ğŸ”„ è¿ç§»ç»éªŒï¼š{from_domain} â†’ {to_domain}")
        
        transferable_patterns = {
            "webâ†’cli": {
                "é”™è¯¯å¤„ç†": "try-exceptåŒ…è£… â†’ clickå¼‚å¸¸å¤„ç†",
                "å‚æ•°éªŒè¯": "Pydanticæ¨¡å‹ â†’ clickå‚æ•°ç±»å‹",
                "æ—¥å¿—è¾“å‡º": "logger â†’ click.echo"
            },
            "è°ƒè¯•â†’ç”Ÿæˆ": {
                "æ‰¹é‡å¤„ç†": "æ‰¹é‡ä¿®é”™ â†’ æ‰¹é‡ç”Ÿæˆ",
                "æ¨¡æ¿æ€ç»´": "é”™è¯¯æ¨¡æ¿ â†’ ä»£ç æ¨¡æ¿",
                "å¹¶è¡Œæ€ç»´": "å¹¶è¡Œæµ‹è¯• â†’ å¹¶è¡Œç”Ÿæˆ"
            }
        }
        
        key = f"{from_domain}â†’{to_domain}"
        if key in transferable_patterns:
            print(f"âœ… æ‰¾åˆ°å¯è¿ç§»æ¨¡å¼ï¼š")
            for name, pattern in transferable_patterns[key].items():
                print(f"  - {name}: {pattern}")
        
    def optimize_by_intuition(self):
        """åŸºäºç›´è§‰çš„ä¼˜åŒ–ï¼ˆæ— éœ€æ•°æ®ï¼‰"""
        print("ğŸ’¡ ç›´è§‰ä¼˜åŒ–ï¼ˆåŸºäºç»éªŒï¼‰")
        
        intuitions = [
            "å¦‚æœç¬¬ä¸€æ¬¡å°±ç”¨äº†86è½®ï¼ŒçŸ¥è¯†æ–‡ä»¶è‚¯å®šæœ‰å¤§é—®é¢˜",
            "æœ€å¯èƒ½çš„é—®é¢˜ï¼šæ²¡æœ‰æ‰¹é‡å¤„ç†æ€ç»´",
            "è§£å†³æ–¹æ¡ˆï¼šæ·»åŠ 'å…ˆæ”¶é›†åå¤„ç†'çš„å¼ºåˆ¶è§„åˆ™",
            "é¢„æœŸæ•ˆæœï¼šç«‹å³é™åˆ°20è½®ä»¥ä¸‹"
        ]
        
        for intuition in intuitions:
            print(f"  â†’ {intuition}")
        
        # ç›´æ¥ä¼˜åŒ–
        optimization = """
## âš¡ å¼ºåˆ¶ä¼˜åŒ–è§„åˆ™ï¼ˆåŸºäºäººç±»ç›´è§‰ï¼‰

### ç»å¯¹ç¦æ­¢
- âŒ é€ä¸ªæ–‡ä»¶ä¿®å¤
- âŒ é€ä¸ªæµ‹è¯•è¿è¡Œ
- âŒ åå¤å°è¯•åŒä¸€å‘½ä»¤

### å¿…é¡»æ‰§è¡Œ
- âœ… ç¬¬1æ­¥ï¼šè¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼Œæ”¶é›†æ‰€æœ‰é”™è¯¯
- âœ… ç¬¬2æ­¥ï¼šåˆ†ç±»é”™è¯¯ï¼ˆå¯¼å…¥/ç±»å‹/é€»è¾‘ï¼‰
- âœ… ç¬¬3æ­¥ï¼šæ¯ç±»é”™è¯¯ç”¨ä¸€ä¸ªå‘½ä»¤æ‰¹é‡ä¿®å¤
- âœ… ç¬¬4æ­¥ï¼šä¸€æ¬¡æ€§éªŒè¯æ‰€æœ‰ä¿®å¤

### æ—¶é—´é™åˆ¶
- æ”¶é›†é”™è¯¯ï¼š1è½®
- åˆ†ç±»åˆ†æï¼š1è½®  
- æ‰¹é‡ä¿®å¤ï¼š3è½®
- éªŒè¯ç»“æœï¼š1è½®
- **æ€»è®¡ï¼š6è½®**ï¼ˆå¦‚æœè¶…è¿‡10è½®å°±æ˜¯æ–¹æ³•é”™è¯¯ï¼‰
"""
        return optimization


def fast_optimization():
    """å¿«é€Ÿä¼˜åŒ–æ¼”ç¤ºï¼ˆæ— éœ€å¼ºåŒ–å­¦ä¹ ï¼‰"""
    print("=" * 60)
    print("ğŸš€ äººç±»å¼å­¦ä¹ ä¼˜åŒ–")
    print("=" * 60)
    
    learner = HumanLikeLearning()
    
    print("\n1ï¸âƒ£ ä»å•ä¸ªæ¡ˆä¾‹å­¦ä¹ ")
    # learner.learn_from_single_case()
    
    print("\n2ï¸âƒ£ åº”ç”¨å·²çŸ¥æ¨¡å¼")
    learner.apply_pattern_library()
    
    print("\n3ï¸âƒ£ æ¨¡æ‹Ÿäººç±»æ€ç»´")
    human_rounds = learner.simulate_human_debugging()
    print(f"   äººç±»éœ€è¦ï¼š{human_rounds}è½®")
    print(f"   æœºå™¨éœ€è¦ï¼š86è½®")
    print(f"   å·®è·ï¼š{86/human_rounds:.1f}å€")
    
    print("\n4ï¸âƒ£ ç»éªŒè¿ç§»")
    learner.transfer_experience("è°ƒè¯•", "ç”Ÿæˆ")
    
    print("\n5ï¸âƒ£ ç›´è§‰ä¼˜åŒ–")
    optimization = learner.optimize_by_intuition()
    
    # ä¿å­˜ä¼˜åŒ–ç»“æœ
    with open("human_optimization.md", "w") as f:
        f.write(optimization)
    
    print("\nâœ… ä¼˜åŒ–å®Œæˆï¼")
    print("ğŸ“ ä¼˜åŒ–ç­–ç•¥å·²ä¿å­˜åˆ° human_optimization.md")
    print("\né¢„æœŸæ•ˆæœï¼š")
    print("  - ç¬¬1æ¬¡ï¼š86è½® â†’ ç¬¬2æ¬¡ï¼š<10è½®")
    print("  - æ— éœ€å¤šæ¬¡è¿­ä»£")
    print("  - æ— éœ€ç”Ÿæˆæµ‹è¯•ä»£ç ")
    

if __name__ == "__main__":
    fast_optimization()