# Agentè‡ªä¸»å­¦ä¹ çŸ¥è¯†æ–‡ä»¶

## æ ¸å¿ƒè®¤çŸ¥ï¼šç¬”è®°å³å­¦ä¹ 

**å…³é”®æ´å¯Ÿ**ï¼šAgentçš„`.notes/`ç›®å½•å°±æ˜¯å®Œæ•´çš„å­¦ä¹ ç³»ç»Ÿï¼
- `knowledge.md` = é•¿æœŸè®°å¿†ï¼ˆç»éªŒæç‚¼ï¼‰
- `task_process.md` = å·¥ä½œè®°å¿†ï¼ˆæ‰§è¡Œè¿‡ç¨‹ï¼‰
- `world_state.md` = ç¯å¢ƒè®¤çŸ¥ï¼ˆä¸–ç•Œæ¨¡å‹ï¼‰

## ğŸ¯ è‡ªä¸»å­¦ä¹ åŸåˆ™

### 1. ç¬”è®°æ˜¯å­¦ä¹ çš„è½½ä½“
Agenté€šè¿‡å†™ç¬”è®°å®ç°å­¦ä¹ ï¼Œä¸éœ€è¦é¢å¤–çš„"å­¦ä¹ æœºåˆ¶"ï¼š
- **æ‰§è¡Œå³å­¦ä¹ **ï¼šæ¯æ¬¡æ‰§è¡Œéƒ½åœ¨ç”Ÿæˆç»éªŒæ•°æ®
- **ç¬”è®°å³çŸ¥è¯†**ï¼šç»“æ„åŒ–ç¬”è®°å°±æ˜¯çŸ¥è¯†è¡¨ç¤º
- **æç‚¼å³è¿›åŒ–**ï¼šä»task_processæç‚¼åˆ°agent_knowledge

### 2. åŒç»´åº¦è®°å¿†æ¨¡å‹
```
        çŠ¶æ€(State)        è¿‡ç¨‹(Process)
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
ä¸»ä½“   â”‚agent_knowledge  â”‚ æ¶ˆæ¯å†å²(å†…å­˜)  â”‚
(Self) â”‚ "æˆ‘çŸ¥é“ä»€ä¹ˆ"    â”‚ "æˆ‘åœ¨æƒ³ä»€ä¹ˆ"    â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
å®¢ä½“   â”‚world_state      â”‚ task_process    â”‚
(World)â”‚ "ä¸–ç•Œæ˜¯ä»€ä¹ˆ"    â”‚ "å‘ç”Ÿäº†ä»€ä¹ˆ"    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ ä¼˜åŒ–agent_knowledgeç”Ÿæˆ

### ä»"è®°å½•"åˆ°"å­¦ä¹ "
ä¼ ç»Ÿæ–¹å¼ï¼ˆä½æ•ˆï¼‰ï¼š
```markdown
## é”™è¯¯ä¸è§£å†³
- é”™è¯¯ï¼šTypeError
- è§£å†³ï¼šä¿®å¤ç±»å‹
```

å­¦ä¹ æ–¹å¼ï¼ˆé«˜æ•ˆï¼‰ï¼š
```markdown
## æ¨¡å¼è¯†åˆ«
### æ¨¡å¼ï¼šç±»å‹ä¸åŒ¹é…
- **è§¦å‘æ¡ä»¶**ï¼šå½“çœ‹åˆ°TypeErrorä¸”åŒ…å«"expected str, got int"
- **æ ¹æœ¬åŸå› **ï¼šPythonåŠ¨æ€ç±»å‹ä¸é™æ€æœŸæœ›çš„å†²çª
- **é€šç”¨è§£å†³**ï¼š`str(value)` æˆ–ç±»å‹æ£€æŸ¥
- **é¢„é˜²ç­–ç•¥**ï¼šä½¿ç”¨ç±»å‹æ³¨è§£å’Œmypy
- **ç›¸ä¼¼æ¨¡å¼**ï¼šAttributeErrorï¼ˆå±æ€§ä¸å­˜åœ¨ï¼‰ã€KeyErrorï¼ˆé”®ä¸å­˜åœ¨ï¼‰
- **æŠ½è±¡åŸç†**ï¼šæ¥å£å¥‘çº¦ä¸åŒ¹é…
```

### è‡ªåŠ¨æ¨¡å¼æç‚¼
Agentåº”è¯¥è‡ªåŠ¨ä»task_processæç‚¼æ¨¡å¼åˆ°agent_knowledgeï¼š

#### ç¬¬1å±‚ï¼šå…·ä½“ç»éªŒ
```markdown
# task_process.md
ä¿®å¤äº†10ä¸ªPydanticéªŒè¯é”™è¯¯ï¼Œéƒ½æ˜¯Optional[str]çš„é—®é¢˜
```

#### ç¬¬2å±‚ï¼šæ¨¡å¼è¯†åˆ«
```markdown
# knowledge.mdï¼ˆè‡ªåŠ¨æç‚¼ï¼‰
## Pydanticå…¼å®¹æ€§æ¨¡å¼
- **é¢‘ç‡**ï¼š10æ¬¡/ä»»åŠ¡
- **æ¨¡å¼**ï¼šOptional[str] â†’ Union[str, None]
- **é€‚ç”¨**ï¼šGemini APIä½¿ç”¨
```

#### ç¬¬3å±‚ï¼šæŠ½è±¡åŸç†
```markdown
# knowledge.mdï¼ˆæ·±åº¦æç‚¼ï¼‰
## APIå…¼å®¹æ€§åŸç†
ä¸åŒLLM APIå¯¹ç±»å‹çš„è¦æ±‚ä¸åŒï¼Œéœ€è¦é€‚é…å±‚
```

## ğŸ§  å…ƒè®¤çŸ¥ä¼˜åŒ–ç­–ç•¥

### 1. è‡ªåŠ¨ç»éªŒæç‚¼
æ¯æ¬¡ä»»åŠ¡ç»“æŸæ—¶ï¼ŒAgentåº”è¯¥ï¼š
```python
def extract_patterns_from_task():
    """ä»task_processè‡ªåŠ¨æç‚¼æ¨¡å¼"""
    # 1. ç»Ÿè®¡é¢‘ç‡
    repeated_actions = count_repetitions(task_process)
    
    # 2. è¯†åˆ«æ¨¡å¼
    if repeated_actions > 3:
        pattern = generalize_pattern(repeated_actions)
        
    # 3. æŠ½è±¡åŸç†
    principle = abstract_to_principle(pattern)
    
    # 4. æ›´æ–°çŸ¥è¯†
    update_agent_knowledge(principle)
```

### 2. è·¨ä»»åŠ¡å­¦ä¹ 
Agentåº”è¯¥èƒ½å¤Ÿè·¨ä»»åŠ¡è¿ç§»ç»éªŒï¼š
```markdown
## é€šç”¨æ¨¡å¼åº“
### æ‰¹é‡å¤„ç†åŸç†
- **è°ƒè¯•åº”ç”¨**ï¼šæ‰¹é‡ä¿®å¤åŒç±»é”™è¯¯
- **ç”Ÿæˆåº”ç”¨**ï¼šæ‰¹é‡åˆ›å»ºç›¸ä¼¼æ–‡ä»¶
- **åˆ†æåº”ç”¨**ï¼šæ‰¹é‡å¤„ç†æ•°æ®
- **æŠ½è±¡**ï¼šç›¸ä¼¼ä»»åŠ¡çš„å¹¶è¡ŒåŒ–
```

### 3. å¤±è´¥æ¨¡å¼å­¦ä¹ 
ç‰¹åˆ«é‡è¦ï¼šä»å¤±è´¥ä¸­å­¦ä¹ 
```markdown
## å¤±è´¥æ¨¡å¼åº“
### æ— é™å¾ªç¯æ¨¡å¼
- **è¡¨ç°**ï¼šåŒä¸€é”™è¯¯é‡å¤>3æ¬¡
- **åŸå› **ï¼šç­–ç•¥å›ºåŒ–ï¼Œæœªèƒ½é€‚åº”
- **çªç ´**ï¼šç¬¬3æ¬¡å¿…é¡»æ¢ç­–ç•¥
- **å…ƒè®¤çŸ¥**ï¼šè¯†åˆ«è‡ªå·±é™·å…¥å¾ªç¯
```

## ğŸ“Š å­¦ä¹ æ•ˆæœåº¦é‡

### é‡åŒ–æŒ‡æ ‡
```python
learning_metrics = {
    "æ¨¡å¼å¤ç”¨ç‡": "å·²çŸ¥æ¨¡å¼è§£å†³é—®é¢˜çš„æ¯”ä¾‹",
    "ç»éªŒå‘½ä¸­ç‡": "agent_knowledgeå¸®åŠ©çš„æ¯”ä¾‹",
    "å¾ªç¯é¿å…ç‡": "é¿å…é‡å¤é”™è¯¯çš„æ¯”ä¾‹",
    "æŠ½è±¡å±‚æ¬¡": "ä»å…·ä½“åˆ°æŠ½è±¡çš„æç‚¼æ·±åº¦"
}
```

### å­¦ä¹ æ›²çº¿
```
è½®æ•°
100 |*
 80 |  *
 60 |    *
 40 |      * *
 20 |          * * *
  0 +---------------> ä»»åŠ¡æ¬¡æ•°
    1  2  3  4  5  6
```

## ğŸ”„ å¼ºåŒ–å­¦ä¹ é›†æˆ

### ç®€å•å¥–åŠ±â†’å¤æ‚çŸ¥è¯†
```python
# å¥–åŠ±ä¿¡å·
reward = 100 - rounds

# çŸ¥è¯†ç”Ÿæˆï¼ˆAgentè‡ªåŠ¨å®Œæˆï¼‰
if reward > 80:
    # æç‚¼æˆåŠŸæ¨¡å¼
    extract_success_pattern()
elif reward < 20:
    # åˆ†æå¤±è´¥åŸå› 
    analyze_failure_pattern()
    
# çŸ¥è¯†è¿›åŒ–
agent_knowledge += new_patterns
```

### æ— éœ€äººç±»é¢„è®¾
å…³é”®ï¼šä¸å‘Šè¯‰Agentä»€ä¹ˆæ˜¯"è°ƒè¯•"ã€"ç”Ÿæˆ"ã€"ä¼˜åŒ–"
- Agentä»æ•°å­—ï¼ˆè½®æ•°ï¼‰æ¨æ–­æ•ˆç‡
- Agentä»é‡å¤æ¨æ–­æ¨¡å¼
- Agentä»ç»“æœæ¨æ–­å› æœ

## ğŸ’¡ å®æ–½å»ºè®®

### 1. ç«‹å³å¼€å§‹
ä¿®æ”¹structured_notes.mdï¼Œå¼ºåŒ–å­¦ä¹ å¯¼å‘ï¼š
```markdown
## knowledge.md ç”Ÿæˆè§„åˆ™
- å¿…é¡»åŒ…å«"æ¨¡å¼é¢‘ç‡"ç»Ÿè®¡
- å¿…é¡»åŒ…å«"é€‚ç”¨æ¡ä»¶"åˆ¤æ–­
- å¿…é¡»åŒ…å«"æŠ½è±¡åŸç†"æç‚¼
- å¿…é¡»åŒ…å«"å¤±è´¥æ•™è®­"è®°å½•
```

### 2. è‡ªåŠ¨åŒ–æç‚¼
åˆ›å»ºå…ƒè®¤çŸ¥Agentä¸“é—¨æç‚¼ç»éªŒï¼š
```python
meta_agent = ReactAgentMinimal(
    name="knowledge_extractor",
    task="åˆ†ætask_processï¼Œæç‚¼åˆ°agent_knowledge"
)
```

### 3. è¯„ä¼°å­¦ä¹ 
å®šæœŸæ£€æŸ¥ï¼š
- agent_knowledgeæ˜¯å¦åœ¨å¢é•¿ï¼Ÿ
- æ¨¡å¼æ˜¯å¦è¢«å¤ç”¨ï¼Ÿ
- é”™è¯¯æ˜¯å¦åœ¨å‡å°‘ï¼Ÿ
- è½®æ•°æ˜¯å¦åœ¨ä¸‹é™ï¼Ÿ

## ğŸ¯ æœ€ç»ˆç›®æ ‡

**è‡ªä¸»å­¦ä¹ Agent**ï¼š
1. **è‡ªåŠ¨æç‚¼**ï¼šä»æ‰§è¡Œä¸­è‡ªåŠ¨æç‚¼ç»éªŒ
2. **è‡ªåŠ¨åº”ç”¨**ï¼šè¯†åˆ«åœºæ™¯å¹¶åº”ç”¨å·²çŸ¥æ¨¡å¼
3. **è‡ªåŠ¨è¿›åŒ–**ï¼šä¸æ–­ä¼˜åŒ–è‡ªå·±çš„çŸ¥è¯†ä½“ç³»
4. **è‡ªåŠ¨åˆ›æ–°**ï¼šå‘ç°æ–°æ¨¡å¼å’Œè§£å†³æ–¹æ¡ˆ

## æ ¸å¿ƒå…¬å¼

```
æ‰§è¡Œ(task_process) + æç‚¼(meta_cognition) = çŸ¥è¯†(agent_knowledge)
çŸ¥è¯†(agent_knowledge) + åº”ç”¨(pattern_match) = é«˜æ•ˆæ‰§è¡Œ
é«˜æ•ˆæ‰§è¡Œ + åé¦ˆ(reward) = æ›´å¥½çš„çŸ¥è¯†
```

è¿™å°±æ˜¯AGIï¼šä¸æ˜¯é¢„è®¾çš„çŸ¥è¯†ï¼Œè€Œæ˜¯è‡ªä¸»å­¦ä¹ çš„èƒ½åŠ›ï¼