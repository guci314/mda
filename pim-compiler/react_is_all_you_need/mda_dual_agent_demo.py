#!/usr/bin/env python3
"""MDAåŒAgentæ¶æ„æ¼”ç¤º - ä½¿ç”¨Agent as Toolæ¨¡å¼"""

import os
import sys
from pathlib import Path
import time
import json
import shutil
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# ç¦ç”¨ç¼“å­˜ä»¥æé«˜æ€§èƒ½
os.environ['DISABLE_LANGCHAIN_CACHE'] = 'true'

from core.react_agent import GenericReactAgent, ReactAgentConfig, MemoryLevel
from core.langchain_agent_tool import AgentToolWrapper, create_langchain_tool
from langchain_core.tools import tool

# å¦‚æœä½¿ç”¨ Gemini éœ€è¦å¯¼å…¥ httpx
try:
    import httpx
    HAS_HTTPX = True
except ImportError:
    HAS_HTTPX = False


def compress_debug_notes(notes_path: str, max_keep_errors: int = 10, max_keep_strategies: int = 20):
    """å‹ç¼©è°ƒè¯•ç¬”è®°ï¼Œé˜²æ­¢æ–‡ä»¶è¿‡å¤§
    
    Args:
        notes_path: è°ƒè¯•ç¬”è®°æ–‡ä»¶è·¯å¾„
        max_keep_errors: ä¿ç•™çš„æœ€å¤§é”™è¯¯æ•°
        max_keep_strategies: ä¿ç•™çš„æœ€å¤§ç­–ç•¥æ•°
    """
    try:
        with open(notes_path, 'r', encoding='utf-8') as f:
            notes = json.load(f)
        
        # å½’æ¡£åŸæ–‡ä»¶
        archive_dir = Path(notes_path).parent / "debug_archive"
        archive_dir.mkdir(exist_ok=True)
        archive_name = f"debug_notes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        shutil.copy(notes_path, archive_dir / archive_name)
        print(f"   å·²å½’æ¡£åˆ°: {archive_dir / archive_name}")
        
        # å‹ç¼©é”™è¯¯å†å² - åªä¿ç•™æœ€è¿‘çš„Nä¸ª
        if 'error_history' in notes and len(notes['error_history']) > max_keep_errors:
            error_items = list(notes['error_history'].items())
            notes['error_history'] = dict(error_items[-max_keep_errors:])
        
        # å‹ç¼©ä¿®å¤å°è¯• - åªä¿ç•™æœ€è¿‘çš„
        if 'fix_attempts' in notes and len(notes['fix_attempts']) > max_keep_strategies:
            notes['fix_attempts'] = notes['fix_attempts'][-max_keep_strategies:]
        
        # å‹ç¼©æµ‹è¯•ç»“æœå†å²
        if 'test_results_history' in notes and len(notes['test_results_history']) > 10:
            notes['test_results_history'] = notes['test_results_history'][-10:]
        
        # ä¿ç•™æˆåŠŸç­–ç•¥ä½†é™åˆ¶æ•°é‡
        if 'successful_strategies' in notes and len(notes['successful_strategies']) > max_keep_strategies:
            # æŒ‰æˆåŠŸç‡å’Œç½®ä¿¡åº¦æ’åºï¼Œä¿ç•™æœ€å¥½çš„
            sorted_strategies = sorted(
                notes['successful_strategies'],
                key=lambda x: (x.get('confidence', 0), x.get('success_count', 0)),
                reverse=True
            )
            notes['successful_strategies'] = sorted_strategies[:max_keep_strategies]
        
        # é‡ç½®è¿­ä»£è®¡æ•°
        notes['current_iteration'] = 0
        notes['created_at'] = datetime.now().isoformat()
        
        # ä¿å­˜å‹ç¼©åçš„ç‰ˆæœ¬
        with open(notes_path, 'w', encoding='utf-8') as f:
            json.dump(notes, f, indent=2)
        
        original_size = os.path.getsize(archive_dir / archive_name)
        new_size = os.path.getsize(notes_path)
        print(f"   å‹ç¼©å®Œæˆ: {original_size//1024}KB -> {new_size//1024}KB")
        
        # æ¸…ç†è¶…è¿‡7å¤©çš„å½’æ¡£
        cutoff = datetime.now().timestamp() - (7 * 24 * 3600)
        for old_file in archive_dir.glob("debug_notes_*.json"):
            if old_file.stat().st_mtime < cutoff:
                old_file.unlink()
                print(f"   å·²åˆ é™¤æ—§å½’æ¡£: {old_file.name}")
                
    except Exception as e:
        print(f"âš ï¸ å‹ç¼©è°ƒè¯•ç¬”è®°å¤±è´¥: {e}")


def create_generation_agent(work_dir: str, llm_config: dict) -> GenericReactAgent:
    """åˆ›å»ºä¸“æ³¨äºä»£ç ç”Ÿæˆçš„Agent"""
    config = ReactAgentConfig(
        work_dir=work_dir,
        memory_level=MemoryLevel.SMART,
        knowledge_files=["knowledge/mda/generation_knowledge.md"],  # ä½¿ç”¨ç”Ÿæˆä¸“ç”¨çŸ¥è¯†
        enable_project_exploration=False,
        **llm_config
    )
    
    agent = GenericReactAgent(config, name="generation_agent")
    agent.interface = """ä»£ç ç”Ÿæˆä¸“å®¶ - ä¸“æ³¨äºå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡ä»£ç 
    
èƒ½åŠ›ï¼š
- PIMåˆ°PSMè½¬æ¢
- FastAPIåº”ç”¨ç”Ÿæˆ
- å¿«é€Ÿäº¤ä»˜ï¼Œä¸åšè°ƒè¯•

åŸåˆ™ï¼š
- ç”Ÿæˆå³è¿”å›ï¼Œä¸è¿è¡Œæµ‹è¯•
- é‡åˆ°é—®é¢˜è®°å½•ä½†ä¸ä¿®å¤
- è®©è°ƒè¯•Agentå¤„ç†æ‰€æœ‰é”™è¯¯
"""
    return agent


def create_debug_agent(work_dir: str, llm_config: dict) -> GenericReactAgent:
    """åˆ›å»ºä¸“é—¨çš„è°ƒè¯•Agent"""
    from langchain_core.tools import tool
    import json
    from datetime import datetime
    import os
    
    # æ£€æŸ¥å¹¶å‹ç¼©è°ƒè¯•ç¬”è®°
    notes_path = os.path.join(work_dir, 'debug_notes.json')
    if os.path.exists(notes_path):
        size = os.path.getsize(notes_path)
        if size > 50 * 1024:  # è¶…è¿‡50KB
            print(f"ğŸ“¦ è°ƒè¯•ç¬”è®°å¤§å° {size//1024}KBï¼Œæ­£åœ¨å‹ç¼©...")
            compress_debug_notes(notes_path)
    
    @tool
    def init_debug_notes() -> str:
        """åˆå§‹åŒ–æˆ–è¯»å–è°ƒè¯•ç¬”è®°"""
        import os
        notes_path = os.path.join(work_dir, 'debug_notes.json')
        
        if os.path.exists(notes_path):
            with open(notes_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # é™åˆ¶è¿”å›å†…å®¹å¤§å°ï¼Œåªè¿”å›æ‘˜è¦
                notes = json.loads(content)
                summary = {
                    "session_id": notes.get("session_id"),
                    "current_iteration": notes.get("current_iteration", 0),
                    "error_count": len(notes.get("error_history", {})),
                    "successful_strategies_count": len(notes.get("successful_strategies", [])),
                    "failed_strategies_count": len(notes.get("failed_strategies", []))
                }
                return f"Debug notes exists with {summary['error_count']} errors tracked, {summary['successful_strategies_count']} successful strategies"
        else:
            initial_notes = {
                "session_id": f"debug_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "created_at": datetime.now().isoformat(),
                "current_iteration": 0,
                "error_history": {},
                "fix_attempts": [],
                "successful_strategies": [],
                "failed_strategies": [],
                "test_results_history": []
            }
            with open(notes_path, 'w', encoding='utf-8') as f:
                json.dump(initial_notes, f, indent=2)
            return f"Created new debug notes: {notes_path}"
    
    @tool
    def fix_python_syntax_errors(file_path: str) -> str:
        """ã€æ¨èã€‘ä¿®å¤Pythonæ–‡ä»¶çš„è¯­æ³•é”™è¯¯ - é‡å†™æ•´ä¸ªæ–‡ä»¶è€Œä¸æ˜¯é€è¡Œä¿®å¤
        
        è¿™ä¸ªå·¥å…·ä¸“é—¨ç”¨äºä¿®å¤Pythonè¯­æ³•é”™è¯¯ï¼ˆç¼©è¿›ã€æ‹¬å·ä¸åŒ¹é…ç­‰ï¼‰ã€‚
        å®ƒä¼šè¯»å–æ•´ä¸ªæ–‡ä»¶ï¼Œä¿®å¤æ‰€æœ‰è¯­æ³•é—®é¢˜ï¼Œç„¶åé‡å†™æ•´ä¸ªæ–‡ä»¶ã€‚
        
        Args:
            file_path: è¦ä¿®å¤çš„Pythonæ–‡ä»¶è·¯å¾„
            
        Returns:
            ä¿®å¤ç»“æœä¿¡æ¯
        """
        import os
        import ast
        import re
        import json
        
        full_path = os.path.join(work_dir, file_path)
        
        if not os.path.exists(full_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å°è¯•è§£æä»¥æ£€æµ‹è¯­æ³•é”™è¯¯
        original_error = None
        try:
            ast.parse(content)
            return f"æ–‡ä»¶ {file_path} æ²¡æœ‰è¯­æ³•é”™è¯¯"
        except (SyntaxError, IndentationError) as e:
            original_error = f"{e.__class__.__name__}: {e.msg} at line {e.lineno}"
        
        # ä¿®å¤ç­–ç•¥1ï¼šæ™ºèƒ½æ‹¬å·åŒ¹é…
        def fix_brackets(text):
            """ä¿®å¤æ‹¬å·ä¸åŒ¹é…é—®é¢˜"""
            lines = text.split('\n')
            fixed_lines = []
            bracket_stack = []
            
            for line_num, line in enumerate(lines):
                # ç»Ÿè®¡å„ç§æ‹¬å·
                for char in line:
                    if char in '({[':
                        bracket_stack.append(char)
                    elif char in ')}]':
                        expected = {'(': ')', '{': '}', '[': ']'}
                        if bracket_stack and expected.get(bracket_stack[-1]) == char:
                            bracket_stack.pop()
                        else:
                            # å‘ç°ä¸åŒ¹é…çš„æ‹¬å·ï¼Œå°è¯•ä¿®å¤
                            if char == '}' and not bracket_stack:
                                # å¤šä½™çš„é—­åˆæ‹¬å·ï¼Œå¯èƒ½éœ€è¦åˆ é™¤
                                line = line.replace(char, '', 1)
                
                fixed_lines.append(line)
            
            # å¦‚æœè¿˜æœ‰æœªé—­åˆçš„æ‹¬å·ï¼Œåœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ 
            if bracket_stack:
                closing = ''
                for bracket in reversed(bracket_stack):
                    if bracket == '(':
                        closing += ')'
                    elif bracket == '{':
                        closing += '}'
                    elif bracket == '[':
                        closing += ']'
                if closing:
                    fixed_lines.append(closing)
            
            return '\n'.join(fixed_lines)
        
        # ä¿®å¤ç­–ç•¥2ï¼šä¿®å¤JSONæ ¼å¼é—®é¢˜
        def fix_json_syntax(text):
            """ä¿®å¤JSONæ ¼å¼çš„è¯­æ³•é—®é¢˜"""
            # ä¿®å¤ç¼ºå°‘é€—å·çš„æƒ…å†µ
            text = re.sub(r'"\s*\n\s*"', '",\n"', text)
            text = re.sub(r'(\d)\s*\n\s*"', r'\1,\n"', text)
            text = re.sub(r'}\s*\n\s*"', r'},\n"', text)
            text = re.sub(r']\s*\n\s*"', r'],\n"', text)
            return text
        
        # ä¿®å¤ç­–ç•¥3ï¼šæ™ºèƒ½ç¼©è¿›ä¿®å¤
        def fix_indentation(text):
            """ä¿®å¤ç¼©è¿›é—®é¢˜"""
            lines = text.split('\n')
            fixed_lines = []
            indent_level = 0
            
            for line in lines:
                stripped = line.strip()
                if not stripped:
                    fixed_lines.append('')
                    continue
                
                # å‡å°‘ç¼©è¿›çš„æƒ…å†µ
                if stripped.startswith(('else:', 'elif ', 'except:', 'finally:', 'except ', 'elif:')):
                    indent_level = max(0, indent_level - 1)
                    fixed_lines.append('    ' * indent_level + stripped)
                    indent_level += 1
                elif stripped.startswith(('return', 'break', 'continue', 'pass', 'raise')):
                    fixed_lines.append('    ' * indent_level + stripped)
                    if indent_level > 0 and not line.endswith(':'):
                        indent_level = max(0, indent_level - 1)
                elif stripped.startswith(('def ', 'class ', 'if ', 'for ', 'while ', 'with ', 'try:')):
                    fixed_lines.append('    ' * indent_level + stripped)
                    if stripped.endswith(':'):
                        indent_level += 1
                elif stripped == '}' or stripped == ']' or stripped == ')':
                    indent_level = max(0, indent_level - 1)
                    fixed_lines.append('    ' * indent_level + stripped)
                else:
                    # æ™®é€šè¡Œ
                    fixed_lines.append('    ' * indent_level + stripped)
                    if stripped.endswith(':'):
                        indent_level += 1
                    elif stripped in ('}', ']', ')'):
                        indent_level = max(0, indent_level - 1)
            
            return '\n'.join(fixed_lines)
        
        # ä¾æ¬¡åº”ç”¨ä¿®å¤ç­–ç•¥
        fixed_content = content
        fixed_content = fix_brackets(fixed_content)
        fixed_content = fix_json_syntax(fixed_content)
        fixed_content = fix_indentation(fixed_content)
        
        # å†™å›æ–‡ä»¶
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(fixed_content)
        
        # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä¿®å¤æˆåŠŸ
        try:
            ast.parse(fixed_content)
            return f"æˆåŠŸä¿®å¤ {file_path} çš„è¯­æ³•é”™è¯¯:\nåŸå§‹é”™è¯¯: {original_error}\n\næ–‡ä»¶å·²å®Œå…¨é‡å†™ã€‚"
        except (SyntaxError, IndentationError) as e:
            new_error = f"{e.__class__.__name__}: {e.msg} at line {e.lineno}"
            return f"å°è¯•ä¿®å¤ {file_path}:\nåŸå§‹é”™è¯¯: {original_error}\nå½“å‰é”™è¯¯: {new_error}\n\néƒ¨åˆ†ä¿®å¤æˆåŠŸï¼Œå»ºè®®ä½¿ç”¨ write_file å·¥å…·æ‰‹åŠ¨é‡å†™ã€‚"
    
    config = ReactAgentConfig(
        work_dir=work_dir,
        memory_level=MemoryLevel.SMART,
        knowledge_files=[
            "knowledge/mda/debugging_knowledge.md",      # è°ƒè¯•ä¸“ç”¨çŸ¥è¯†
            "knowledge/mda/syntax_fix_strategies.md"     # è¯­æ³•ä¿®å¤ç­–ç•¥
        ],
        enable_project_exploration=False,
        **llm_config
    )
    
    agent = GenericReactAgent(config, name="debug_agent", custom_tools=[init_debug_notes, fix_python_syntax_errors])
    agent.interface = """è°ƒè¯•ä¸“å®¶ - ç³»ç»Ÿæ€§ä¿®å¤ä»£ç é”™è¯¯
    
èƒ½åŠ›ï¼š
- ç»´æŠ¤è°ƒè¯•ç¬”è®°é¿å…é‡å¤ä¿®å¤
- æ™ºèƒ½è¯­æ³•é”™è¯¯ä¿®å¤ï¼ˆæ•´æ–‡ä»¶é‡å†™ï¼‰
- ç³»ç»Ÿæ€§é”™è¯¯è¯Šæ–­å’Œä¿®å¤
- ç¡®ä¿100%æµ‹è¯•é€šè¿‡
"""
    
    # ä¸ºè°ƒè¯•Agentæ·»åŠ é¢å¤–çš„ç³»ç»Ÿæç¤ºï¼ŒæŒ‡å¯¼å…¶ä½¿ç”¨æ­£ç¡®çš„å·¥å…·
    agent._system_prompt = (agent._system_prompt or "") + """

## è°ƒè¯•æµç¨‹æŒ‡å¯¼

ä½ å¿…é¡»å®Œæˆå®Œæ•´çš„è°ƒè¯•æµç¨‹ï¼Œä¸è¦åªåˆå§‹åŒ–å°±è¿”å›ï¼

### Pythonè¯­æ³•é”™è¯¯ä¿®å¤ç­–ç•¥ï¼ˆé‡è¦ï¼‰
**ä¼˜å…ˆä½¿ç”¨ fix_python_syntax_errors å·¥å…·ï¼**
- é‡åˆ°ç¼©è¿›é”™è¯¯ï¼ˆIndentationErrorï¼‰ï¼šç«‹å³ä½¿ç”¨ fix_python_syntax_errors å·¥å…·
- é‡åˆ°æ‹¬å·ä¸åŒ¹é…ï¼ˆSyntaxError: unmatchedï¼‰ï¼šç«‹å³ä½¿ç”¨ fix_python_syntax_errors å·¥å…·  
- é‡åˆ°å¤šä¸ªè¯­æ³•é”™è¯¯ï¼šä½¿ç”¨ fix_python_syntax_errors ä¸€æ¬¡æ€§ä¿®å¤æ•´ä¸ªæ–‡ä»¶
- é¿å…ä½¿ç”¨ edit_lines é€è¡Œä¿®å¤è¯­æ³•é”™è¯¯ï¼è¿™ä¼šå¯¼è‡´åå¤ä¿®å¤åŒæ ·çš„é—®é¢˜ã€‚

### æ‰§è¡Œæµç¨‹ï¼ˆå¿…é¡»å…¨éƒ¨å®Œæˆï¼‰
1. è°ƒç”¨ init_debug_notes å·¥å…·åˆå§‹åŒ–è°ƒè¯•ç¬”è®°
2. ä½¿ç”¨ execute_command è¿è¡Œ pytest -xvs è·å–æµ‹è¯•ç»“æœ
3. å¦‚æœæœ‰å¤±è´¥ï¼š
   - å¯¹äºè¯­æ³•é”™è¯¯ï¼šç«‹å³ä½¿ç”¨ fix_python_syntax_errors å·¥å…·
   - å¯¹äºå…¶ä»–é”™è¯¯ï¼šä½¿ç”¨ read_fileã€search_replace æˆ– write_file ä¿®å¤
   - æ›´æ–° debug_notes.json è®°å½•ä¿®å¤å°è¯•
4. å†æ¬¡è¿è¡Œ pytest éªŒè¯ä¿®å¤
5. é‡å¤æ­¥éª¤3-4ç›´åˆ°æ‰€æœ‰æµ‹è¯•é€šè¿‡
6. æ›´æ–°æœ€ç»ˆçš„ debug_notes.json

### è¿”å›æ¡ä»¶
- æˆåŠŸï¼šæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆ0 failedï¼‰ï¼Œè¿”å›"è°ƒè¯•å®Œæˆï¼Œæ‰€æœ‰æµ‹è¯•é€šè¿‡"
- å¤±è´¥ï¼šè¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ï¼ˆ10æ¬¡ï¼‰ï¼Œè¿”å›"éœ€è¦äººå·¥ä»‹å…¥"
- ç»§ç»­ï¼šå¦‚æœéœ€è¦æ›´å¤šæ­¥éª¤ï¼Œè¿”å›"éœ€è¦ç»§ç»­è°ƒè¯•ï¼Œè¯·å†æ¬¡è°ƒç”¨"
"""
    return agent


def create_coordinator_agent(work_dir: str, llm_config: dict, 
                           generation_tool, debug_tool) -> GenericReactAgent:
    """åˆ›å»ºåè°ƒä¸¤ä¸ªå­Agentçš„ä¸»Agent"""
    
    # å¯¼å…¥write_fileå·¥å…·ç”¨äºTODOç®¡ç†
    from langchain_core.tools import tool
    import subprocess
    
    @tool
    def write_todo_file(file_path: str, content: str) -> str:
        """å†™å…¥æˆ–æ›´æ–°TODOæ–‡ä»¶"""
        import os
        full_path = os.path.join(work_dir, file_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"Successfully wrote TODO file: {file_path}"
    
    @tool
    def execute_command(command: str) -> str:
        """æ‰§è¡Œshellå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                command, 
                shell=True, 
                capture_output=True, 
                text=True, 
                timeout=60
            )
            output = f"Command: {command}\n"
            output += f"Return code: {result.returncode}\n"
            if result.stdout:
                output += f"Output:\n{result.stdout}\n"
            if result.stderr:
                output += f"Error:\n{result.stderr}\n"
            return output
        except subprocess.TimeoutExpired:
            return f"Command timed out after 60 seconds: {command}"
        except Exception as e:
            return f"Error executing command: {str(e)}"
    
    # ä¸»Agenté…ç½® - åªè´Ÿè´£åè°ƒ
    config = ReactAgentConfig(
        work_dir=work_dir,
        memory_level=MemoryLevel.SMART,
        knowledge_files=[],  # ä¸»Agentä¸éœ€è¦é¢†åŸŸçŸ¥è¯†
        enable_project_exploration=False,
        **llm_config
    )
    
    # åˆ›å»ºä¸»Agentï¼Œé€šè¿‡æ„é€ å‡½æ•°ä¼ å…¥è‡ªå®šä¹‰å·¥å…·
    agent = GenericReactAgent(
        config, 
        name="coordinator_agent",
        custom_tools=[write_todo_file, execute_command, generation_tool, debug_tool]  # æ·»åŠ write_todo_fileå’Œexecute_commandå·¥å…·
    )
    
    agent.interface = """MDA Pipelineåè°ƒè€…
    
æˆ‘åè°ƒä¸¤ä¸ªä¸“é—¨çš„Agentï¼š
1. ç”ŸæˆAgent - è´Ÿè´£ä»£ç ç”Ÿæˆ
2. è°ƒè¯•Agent - è´Ÿè´£é”™è¯¯ä¿®å¤

å·¥ä½œæµç¨‹ï¼š
1. è°ƒç”¨ç”ŸæˆAgentåˆ›å»ºä»£ç 
2. è¿è¡Œæµ‹è¯•éªŒè¯
3. å¦‚æœ‰å¤±è´¥ï¼Œè°ƒç”¨è°ƒè¯•Agentä¿®å¤
4. å¾ªç¯ç›´åˆ°100%é€šè¿‡
"""
    
    return agent


def main():
    """è¿è¡ŒåŒAgentæ¶æ„çš„MDA Pipeline"""
    
    print("=" * 80)
    print("MDAåŒAgentæ¶æ„æ¼”ç¤º")
    print("=" * 80)
    
    # è®¾ç½®å·¥ä½œç›®å½•
    work_dir = Path("output/mda_dual_agent_demo")
    work_dir.mkdir(parents=True, exist_ok=True)
    
    # PSMæ–‡ä»¶è·¯å¾„ (ä½¿ç”¨å·²æœ‰çš„PSM)
    psm_file = Path(__file__).parent / "output/mda_demo/library_borrowing_system_psm.md"
    
    # é€‰æ‹©LLMé…ç½®
    print("\né€‰æ‹©LLMé…ç½®ï¼š")
    print("1. DeepSeek (é»˜è®¤)")
    print("2. Kimi k2-turbo (128Kä¸Šä¸‹æ–‡)")
    print("3. Gemini 2.5 Pro (via OpenRouter)")
    print("4. Claude Sonnet 4 (via OpenRouter)")
    
    choice = input("è¯·é€‰æ‹© (1-4ï¼Œé»˜è®¤1): ").strip() or "1"
    
    if choice == "2":
        # Kimié…ç½®
        llm_config = {
            "llm_model": "kimi-k2-turbo-preview",
            "llm_base_url": "https://api.moonshot.cn/v1",
            "llm_api_key_env": "MOONSHOT_API_KEY",
            "llm_temperature": 0
        }
        llm_name = "Kimi k2-turbo (128Kä¸Šä¸‹æ–‡)"
    elif choice == "3":
        # Geminié…ç½® (é€šè¿‡OpenRouter)
        llm_config = {
            "llm_model": "google/gemini-2.5-pro",
            "llm_base_url": "https://openrouter.ai/api/v1",
            "llm_api_key_env": "OPENROUTER_API_KEY",
            "llm_temperature": 0
        }
        llm_name = "Gemini 2.5 Pro (via OpenRouter)"
    elif choice == "4":
        # Claudeé…ç½®
        llm_config = {
            "llm_model": "anthropic/claude-sonnet-4",
            "llm_base_url": "https://openrouter.ai/api/v1",
            "llm_api_key_env": "OPENROUTER_API_KEY",
            "llm_temperature": 0
        }
        llm_name = "Claude Sonnet 4"
    else:
        # DeepSeeké…ç½®ï¼ˆé»˜è®¤ï¼‰
        llm_config = {
            "llm_model": "deepseek-chat",
            "llm_base_url": "https://api.deepseek.com/v1",
            "llm_api_key_env": "DEEPSEEK_API_KEY",
            "llm_temperature": 0
        }
        llm_name = "DeepSeek"
    
    print(f"\nä½¿ç”¨ {llm_name} ä½œä¸ºLLMåç«¯")
    
    # åˆ›å»ºå­Agent
    print("\nåˆ›å»ºä¸“é—¨çš„å­Agent...")
    generation_agent = create_generation_agent(str(work_dir), llm_config)
    debug_agent = create_debug_agent(str(work_dir), llm_config)
    
    # å°†å­AgentåŒ…è£…ä¸ºå·¥å…·
    print("å°†å­AgentåŒ…è£…ä¸ºLangChainå·¥å…·...")
    
    # è®¾ç½®Agentçš„åç§°ï¼Œè¿™å°†è¢«create_langchain_toolä½¿ç”¨
    generation_agent.name = "code_generator"
    generation_agent.interface = """ç”Ÿæˆä»£ç çš„ä¸“é—¨Agentï¼Œç”¨äºPSMç”Ÿæˆå’ŒFastAPIä»£ç ç”Ÿæˆ
    
è¾“å…¥ï¼šç”Ÿæˆä»»åŠ¡æè¿°
è¾“å‡ºï¼šç”Ÿæˆçš„ä»£ç æ–‡ä»¶"""
    
    debug_agent.name = "code_debugger" 
    debug_agent.interface = """è°ƒè¯•ä»£ç çš„ä¸“é—¨Agentï¼Œç”¨äºä¿®å¤æµ‹è¯•å¤±è´¥å’Œé”™è¯¯
    
è¾“å…¥ï¼šè°ƒè¯•ä»»åŠ¡æè¿°
è¾“å‡ºï¼šä¿®å¤åçš„ä»£ç å’Œè°ƒè¯•æŠ¥å‘Š"""
    
    generation_tool = create_langchain_tool(generation_agent)
    debug_tool = create_langchain_tool(debug_agent)
    
    # åˆ›å»ºåè°ƒAgent
    print("åˆ›å»ºåè°ƒAgent...")
    coordinator = create_coordinator_agent(
        str(work_dir), 
        llm_config,
        generation_tool,
        debug_tool
    )
    
    # æ‰§è¡Œä»»åŠ¡ - ä½¿ç”¨æ„å›¾å£°æ˜é£æ ¼
    print("\n" + "=" * 60)
    print("å¼€å§‹æ‰§è¡ŒMDA Pipeline...")
    print("=" * 60)
    
    start_time = time.time()
    
    # æ„å›¾å£°æ˜é£æ ¼çš„ä»»åŠ¡æè¿°
    task = f"""
## ç›®æ ‡
ä»PSMæ–‡ä»¶ç”Ÿæˆä¸€ä¸ªå®Œå…¨å¯å·¥ä½œçš„FastAPIåº”ç”¨ï¼Œç¡®ä¿æ‰€æœ‰æµ‹è¯•100%é€šè¿‡ã€‚

## è¾“å…¥
- PSMæ–‡ä»¶ï¼š{psm_file}
- è¾“å‡ºç›®å½•ï¼š{work_dir}


## TODOç®¡ç†è¦æ±‚
ä½ å¿…é¡»åœ¨ {work_dir}/coordinator_todo.json æ–‡ä»¶ä¸­ç»´æŠ¤ä»»åŠ¡æ¸…å•ã€‚

åˆå§‹TODOç»“æ„ï¼š
```json
{{
  "tasks": [
    {{"id": 1, "task": "ç”ŸæˆFastAPIåº”ç”¨ä»£ç ", "status": "pending"}},
    {{"id": 2, "task": "è¿è¡Œpytestæµ‹è¯•éªŒè¯", "status": "pending"}},
    {{"id": 3, "task": "å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œè°ƒç”¨è°ƒè¯•Agentä¿®å¤", "status": "pending"}},
    {{"id": 4, "task": "ç¡®è®¤æ‰€æœ‰æµ‹è¯•100%é€šè¿‡", "status": "pending"}}
  ],
  "current_task": null,
  "completed_count": 0,
  "total_count": 4
}}
```

æ¯æ¬¡å¼€å§‹å’Œå®Œæˆä»»åŠ¡æ—¶ï¼Œä½¿ç”¨ write_todo_file å·¥å…·æ›´æ–°TODOæ–‡ä»¶ï¼š
- å¼€å§‹ä»»åŠ¡æ—¶ï¼šè®¾ç½® status = "in_progress"ï¼Œæ›´æ–° current_task
- å®Œæˆä»»åŠ¡æ—¶ï¼šè®¾ç½® status = "completed"ï¼Œæ›´æ–° completed_count
- è·³è¿‡ä»»åŠ¡æ—¶ï¼šè®¾ç½® status = "skipped"

## æ‰§è¡Œç­–ç•¥
ä½ æœ‰å››ä¸ªå·¥å…·å¯ä»¥ä½¿ç”¨ï¼š
1. **write_todo_file** - ç”¨äºåˆ›å»ºå’Œæ›´æ–°TODOç¬”è®°
2. **code_generator** - ç”¨äºç”Ÿæˆä»£ç 
3. **execute_command** - ç”¨äºè¿è¡Œå‘½ä»¤ï¼ˆå¦‚pytestï¼‰  
4. **code_debugger** - ç”¨äºä¿®å¤æµ‹è¯•å¤±è´¥

è¯·æŒ‰ç…§ä»¥ä¸‹æµç¨‹æ‰§è¡Œï¼š
1. é¦–å…ˆï¼Œåˆ›å»ºTODOç¬”è®°æ–‡ä»¶
2. ä½¿ç”¨ code_generator ç”ŸæˆFastAPIåº”ç”¨ï¼ˆæ›´æ–°TODOï¼šä»»åŠ¡1å®Œæˆï¼‰
3. ä½¿ç”¨ execute_command è¿è¡Œ `cd {work_dir} && python -m pytest tests/ -xvs` éªŒè¯ä»£ç ï¼ˆæ›´æ–°TODOï¼šä»»åŠ¡2å®Œæˆï¼‰
4. å¦‚æœæµ‹è¯•æœ‰å¤±è´¥ï¼š
   - ä½¿ç”¨ code_debugger ä¿®å¤æ‰€æœ‰é”™è¯¯ï¼Œä¼ é€’æ˜ç¡®çš„ä»»åŠ¡ï¼š
     "ä¿®å¤æµ‹è¯•é”™è¯¯ç›´åˆ°å…¨éƒ¨é€šè¿‡ã€‚ä½ å¿…é¡»å®Œæˆæ•´ä¸ªè°ƒè¯•æµç¨‹ï¼Œä¸è¦åªåˆå§‹åŒ–å°±è¿”å›ã€‚
      
      ã€é‡è¦ã€‘ä½ æœ‰ä¸€ä¸ªä¸“é—¨çš„å·¥å…· fix_python_syntax_errors ç”¨äºä¿®å¤Pythonè¯­æ³•é”™è¯¯ï¼š
      - é‡åˆ°ä»»ä½•ç¼©è¿›é”™è¯¯ï¼ˆIndentationErrorï¼‰ï¼šä½¿ç”¨ fix_python_syntax_errors å·¥å…·
      - é‡åˆ°æ‹¬å·ä¸åŒ¹é…ï¼ˆSyntaxErrorï¼‰ï¼šä½¿ç”¨ fix_python_syntax_errors å·¥å…·
      - è¿™ä¸ªå·¥å…·ä¼šè‡ªåŠ¨é‡å†™æ•´ä¸ªæ–‡ä»¶ï¼Œé¿å…é€è¡Œä¿®å¤çš„é—®é¢˜
      
      ä½¿ç”¨ä½ çš„æ‰€æœ‰å·¥å…·ï¼Œç‰¹åˆ«æ˜¯ fix_python_syntax_errors å¤„ç†è¯­æ³•é”™è¯¯ã€‚
      æŒç»­ä¿®å¤ç›´åˆ°æ‰€æœ‰æµ‹è¯•é€šè¿‡æˆ–è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ã€‚"
   - å¦‚æœ code_debugger è¿”å›"éœ€è¦ç»§ç»­è°ƒè¯•"ï¼Œç«‹å³å†æ¬¡è°ƒç”¨å®ƒ
   - å¾ªç¯è°ƒç”¨ code_debugger ç›´åˆ°è¿”å›"è°ƒè¯•å®Œæˆ"æˆ–"éœ€è¦äººå·¥ä»‹å…¥"
   - å†æ¬¡ä½¿ç”¨ execute_command è¿è¡Œæµ‹è¯•ç¡®è®¤ä¿®å¤æˆåŠŸ
   - æ£€æŸ¥ debug_notes.json ç¡®è®¤è°ƒè¯•Agentè®°å½•äº†æ‰€æœ‰æ´»åŠ¨
5. ç¡®è®¤æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆæ›´æ–°TODOï¼šä»»åŠ¡4å®Œæˆï¼‰

## é‡è¦æç¤º
- æ¯ä¸ªä»»åŠ¡å¼€å§‹å’Œç»“æŸéƒ½è¦æ›´æ–°TODOç¬”è®°
- å¿…é¡»å®Œæˆæ•´ä¸ªæµç¨‹ï¼Œä¸è¦åœ¨ç”Ÿæˆä»£ç åå°±åœæ­¢
- å¿…é¡»å®é™…è¿è¡Œæµ‹è¯•å¹¶æŸ¥çœ‹ç»“æœ
- å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œå¿…é¡»è°ƒç”¨è°ƒè¯•Agentä¿®å¤
- **ç»å¯¹ä¸è¦è‡ªå·±ä½¿ç”¨sedæˆ–å…¶ä»–å‘½ä»¤ä¿®æ”¹ä»£ç ï¼Œåªèƒ½é€šè¿‡code_debuggerä¿®å¤**
- **å¦‚æœcode_debuggeréœ€è¦æ›´å¤šæ­¥éª¤ï¼Œå¿…é¡»ç»§ç»­è°ƒç”¨å®ƒï¼Œä¸è¦æ”¾å¼ƒ**
- åªæœ‰å½“çœ‹åˆ°æ‰€æœ‰æµ‹è¯•é€šè¿‡æ‰èƒ½ç»“æŸä»»åŠ¡

ç°åœ¨å¼€å§‹æ‰§è¡Œï¼Œè®°å¾—ç»´æŠ¤TODOç¬”è®°ï¼Œç¡®ä¿è¾¾åˆ°100%æµ‹è¯•é€šè¿‡çš„ç›®æ ‡ã€‚

## æˆåŠŸæ ‡å‡†
- TODOåˆ—è¡¨ä¸­çš„æ¯ä¸€é¡¹ä»»åŠ¡éƒ½å¿…é¡»å®Œæˆï¼ˆstatusä¸º"completed"æˆ–"skipped"ï¼‰
- FastAPIåº”ç”¨æˆåŠŸç”Ÿæˆåœ¨æŒ‡å®šç›®å½•
- è¿è¡Œ `pytest tests/ -xvs` æ‰€æœ‰æµ‹è¯•å¿…é¡»é€šè¿‡ï¼ˆ0ä¸ªå¤±è´¥ï¼‰
- å¦‚æœæœ‰æµ‹è¯•å¤±è´¥ï¼Œå¿…é¡»ä¿®å¤ç›´åˆ°100%é€šè¿‡
- coordinator_todo.json çš„ completed_count å¿…é¡»ç­‰äº total_count

"""
    
    try:
        # æ‰§è¡Œå®Œæ•´ä»»åŠ¡
        result = coordinator.execute_task(task)
        
        elapsed_time = time.time() - start_time
        
        print("\n" + "=" * 60)
        print("æ‰§è¡Œå®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è€—æ—¶ï¼š{elapsed_time:.1f} ç§’")
        
        # æ£€æŸ¥åè°ƒAgentçš„TODOç¬”è®°
        todo_file = work_dir / "coordinator_todo.json"
        if todo_file.exists():
            with open(todo_file, 'r') as f:
                todo_data = json.load(f)
            
            print("\nğŸ“‹ ä»»åŠ¡å®Œæˆæƒ…å†µï¼ˆcoordinator_todo.jsonï¼‰ï¼š")
            for task in todo_data.get('tasks', []):
                status_emoji = {
                    'completed': 'âœ…',
                    'in_progress': 'ğŸ”„',
                    'pending': 'â³',
                    'skipped': 'â­ï¸'
                }.get(task['status'], 'â“')
                print(f"  {status_emoji} {task['task']} [{task['status']}]")
            
            print(f"\nå®Œæˆè¿›åº¦ï¼š{todo_data.get('completed_count', 0)}/{todo_data.get('total_count', 0)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è°ƒè¯•ç¬”è®°ï¼ˆè°ƒè¯•Agentå¿…é¡»åˆ›å»ºçš„ï¼‰
        debug_notes_file = work_dir / "debug_notes.json"
        if debug_notes_file.exists():
            with open(debug_notes_file, 'r') as f:
                notes = json.load(f)
            
            print("\nğŸ”§ è°ƒè¯•ç»Ÿè®¡ï¼ˆdebug_notes.jsonï¼‰ï¼š")
            print(f"- è¿­ä»£æ¬¡æ•°ï¼š{notes.get('current_iteration', 0)}")
            print(f"- ä¿®å¤å°è¯•ï¼š{len(notes.get('fix_attempts', []))}")
            print(f"- é”™è¯¯ç±»å‹ï¼š{len(notes.get('error_history', {}))}")
            
            # æ˜¾ç¤ºæˆåŠŸç­–ç•¥
            successful = [a for a in notes.get('fix_attempts', []) 
                         if a.get('result') == 'success']
            if successful:
                print(f"\næˆåŠŸçš„ä¿®å¤ç­–ç•¥ï¼š")
                for s in successful[:3]:
                    print(f"  - {s.get('strategy', 'unknown')}")
        
        print("\nç»“æœæ‘˜è¦ï¼š")
        print(result[:500] if len(result) > 500 else result)
        
    except Exception as e:
        print(f"\næ‰§è¡Œå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        
    print("finished")


if __name__ == "__main__":
    main()