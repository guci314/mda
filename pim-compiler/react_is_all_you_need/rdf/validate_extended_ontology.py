#!/usr/bin/env python3
"""
éªŒè¯æ‰©å±•æœ¬ä½“çš„ä¸€è‡´æ€§å’Œè´¨é‡
æ£€æŸ¥é™æ€æ ¸å¿ƒ + åŠ¨æ€æ‰©å±•çš„ç»“æ„
"""

import rdflib
from rdflib import Namespace, RDF, RDFS
from collections import defaultdict

def validate_extended_ontology(ttl_file):
    """éªŒè¯æ‰©å±•æœ¬ä½“"""
    
    # åŠ è½½RDFå›¾
    g = rdflib.Graph()
    g.parse(ttl_file, format="turtle")
    
    # å®šä¹‰å‘½åç©ºé—´
    CORE = Namespace("http://ontology.core#")
    ONTO = Namespace("http://ontology.meta#")
    EXT = Namespace("http://ontology.ext#")
    
    print("=" * 60)
    print("æ‰©å±•æœ¬ä½“éªŒè¯æŠ¥å‘Š")
    print("=" * 60)
    
    # 1. éªŒè¯é™æ€æ ¸å¿ƒ
    print("\n1. é™æ€æ ¸å¿ƒæœ¬ä½“éªŒè¯")
    print("-" * 40)
    
    core_concepts = [
        "Thing", "Entity", "Concept",
        "Relation", "partOf", "instanceOf", "relatedTo",
        "Process", "causes", "transformsTo"
    ]
    
    found_core = 0
    for concept in core_concepts:
        if (CORE[concept], RDF.type, None) in g or \
           (CORE[concept], RDFS.subClassOf, None) in g or \
           (CORE[concept], RDFS.subPropertyOf, None) in g:
            print(f"âœ… core:{concept}")
            found_core += 1
        else:
            print(f"âŒ ç¼ºå¤±: core:{concept}")
    
    print(f"\næ ¸å¿ƒæ¦‚å¿µè¦†ç›–ç‡: {found_core}/{len(core_concepts)}")
    
    # 2. éªŒè¯åŠ¨æ€æ‰©å±•
    print("\n2. åŠ¨æ€æ‰©å±•éªŒè¯")
    print("-" * 40)
    
    extensions = []
    for s, p, o in g:
        if str(s).startswith(str(EXT)):
            if p == RDF.type and o == RDFS.Class:
                concept_name = str(s).split('#')[-1]
                extensions.append(concept_name)
                
                # æ£€æŸ¥å¿…éœ€çš„è‡ªç„¶è¯­è¨€è¯´æ˜
                has_nl_desc = (s, ONTO.nlDescription, None) in g
                has_nl_context = (s, ONTO.nlContext, None) in g
                has_nl_example = (s, ONTO.nlExample, None) in g
                has_embedding = (s, ONTO.embedding, None) in g
                has_confidence = (s, ONTO.confidence, None) in g
                
                print(f"\næ‰©å±•æ¦‚å¿µ: ext:{concept_name}")
                
                # è·å–çˆ¶ç±»
                parent = g.value(s, RDFS.subClassOf)
                if parent:
                    parent_name = str(parent).split('#')[-1]
                    print(f"  çˆ¶ç±»: core:{parent_name}")
                
                # è·å–æè¿°
                nl_desc = g.value(s, ONTO.nlDescription)
                if nl_desc:
                    print(f"  æè¿°: {nl_desc[:60]}...")
                
                # è·å–ç½®ä¿¡åº¦
                confidence = g.value(s, ONTO.confidence)
                if confidence:
                    conf_val = float(confidence)
                    status = "âœ… è‡ªåŠ¨æ¥å—" if conf_val >= 0.8 else "âš ï¸ éœ€è¦å®¡æ ¸"
                    print(f"  ç½®ä¿¡åº¦: {conf_val} ({status})")
                
                # éªŒè¯å®Œæ•´æ€§
                completeness = []
                if has_nl_desc: completeness.append("æè¿°")
                if has_nl_context: completeness.append("è¯­å¢ƒ")
                if has_nl_example: completeness.append("ç¤ºä¾‹")
                if has_embedding: completeness.append("å‘é‡")
                if has_confidence: completeness.append("ç½®ä¿¡åº¦")
                
                print(f"  å®Œæ•´æ€§: [{', '.join(completeness)}]")
    
    print(f"\nåŠ¨æ€æ‰©å±•æ€»æ•°: {len(extensions)}")
    
    # 3. éªŒè¯ç»§æ‰¿å…³ç³»
    print("\n3. ç»§æ‰¿å…³ç³»éªŒè¯")
    print("-" * 40)
    
    inheritance = defaultdict(list)
    for s, p, o in g:
        if p == RDFS.subClassOf:
            child = str(s).split('#')[-1]
            parent = str(o).split('#')[-1]
            inheritance[parent].append(child)
    
    # æ˜¾ç¤ºç»§æ‰¿æ ‘
    def print_tree(node, prefix="", visited=None):
        if visited is None:
            visited = set()
        if node in visited:
            return
        visited.add(node)
        
        print(f"{prefix}{node}")
        children = inheritance.get(node, [])
        for i, child in enumerate(children):
            is_last = i == len(children) - 1
            child_prefix = prefix + ("â””â”€â”€ " if is_last else "â”œâ”€â”€ ")
            next_prefix = prefix + ("    " if is_last else "â”‚   ")
            print_tree(child, child_prefix, visited)
    
    print("\nç»§æ‰¿æ ‘:")
    print_tree("Thing", "")
    
    # 4. ç»Ÿè®¡åˆ†æ
    print("\n4. ç»Ÿè®¡åˆ†æ")
    print("-" * 40)
    
    # ç»Ÿè®¡å„å‘½åç©ºé—´çš„ä½¿ç”¨
    ns_stats = defaultdict(int)
    for s, p, o in g:
        for term in [s, p, o]:
            if isinstance(term, rdflib.URIRef):
                ns = str(term).split('#')[0] + '#'
                if 'ontology' in ns:
                    ns_name = ns.split('/')[-1].replace('#', '')
                    ns_stats[ns_name] += 1
    
    print("\nå‘½åç©ºé—´ä½¿ç”¨:")
    for ns, count in sorted(ns_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  {ns}: {count} æ¬¡")
    
    # 5. è´¨é‡è¯„ä¼°
    print("\n5. è´¨é‡è¯„ä¼°")
    print("-" * 40)
    
    issues = []
    warnings = []
    
    # æ£€æŸ¥æ‰©å±•æ˜¯å¦éƒ½æœ‰çˆ¶ç±»
    for ext in extensions:
        ext_uri = EXT[ext]
        if not g.value(ext_uri, RDFS.subClassOf):
            issues.append(f"æ‰©å±• {ext} æ²¡æœ‰çˆ¶ç±»")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å­¤ç«‹æ¦‚å¿µ
    for s in g.subjects(RDF.type, RDFS.Class):
        if str(s).startswith(str(EXT)):
            has_instances = False
            for _, _, o in g.triples((None, RDF.type, s)):
                has_instances = True
                break
            if not has_instances:
                name = str(s).split('#')[-1]
                warnings.append(f"æ‰©å±•æ¦‚å¿µ {name} æ²¡æœ‰å®ä¾‹")
    
    if issues:
        print("\nâŒ å‘ç°é—®é¢˜:")
        for issue in issues:
            print(f"  - {issue}")
    
    if warnings:
        print("\nâš ï¸ è­¦å‘Š:")
        for warning in warnings[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - {warning}")
        if len(warnings) > 5:
            print(f"  ... è¿˜æœ‰ {len(warnings) - 5} ä¸ªè­¦å‘Š")
    
    if not issues:
        print("\nâœ… æœ¬ä½“ç»“æ„éªŒè¯é€šè¿‡!")
        print("  - é™æ€æ ¸å¿ƒå®Œæ•´")
        print("  - åŠ¨æ€æ‰©å±•è§„èŒƒ")
        print("  - ç»§æ‰¿å…³ç³»æ­£ç¡®")
        print("  - è‡ªç„¶è¯­è¨€è¯´æ˜å®Œå¤‡")
    
    # 6. æ€»ç»“
    print("\n" + "=" * 60)
    print("éªŒè¯æ€»ç»“")
    print("=" * 60)
    print(f"æ€»ä¸‰å…ƒç»„æ•°: {len(g)}")
    print(f"æ ¸å¿ƒæ¦‚å¿µ: {found_core}")
    print(f"æ‰©å±•æ¦‚å¿µ: {len(extensions)}")
    print(f"ä¸¥é‡é—®é¢˜: {len(issues)}")
    print(f"è­¦å‘Šæ•°é‡: {len(warnings)}")
    
    return len(issues) == 0

if __name__ == "__main__":
    ttl_file = "/tmp/knowledge_extended.ttl"
    success = validate_extended_ontology(ttl_file)
    
    if success:
        print("\nğŸ‰ æ‰©å±•æœ¬ä½“éªŒè¯æˆåŠŸ!")
    else:
        print("\nâš ï¸ æ‰©å±•æœ¬ä½“å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥")