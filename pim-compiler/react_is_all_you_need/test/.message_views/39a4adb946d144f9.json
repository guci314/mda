{
  "id": "39a4adb946d144f9",
  "timestamp": "2025-08-19T21:57:01.380986",
  "metadata": {
    "role": "tool",
    "round": 65,
    "importance": null
  },
  "views": {
    "FULL": {
      "content": {
        "role": "tool",
        "tool_call_id": "call_590632dc902b45f4b94450da",
        "name": "read_file",
        "content": "#!/usr/bin/env python3\n\"\"\"\n统一的记忆管理器\n自动配置和管理状态记忆与过程记忆\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom .vscode_memory import VSCodeMemory, Resolution\nfrom .vscode_memory_async import AsyncVSCodeMemory\nfrom .process_memory import ProcessMemory, MessageImportance\nfrom .async_memory_processor import AsyncMemoryProcessor, ClarityLevel\n\nclass MemoryMode(Enum):\n    \"\"\"记忆模式\"\"\"\n    DISABLED = \"disabled\"           # 禁用记忆\n    BASIC = \"basic\"                 # 基础模式（传统压缩）\n    HYBRID = \"hybrid\"               # 混合模式（部分预计算）\n    FULL_ASYNC = \"full_async\"       # 完整异步（全部预计算）\n    AUTO = \"auto\"                   # 自动选择\n\nclass MemoryManager:\n    \"\"\"统一的记忆管理器\"\"\"\n    \n    def __init__(self,\n                 work_dir: str,\n                 mode: MemoryMode = MemoryMode.AUTO,\n                 max_context_tokens: int = 262144,\n                 enable_cache: bool = True):\n        \"\"\"\n        初始化记忆管理器\n        \n        Args:\n            work_dir: 工作目录\n            mode: 记忆模式\n            max_context_tokens: 最大上下文tokens\n            enable_cache: 是否启用缓存\n        \"\"\"\n        self.work_dir = Path(work_dir)\n        self.work_dir.mkdir(parents=True, exist_ok=True)\n        \n        self.max_context_tokens = max_context_tokens\n        self.enable_cache = enable_cache\n        \n        # 根据模式自动配置\n        if mode == MemoryMode.AUTO:\n            self.mode = self._auto_select_mode()\n        else:\n            self.mode = mode\n        \n        # 初始化记忆组件\n        self._initialize_components()\n        \n        # 显示配置信息\n        self._show_configuration()\n    \n    def _auto_select_mode(self) -> MemoryMode:\n        \"\"\"自动选择最佳记忆模式\"\"\"\n        # 检查系统资源\n        import multiprocessing\n        cpu_count = multiprocessing.cpu_count()\n        \n        # 检查上下文大小\n        if self.max_context_tokens >= 200000:\n            # 大上下文，需要高性能\n            if cpu_count >= 4:\n                return MemoryMode.FULL_ASYNC\n            else:\n                return MemoryMode.HYBRID\n        elif self.max_context_tokens >= 50000:\n            # 中等上下文\n            return MemoryMode.HYBRID\n        else:\n            # 小上下文\n            return MemoryMode.BASIC\n    \n    def _initialize_components(self):\n        \"\"\"初始化记忆组件\"\"\"\n        self.state_memory = None\n        self.process_memory = None\n        self.async_processor = None\n        \n        if self.mode == MemoryMode.DISABLED:\n            return\n        \n        # 状态记忆配置\n        if self.mode == MemoryMode.FULL_ASYNC:\n            # 完整异步模式\n            self.state_memory = AsyncVSCodeMemory(\n                self.work_dir,\n                max_context_tokens=self.max_context_tokens\n            )\n            self.async_processor = AsyncMemoryProcessor(\n                cache_dir=self.work_dir / \".message_views\",\n                max_workers=4\n            )\n        \n        elif self.mode == MemoryMode.HYBRID:\n            # 混合模式 - 过程记忆用异步，状态记忆用传统\n            self.state_memory = VSCodeMemory(\n                self.work_dir,\n                max_context_tokens=self.max_context_tokens\n            )\n            self.async_processor = AsyncMemoryProcessor(\n                cache_dir=self.work_dir / \".message_views\",\n                max_workers=2\n            )\n        \n        elif self.mode == MemoryMode.BASIC:\n            # 基础模式 - 全部用传统压缩\n            self.state_memory = VSCodeMemory(\n                self.work_dir,\n                max_context_tokens=self.max_context_tokens\n            )\n            self.process_memory = ProcessMemory(\n                max_context_tokens=self.max_context_tokens\n            )\n    \n    def _show_configuration(self):\n        \"\"\"显示配置信息\"\"\"\n        if self.mode == MemoryMode.DISABLED:\n            print(\"ℹ️ 记忆系统已禁用\")\n            return\n        \n        mode_names = {\n            MemoryMode.BASIC: \"基础模式\",\n            MemoryMode.HYBRID: \"混合模式\",\n            MemoryMode.FULL_ASYNC: \"完整异步模式\"\n        }\n        \n        icons = {\n            MemoryMode.BASIC: \"✅\",\n            MemoryMode.HYBRID: \"⚡\",\n            MemoryMode.FULL_ASYNC: \"🚀\"\n        }\n        \n        print(f\"{icons[self.mode]} 记忆系统已启用 - {mode_names[self.mode]}\")\n        \n        # 显示详细配置\n        if self.state_memory:\n            state_type = \"异步VSCode\" if isinstance(self.state_memory, AsyncVSCodeMemory) else \"VSCode\"\n            print(f\"  - 状态记忆: {state_type}（潜意识/显意识）\")\n        \n        if self.async_processor:\n            print(f\"  - 过程记忆: 异步多视图（5级清晰度）\")\n        elif self.process_memory:\n            print(f\"  - 过程记忆: 时间衰减压缩\")\n        \n        if self.enable_cache and self.async_processor:\n            print(f\"  - 视图缓存: {self.work_dir}/.message_views\")\n        \n        print(f\"  - 上下文限制: {self.max_context_tokens:,} tokens\")\n    \n    # ========== 状态记忆接口 ==========\n    \n    def open_file(self, file_path: str, content: str):\n        \"\"\"打开文件到记忆\"\"\"\n        if self.state_memory:\n            self.state_memory.open_file(file_path, content)\n    \n    def close_file(self, file_path: str):\n        \"\"\"关闭文件\"\"\"\n        if self.state_memory:\n            self.state_memory.close_file(file_path)\n    \n    def search(self, query: str) -> List[Dict]:\n        \"\"\"搜索记忆\"\"\"\n        if self.state_memory:\n            return self.state_memory.search(query)\n        return []\n    \n    def save_episode(self, event: str, data: Dict):\n        \"\"\"保存事件\"\"\"\n        if self.state_memory:\n            self.state_memory.save_episode(event, data)\n    \n    def save_state(self, state_name: str, state_data: Dict):\n        \"\"\"保存状态快照\"\"\"\n        if self.state_memory:\n            self.state_memory.save_state(state_name, state_data)\n    \n    # ========== 过程记忆接口 ==========\n    \n    def add_message(self, message: Dict, importance: Optional[str] = None):\n        \"\"\"添加消息到过程记忆\"\"\"\n        if self.async_processor:\n            # 使用异步处理器\n            return self.async_processor.add_message(message, importance)\n        # ProcessMemory不存储消息，只在压缩时处理\n    \n    def compress_messages(self, messages: List[Dict]) -> Tuple[List[Dict], Dict]:\n        \"\"\"压缩消息历史\"\"\"\n        if self.async_processor:\n            # 使用异步处理器的优化历史\n            optimized = self.async_processor.get_optimized_history(\n                max_tokens=int(self.max_context_tokens * 0.8),\n                time_decay=True\n            )\n            stats = self.async_processor.get_statistics()\n            return optimized, {\n                \"original_count\": len(messages),\n                \"compressed_count\": len(optimized),\n                \"compression_ratio\": 1 - len(optimized) / max(len(messages), 1)\n            }\n        elif self.process_memory:\n            # 使用传统压缩\n            return self.process_memory.compress_messages(messages)\n        else:\n            # 无压缩\n            return messages, {\"original_count\": len(messages), \"compressed_count\": len(messages)}\n    \n    # ========== 统一接口 ==========\n    \n    def get_memory_context(self, extra_tokens: int = 0) -> str:\n        \"\"\"获取记忆上下文（用于系统提示词）\"\"\"\n        if not self.state_memory:\n            return \"\"\n        \n        # 根据记忆类型选择压缩方法\n        if isinstance(self.state_memory, AsyncVSCodeMemory):\n            # 使用优化压缩\n            return self.state_memory.compress_for_llm_optimized(\n                extra_tokens=extra_tokens,\n                target_resolution={\n                    \"detail_view\": Resolution.FULL,\n                    \"working_set\": Resolution.PREVIEW,\n                    \"resource_outline\": Resolution.OUTLINE,\n                    \"action_history\": Resolution.PREVIEW,\n                    \"findings\": Resolution.PREVIEW,\n                    \"overview\": Resolution.FULL\n                }\n            )\n        else:\n            # 使用传统压缩\n            return self.state_memory.compress_for_llm(extra_tokens=extra_tokens)\n    \n    def optimize_message_history(self, messages: List[Dict], protected_count: int = 2) -> List[Dict]:\n        \"\"\"优化消息历史\"\"\"\n        if len(messages) <= protected_count:\n            return messages\n        \n        # 保护前N条消息\n        protected = messages[:protected_count]\n        optimizable = messages[protected_count:]\n        \n        # 优化可优化部分\n        if self.async_processor:\n            # 确保消息都在处理器中\n            for msg in optimizable:\n                if msg not in self.async_processor.messages:\n                    self.async_processor.add_message(msg)\n            \n            # 获取优化历史\n            optimized = self.async_processor.get_optimized_history(\n                max_tokens=int(self.max_context_tokens * 0.7),\n                time_decay=True\n            )\n        else:\n            # 使用传统压缩或不压缩\n            optimized = optimizable\n        \n        # 重组消息\n        result = protected + optimized\n        \n        # 插入当前状态记忆\n        memory_context = self.get_memory_context(10000)\n        if memory_context:\n            result.insert(protected_count, {\n                \"role\": \"system\",\n                \"content\": f\"[当前状态记忆]\\n{memory_context}\"\n            })\n        \n        return result\n    \n    def should_optimize(self, round_num: int, message_count: int) -> bool:\n        \"\"\"判断是否需要优化\"\"\"\n        if self.mode == MemoryMode.DISABLED:\n            return False\n        \n        # 根据模式调整优化频率\n        if self.mode == MemoryMode.FULL_ASYNC:\n            # 异步模式效率高，可以降低频率\n            return round_num % 50 == 0 and round_num > 0\n        elif self.mode == MemoryMode.HYBRID:\n            # 混合模式\n            return round_num % 30 == 0 and round_num > 0\n        else:\n            # 基础模式，需要更频繁\n            return round_num % 20 == 0 and round_num > 0\n    \n    def get_status(self) -> Dict:\n        \"\"\"获取记忆系统状态\"\"\"\n        status = {\n            \"mode\": self.mode.value,\n            \"enabled\": self.mode != MemoryMode.DISABLED\n        }\n        \n        if self.state_memory:\n            session = self.state_memory.export_session()\n            status[\"state_memory\"] = {\n                \"type\": type(self.state_memory).__name__,\n                \"working_set\": len(self.state_memory.consciousness.get(\"working_set\", [])),\n                \"current_focus\": self.state_memory.attention.get(\"focus\"),\n                \"episodes\": len(self.state_memory.index.get(\"episodes\", [])),\n                \"states\": len(self.state_memory.index.get(\"states\", []))\n            }\n        \n        if self.async_processor:\n            stats = self.async_processor.get_statistics()\n            status[\"async_processor\"] = {\n                \"enabled\": True,\n                \"messages\": stats[\"total_messages\"],\n                \"views_generated\": stats[\"completed_views\"],\n                \"completion_rate\": f\"{stats['completion_rate']:.1%}\",\n                \"cache_enabled\": stats[\"cache_enabled\"]\n            }\n        elif self.process_memory:\n            status[\"process_memory\"] = {\n                \"enabled\": True,\n                \"messages\": len(getattr(self.process_memory, 'messages', []))\n            }\n        \n        return status\n    \n    def cleanup(self):\n        \"\"\"清理资源\"\"\"\n        if self.async_processor:\n            self.async_processor.cleanup()\n        \n        if self.state_memory:\n            if isinstance(self.state_memory, AsyncVSCodeMemory):\n                self.state_memory.cleanup()\n            else:\n                self.state_memory.garbage_collect()"
      },
      "tokens": 3677,
      "generated_at": "2025-08-19T21:57:01.381229"
    },
    "MINIMAL": {
      "content": {
        "marker": "[tool:result]"
      },
      "tokens": 5,
      "generated_at": "2025-08-19T21:57:01.381255"
    },
    "HIGH": {
      "content": {
        "role": "tool",
        "content": "#!/usr/bin/env python3\n\"\"\"\n统一的记忆管理器\n自动配置和管理状态记忆与过程记忆\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom .vscode_memory import VSCodeMemory, Resolution\nfrom .vscode_memory_async import AsyncVSCodeMemory\nfrom .process_memory import ProcessMemory, MessageImportance\nfrom .async_memory_processor import AsyncMemoryProcessor, ClarityLevel\n\nclass MemoryMode(Enum):\n    \"\"\"记忆模式\"\"\"\n    DISABLED = \"disabled\"           # 禁用记忆\n    BASIC = \"basic\"                 # 基础模式（传统压缩）\n    HYBRID = \"hybrid\"              \n...[部分内容省略]...\nif self.state_memory:\n            if isinstance(self.state_memory, AsyncVSCodeMemory):\n                self.state_memory.cleanup()\n            else:\n                self.state_memory.garbage_collect()"
      },
      "tokens": 283,
      "generated_at": "2025-08-19T21:57:01.474692"
    },
    "MEDIUM": {
      "content": {
        "role": "tool",
        "content_preview": "#!/usr/bin/env python3\n\"\"\"\n统一的记忆管理器\n自动配置和管理状态记忆与过程记忆\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom .vscode_memory import VSCodeMemory, Resolution\nfrom .vscode_memory_async import AsyncVSCodeMemory..."
      },
      "tokens": 120,
      "generated_at": "2025-08-19T21:57:01.474739"
    },
    "LOW": {
      "content": {
        "role": "tool",
        "summary": "工具返回结果"
      },
      "tokens": 16,
      "generated_at": "2025-08-19T21:57:01.475014"
    }
  }
}