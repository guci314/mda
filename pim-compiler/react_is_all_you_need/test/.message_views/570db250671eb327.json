{
  "id": "570db250671eb327",
  "timestamp": "2025-08-19T21:57:10.955924",
  "metadata": {
    "role": "tool",
    "round": 69,
    "importance": null
  },
  "views": {
    "FULL": {
      "content": {
        "role": "tool",
        "tool_call_id": "call_4a380dc77b0d4705b6ca6ce3",
        "name": "read_file",
        "content": "#!/usr/bin/env python3\n\"\"\"\nVSCode记忆模式 - 基于VSCode的内存管理模式\n模拟人类思维的潜意识(文件系统)和显意识(工作界面)\n\n设计理念：\n- 潜意识(文件系统): 持久化存储，完整但访问较慢\n- 显意识(界面): 内存中的活跃内容，快速访问但容量有限\n- 动态分辨率: 根据注意力焦点动态调整信息清晰度\n\"\"\"\n\nimport json\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime\nfrom enum import Enum\n\nclass Resolution(Enum):\n    \"\"\"信息分辨率级别\"\"\"\n    TITLE = 1      # 仅标题 (~10 tokens)\n    OUTLINE = 2    # 大纲 (~50 tokens)  \n    PREVIEW = 3    # 预览 (~200 tokens)\n    FULL = 4       # 完整内容\n\nclass VSCodeMemory:\n    \"\"\"VSCode记忆模式实现\"\"\"\n    \n    def __init__(self, workspace_dir: Path, max_context_tokens: int = 262144):\n        \"\"\"\n        初始化VSCode记忆系统\n        \n        Args:\n            workspace_dir: 工作目录(潜意识存储位置)\n            max_context_tokens: 最大上下文tokens数 (默认262k for Qwen3-Coder)\n        \"\"\"\n        self.workspace_dir = Path(workspace_dir)\n        self.memory_dir = self.workspace_dir / \".vscode_memory\"\n        self.memory_dir.mkdir(parents=True, exist_ok=True)\n        \n        # 潜意识层 - 文件系统存储\n        self.filesystem = {\n            \"episodes\": self.memory_dir / \"episodes\",      # 事件记忆\n            \"states\": self.memory_dir / \"states\",         # 状态快照\n            \"knowledge\": self.memory_dir / \"knowledge\",   # 知识库\n            \"workspace\": self.memory_dir / \"workspace\"    # 工作文件\n        }\n        \n        # 创建目录结构\n        for dir_path in self.filesystem.values():\n            dir_path.mkdir(parents=True, exist_ok=True)\n        \n        # 显意识层 - 工作记忆\n        self.consciousness = {\n            # 结构认知层\n            \"resource_outline\": [],  # 资源大纲(文件树结构、类/函数列表等)\n            \"overview\": [],         # 全局概览(项目摘要、关键指标等)\n            \n            # 工作记忆层\n            \"working_set\": [],      # 工作集(当前任务涉及的活跃项目)\n            \"focus_item\": None,     # 焦点项(正在编辑/分析的具体内容)\n            \"detail_view\": None,    # 详细视图(焦点项的完整内容)\n            \n            # 操作记录层\n            \"action_history\": [],   # 行动历史(最近执行的操作)\n            \"issues\": [],           # 待解决问题(错误、警告、TODO等)\n            \"findings\": []          # 发现(搜索结果、分析洞察等)\n        }\n        \n        # 注意力管理\n        self.attention = {\n            \"focus\": None,        # 当前焦点\n            \"context\": [],        # 上下文相关项\n            \"recent\": []          # 最近访问\n        }\n        \n        # Token预算管理 - 根据max_context_tokens动态调整\n        self.max_tokens = max_context_tokens\n        \n        # 为大context模型(>100k)调整预算分配\n        if max_context_tokens > 100000:\n            # Qwen3-Coder等大模型可以分配更多tokens\n            self.token_budget = {\n                \"resource_outline\": 3000,  # 资源大纲预算\n                \"overview\": 2000,          # 全局概览预算\n                \"working_set\": 10000,      # 工作集预算\n                \"detail\": 50000,           # 详细内容预算\n                \"context\": 20000,          # 相关上下文预算\n                \"history\": 10000           # 历史记录预算\n            }\n        else:\n            # 标准模型的预算分配\n            self.token_budget = {\n                \"resource_outline\": 800,   # 资源大纲预算\n                \"overview\": 500,           # 全局概览预算\n                \"working_set\": 2000,       # 工作集预算\n                \"detail\": 8000,            # 详细内容预算\n                \"context\": 4000,           # 相关上下文预算\n                \"history\": 2000            # 历史记录预算\n            }\n        \n        # 加载或初始化索引\n        self.index_file = self.memory_dir / \"index.json\"\n        self.index = self._load_index()\n    \n    def _load_index(self) -> Dict:\n        \"\"\"加载内存索引\"\"\"\n        if self.index_file.exists():\n            with open(self.index_file, 'r', encoding='utf-8') as f:\n                return json.load(f)\n        return {\n            \"files\": {},      # 文件索引\n            \"episodes\": [],   # 事件索引\n            \"states\": [],     # 状态索引\n            \"access_log\": []  # 访问日志\n        }\n    \n    def _save_index(self):\n        \"\"\"保存内存索引\"\"\"\n        with open(self.index_file, 'w', encoding='utf-8') as f:\n            json.dump(self.index, f, indent=2, ensure_ascii=False)\n    \n    def _estimate_tokens(self, text: str) -> int:\n        \"\"\"估算文本的token数\"\"\"\n        # 简化估算: 中文约1.5字符/token, 英文约4字符/token\n        chinese_chars = len([c for c in text if '\\u4e00' <= c <= '\\u9fff'])\n        english_chars = len(text) - chinese_chars\n        return int(chinese_chars / 1.5 + english_chars / 4)\n    \n    def _get_file_hash(self, content: str) -> str:\n        \"\"\"计算内容哈希\"\"\"\n        return hashlib.md5(content.encode()).hexdigest()[:8]\n    \n    def _compress_content(self, content: str, resolution: Resolution) -> str:\n        \"\"\"根据分辨率压缩内容\"\"\"\n        lines = content.split('\\n')\n        \n        if resolution == Resolution.TITLE:\n            # 仅返回第一行或标题\n            return lines[0][:100] if lines else \"\"\n        \n        elif resolution == Resolution.OUTLINE:\n            # 返回关键行(函数定义、类定义、注释等)\n            outline = []\n            for line in lines[:50]:  # 最多前50行\n                stripped = line.strip()\n                if any(keyword in stripped for keyword in \n                       ['def ', 'class ', '#', '//', '/*', 'function', 'const ', 'let ', 'var ']):\n                    outline.append(line)\n            return '\\n'.join(outline[:10])  # 最多10行\n        \n        elif resolution == Resolution.PREVIEW:\n            # 返回前200个token的内容\n            preview = []\n            token_count = 0\n            for line in lines:\n                line_tokens = self._estimate_tokens(line)\n                if token_count + line_tokens > 200:\n                    break\n                preview.append(line)\n                token_count += line_tokens\n            return '\\n'.join(preview)\n        \n        else:  # FULL\n            return content\n    \n    def save_episode(self, event: str, data: Dict[str, Any]) -> str:\n        \"\"\"\n        保存事件到潜意识\n        \n        Args:\n            event: 事件类型\n            data: 事件数据\n            \n        Returns:\n            事件ID\n        \"\"\"\n        timestamp = datetime.now().isoformat()\n        episode_id = f\"{event}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        \n        episode = {\n            \"id\": episode_id,\n            \"timestamp\": timestamp,\n            \"event\": event,\n            \"data\": data\n        }\n        \n        # 保存到文件系统\n        episode_file = self.filesystem[\"episodes\"] / f\"{episode_id}.json\"\n        with open(episode_file, 'w', encoding='utf-8') as f:\n            json.dump(episode, f, indent=2, ensure_ascii=False)\n        \n        # 更新索引\n        self.index[\"episodes\"].append({\n            \"id\": episode_id,\n            \"timestamp\": timestamp,\n            \"event\": event,\n            \"summary\": data.get(\"summary\", \"\")\n        })\n        \n        # 保持索引大小\n        if len(self.index[\"episodes\"]) > 1000:\n            self.index[\"episodes\"] = self.index[\"episodes\"][-500:]\n        \n        self._save_index()\n        return episode_id\n    \n    def save_state(self, state_name: str, state_data: Dict) -> str:\n        \"\"\"\n        保存状态快照\n        \n        Args:\n            state_name: 状态名称\n            state_data: 状态数据\n            \n        Returns:\n            状态ID\n        \"\"\"\n        state_id = f\"{state_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        \n        state = {\n            \"id\": state_id,\n            \"name\": state_name,\n            \"timestamp\": datetime.now().isoformat(),\n            \"data\": state_data\n        }\n        \n        # 保存到文件系统\n        state_file = self.filesystem[\"states\"] / f\"{state_id}.json\"\n        with open(state_file, 'w', encoding='utf-8') as f:\n            json.dump(state, f, indent=2, ensure_ascii=False)\n        \n        # 更新索引\n        self.index[\"states\"].append({\n            \"id\": state_id,\n            \"name\": state_name,\n            \"timestamp\": state[\"timestamp\"]\n        })\n        \n        # 保持最近N个状态\n        if len(self.index[\"states\"]) > 100:\n            self.index[\"states\"] = self.index[\"states\"][-50:]\n        \n        self._save_index()\n        return state_id\n    \n    def open_file(self, file_path: str, content: str) -> None:\n        \"\"\"\n        在编辑器中打开文件(加载到显意识)\n        \n        Args:\n            file_path: 文件路径\n            content: 文件内容\n        \"\"\"\n        file_hash = self._get_file_hash(content)\n        \n        # 保存到潜意识(如果是新内容)\n        if file_path not in self.index[\"files\"] or \\\n           self.index[\"files\"][file_path].get(\"hash\") != file_hash:\n            \n            workspace_file = self.filesystem[\"workspace\"] / Path(file_path).name\n            with open(workspace_file, 'w', encoding='utf-8') as f:\n                f.write(content)\n            \n            self.index[\"files\"][file_path] = {\n                \"path\": str(workspace_file),\n                \"hash\": file_hash,\n                \"size\": len(content),\n                \"tokens\": self._estimate_tokens(content),\n                \"last_access\": datetime.now().isoformat()\n            }\n            self._save_index()\n        \n        # 更新显意识\n        self.consciousness[\"focus_item\"] = file_path\n        self.consciousness[\"detail_view\"] = content\n        \n        # 添加到工作集\n        if file_path not in self.consciousness[\"working_set\"]:\n            self.consciousness[\"working_set\"].append(file_path)\n        \n        # 更新注意力\n        self.attention[\"focus\"] = file_path\n        \n        # 记录访问\n        self._log_access(file_path)\n    \n    def _log_access(self, item: str):\n        \"\"\"记录访问日志\"\"\"\n        self.index[\"access_log\"].append({\n            \"item\": item,\n            \"timestamp\": datetime.now().isoformat()\n        })\n        \n        # 保持日志大小\n        if len(self.index[\"access_log\"]) > 1000:\n            self.index[\"access_log\"] = self.index[\"access_log\"][-500:]\n    \n    def search(self, query: str) -> List[Dict]:\n        \"\"\"\n        搜索记忆\n        \n        Args:\n            query: 搜索查询\n            \n        Returns:\n            搜索结果列表\n        \"\"\"\n        results = []\n        \n        # 搜索文件\n        for file_path, file_info in self.index[\"files\"].items():\n            if query.lower() in file_path.lower():\n                results.append({\n                    \"type\": \"file\",\n                    \"path\": file_path,\n                    \"relevance\": 0.8\n                })\n        \n        # 搜索事件\n        for episode in self.index[\"episodes\"]:\n            if query.lower() in episode.get(\"event\", \"\").lower() or \\\n               query.lower() in episode.get(\"summary\", \"\").lower():\n                results.append({\n                    \"type\": \"episode\",\n                    \"id\": episode[\"id\"],\n                    \"event\": episode[\"event\"],\n                    \"relevance\": 0.6\n                })\n        \n        # 更新发现到显意识\n        self.consciousness[\"findings\"] = results[:10]\n        \n        return results\n    \n    def focus_on(self, target: str) -> None:\n        \"\"\"\n        聚焦到特定目标\n        \n        Args:\n            target: 目标(文件路径、事件ID等)\n        \"\"\"\n        self.attention[\"focus\"] = target\n        \n        # 动态加载相关上下文\n        self.attention[\"context\"] = self._find_related(target)\n        \n        # 更新最近访问\n        if target not in self.attention[\"recent\"]:\n            self.attention[\"recent\"].insert(0, target)\n        \n        # 保持最近访问列表大小\n        self.attention[\"recent\"] = self.attention[\"recent\"][:20]\n    \n    def _find_related(self, target: str, max_items: int = 5) -> List[str]:\n        \"\"\"\n        查找相关项\n        \n        Args:\n            target: 目标项\n            max_items: 最大返回数量\n            \n        Returns:\n            相关项列表\n        \"\"\"\n        related = []\n        \n        # 基于访问日志找相关项\n        target_accesses = [log for log in self.index[\"access_log\"] \n                          if log[\"item\"] == target]\n        \n        if target_accesses:\n            last_access_time = target_accesses[-1][\"timestamp\"]\n            \n            # 找时间上接近的访问\n            for log in self.index[\"access_log\"]:\n                if log[\"item\"] != target and \\\n                   abs((datetime.fromisoformat(log[\"timestamp\"]) - \n                        datetime.fromisoformat(last_access_time)).total_seconds()) < 300:\n                    if log[\"item\"] not in related:\n                        related.append(log[\"item\"])\n        \n        return related[:max_items]\n    \n    def compress_for_llm(self, extra_tokens: int = 0) -> str:\n        \"\"\"\n        为LLM压缩当前记忆状态\n        \n        Args:\n            extra_tokens: 额外需要预留的token数\n            \n        Returns:\n            压缩后的记忆状态文本\n        \"\"\"\n        available_tokens = self.max_tokens - extra_tokens\n        used_tokens = 0\n        compressed = []\n        \n        # 1. 当前焦点(最高优先级)\n        if self.attention[\"focus\"] and self.consciousness[\"detail_view\"]:\n            focus_content = self._compress_content(\n                self.consciousness[\"detail_view\"],\n                Resolution.FULL if available_tokens > 10000 else Resolution.PREVIEW\n            )\n            focus_tokens = self._estimate_tokens(focus_content)\n            \n            if used_tokens + focus_tokens < available_tokens:\n                compressed.append(f\"=== 当前焦点: {self.attention['focus']} ===\\n{focus_content}\")\n                used_tokens += focus_tokens\n        \n        # 2. 工作集(中优先级)\n        if self.consciousness[\"working_set\"]:\n            compressed.append(\"\\n=== 工作集 ===\")\n            for item in self.consciousness[\"working_set\"]:\n                if item == self.attention[\"focus\"]:\n                    continue\n                \n                # 从潜意识加载摘要\n                if item in self.index[\"files\"]:\n                    file_info = self.index[\"files\"][item]\n                    item_summary = f\"- {item} ({file_info['size']} bytes, {file_info['tokens']} tokens)\"\n                    item_tokens = self._estimate_tokens(item_summary)\n                    \n                    if used_tokens + item_tokens < available_tokens:\n                        compressed.append(item_summary)\n                        used_tokens += item_tokens\n        \n        # 3. 资源大纲(低优先级)\n        if self.consciousness[\"resource_outline\"]:\n            compressed.append(\"\\n=== 资源大纲 ===\")\n            outline_text = \"\\n\".join(self.consciousness[\"resource_outline\"][:30])\n            outline_tokens = self._estimate_tokens(outline_text)\n            \n            if used_tokens + outline_tokens < available_tokens:\n                compressed.append(outline_text)\n                used_tokens += outline_tokens\n        \n        # 4. 全局概览\n        if self.consciousness[\"overview\"]:\n            compressed.append(\"\\n=== 项目概览 ===\")\n            overview_text = \"\\n\".join(self.consciousness[\"overview\"][:10])\n            overview_tokens = self._estimate_tokens(overview_text)\n            \n            if used_tokens + overview_tokens < available_tokens:\n                compressed.append(overview_text)\n                used_tokens += overview_tokens\n        \n        # 5. 最近事件\n        if self.index[\"episodes\"]:\n            compressed.append(\"\\n=== 最近事件 ===\")\n            recent_episodes = self.index[\"episodes\"][-5:]\n            for episode in recent_episodes:\n                episode_text = f\"- [{episode['timestamp'][:10]}] {episode['event']}: {episode.get('summary', '')[:50]}\"\n                episode_tokens = self._estimate_tokens(episode_text)\n                \n                if used_tokens + episode_tokens < available_tokens:\n                    compressed.append(episode_text)\n                    used_tokens += episode_tokens\n        \n        # 6. 发现\n        if self.consciousness[\"findings\"]:\n            compressed.append(\"\\n=== 发现 ===\")\n            for result in self.consciousness[\"findings\"][:5]:\n                result_text = f\"- {result['type']}: {result.get('path', result.get('id', ''))}\"\n                result_tokens = self._estimate_tokens(result_text)\n                \n                if used_tokens + result_tokens < available_tokens:\n                    compressed.append(result_text)\n                    used_tokens += result_tokens\n        \n        return \"\\n\".join(compressed)\n    \n    def garbage_collect(self, keep_recent: int = 100):\n        \"\"\"\n        垃圾回收 - 清理旧的记忆\n        \n        Args:\n            keep_recent: 保留最近N个项目\n        \"\"\"\n        # 清理旧事件\n        episode_files = sorted(self.filesystem[\"episodes\"].glob(\"*.json\"))\n        if len(episode_files) > keep_recent:\n            for f in episode_files[:-keep_recent]:\n                f.unlink()\n        \n        # 清理旧状态\n        state_files = sorted(self.filesystem[\"states\"].glob(\"*.json\"))\n        if len(state_files) > keep_recent // 2:\n            for f in state_files[:-keep_recent//2]:\n                f.unlink()\n        \n        # 更新索引\n        self.index[\"episodes\"] = self.index[\"episodes\"][-keep_recent:]\n        self.index[\"states\"] = self.index[\"states\"][-keep_recent//2:]\n        self.index[\"access_log\"] = self.index[\"access_log\"][-keep_recent*10:]\n        \n        self._save_index()\n    \n    def export_session(self) -> Dict:\n        \"\"\"导出当前会话状态\"\"\"\n        return {\n            \"timestamp\": datetime.now().isoformat(),\n            \"consciousness\": self.consciousness,\n            \"attention\": self.attention,\n            \"memory_stats\": {\n                \"files\": len(self.index[\"files\"]),\n                \"episodes\": len(self.index[\"episodes\"]),\n                \"states\": len(self.index[\"states\"]),\n                \"working_set_size\": len(self.consciousness[\"working_set\"]),\n                \"current_focus\": self.consciousness[\"focus_item\"]\n            }\n        }\n    \n    def import_session(self, session_data: Dict):\n        \"\"\"导入会话状态\"\"\"\n        if \"consciousness\" in session_data:\n            self.consciousness = session_data[\"consciousness\"]\n        if \"attention\" in session_data:\n            self.attention = session_data[\"attention\"]"
      },
      "tokens": 5821,
      "generated_at": "2025-08-19T21:57:10.956131"
    },
    "MINIMAL": {
      "content": {
        "marker": "[tool:result]"
      },
      "tokens": 5,
      "generated_at": "2025-08-19T21:57:10.956149"
    },
    "HIGH": {
      "content": {
        "role": "tool",
        "content": "#!/usr/bin/env python3\n\"\"\"\nVSCode记忆模式 - 基于VSCode的内存管理模式\n模拟人类思维的潜意识(文件系统)和显意识(工作界面)\n\n设计理念：\n- 潜意识(文件系统): 持久化存储，完整但访问较慢\n- 显意识(界面): 内存中的活跃内容，快速访问但容量有限\n- 动态分辨率: 根据注意力焦点动态调整信息清晰度\n\"\"\"\n\nimport json\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime\nfrom enum import Enum\n\nclass Resolution(Enum):\n    \"\"\"信息分辨率级别\"\"\"\n    TITLE = 1      # 仅标题 (~10 tokens)\n    OUTLINE = 2    # 大纲 (~50 tokens)  \n    PREVIEW = 3    # 预览 (~200 tokens)\n    FULL = 4       # 完整内容\n\nclass VSCodeMemory:\n    \"\"\"VSCode记忆模式实现\"\"\"\n    \n    def __init__(self, workspace_\n...[部分内容省略]...\n       if \"consciousness\" in session_data:\n            self.consciousness = session_data[\"consciousness\"]\n        if \"attention\" in session_data:\n            self.attention = session_data[\"attention\"]"
      },
      "tokens": 394,
      "generated_at": "2025-08-19T21:57:10.956614"
    },
    "MEDIUM": {
      "content": {
        "role": "tool",
        "content_preview": "#!/usr/bin/env python3\n\"\"\"\nVSCode记忆模式 - 基于VSCode的内存管理模式\n模拟人类思维的潜意识(文件系统)和显意识(工作界面)\n\n设计理念：\n- 潜意识(文件系统): 持久化存储，完整但访问较慢\n- 显意识(界面): 内存中的活跃内容，快速访问但容量有限\n- 动态分辨率: 根据注意力焦点动态调整信息清晰度\n\"\"\"\n\nimport json\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime impo..."
      },
      "tokens": 220,
      "generated_at": "2025-08-19T21:57:10.956637"
    },
    "LOW": {
      "content": {
        "role": "tool",
        "summary": "工具返回结果"
      },
      "tokens": 16,
      "generated_at": "2025-08-19T21:57:10.956925"
    }
  }
}