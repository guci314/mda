#!/usr/bin/env python3
"""
éªŒè¯Agentè‡ªä¸»å­¦ä¹ æ•ˆæœ - å¯¹æ¯”å®éªŒ
"""

import os
import json
import shutil
from pathlib import Path
from datetime import datetime
from core.react_agent_minimal import ReactAgentMinimal

class LearningEffectVerifier:
    """éªŒè¯å­¦ä¹ æ•ˆæœçš„å®éªŒæ¡†æ¶"""
    
    def __init__(self):
        self.results = {
            "without_learning": [],
            "with_learning": []
        }
        
    def prepare_test_tasks(self):
        """å‡†å¤‡æµ‹è¯•ä»»åŠ¡åºåˆ—ï¼ˆç›¸ä¼¼ä½†ä¸åŒçš„ä»»åŠ¡ï¼‰"""
        return [
            {
                "name": "debug_task_1",
                "task": """
                ä¿®å¤ä»¥ä¸‹Pythonä»£ç é”™è¯¯ï¼š
                def add(a, b):
                    return a + b + c  # cæœªå®šä¹‰
                """,
                "expected_pattern": "æœªå®šä¹‰å˜é‡"
            },
            {
                "name": "debug_task_2", 
                "task": """
                ä¿®å¤ä»¥ä¸‹Pythonä»£ç é”™è¯¯ï¼š
                def multiply(x, y):
                    return x * y * z  # zæœªå®šä¹‰
                """,
                "expected_pattern": "æœªå®šä¹‰å˜é‡"  # ç›¸åŒæ¨¡å¼
            },
            {
                "name": "debug_task_3",
                "task": """
                ä¿®å¤ä»¥ä¸‹Pythonä»£ç é”™è¯¯ï¼š
                def divide(m, n):
                    result = m / n / p  # pæœªå®šä¹‰
                    return result
                """,
                "expected_pattern": "æœªå®šä¹‰å˜é‡"  # åˆæ˜¯ç›¸åŒæ¨¡å¼
            }
        ]
    
    def run_without_learning(self, tasks):
        """è¿è¡Œä¸å¸¦å­¦ä¹ çš„Agentï¼ˆä¸ä½¿ç”¨agent_knowledge.mdï¼‰"""
        print("\n" + "="*60)
        print("ğŸ”´ æµ‹è¯•1ï¼šæ— å­¦ä¹ æœºåˆ¶çš„Agent")
        print("="*60)
        
        for i, task_def in enumerate(tasks):
            print(f"\nä»»åŠ¡ {i+1}: {task_def['name']}")
            
            # åˆ›å»ºæ–°Agentï¼Œä¸è¯»å–çŸ¥è¯†
            agent = ReactAgentMinimal(
                work_dir=f"output/test_no_learning_{i}",
                name=f"no_learning_{i}",
                model="kimi-k2-turbo-preview",  # ä½¿ç”¨kimi
                knowledge_files=["knowledge/structured_notes.md"]  # åªç»™ç»“æ„ï¼Œä¸ç»™å†å²çŸ¥è¯†
            )
            
            start_time = datetime.now()
            
            # æ‰§è¡Œä»»åŠ¡
            result = agent.execute(task=task_def['task'])
            
            elapsed = (datetime.now() - start_time).total_seconds()
            
            # è®°å½•ç»“æœ
            self.results["without_learning"].append({
                "task": task_def['name'],
                "time": elapsed,
                "pattern": task_def['expected_pattern'],
                "learned": False
            })
            
            print(f"  è€—æ—¶: {elapsed:.1f}ç§’")
            
            # æ¸…ç†ï¼ˆä¸ä¿ç•™çŸ¥è¯†ï¼‰
            if Path(f"output/test_no_learning_{i}").exists():
                shutil.rmtree(f"output/test_no_learning_{i}")
    
    def run_with_learning(self, tasks):
        """è¿è¡Œå¸¦å­¦ä¹ çš„Agentï¼ˆä½¿ç”¨æ”¹è¿›çš„agent_knowledge.mdæ¨¡æ¿ï¼‰"""
        print("\n" + "="*60)
        print("ğŸŸ¢ æµ‹è¯•2ï¼šæœ‰å­¦ä¹ æœºåˆ¶çš„Agentï¼ˆSONICæ–¹æ³•è®ºï¼‰")
        print("="*60)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å·¥ä½œç›®å½•ï¼Œè®©çŸ¥è¯†è‡ªç„¶ç´¯ç§¯
        work_dir = "output/test_with_learning"
        
        for i, task_def in enumerate(tasks):
            print(f"\nä»»åŠ¡ {i+1}: {task_def['name']}")
            
            # æ„å»ºçŸ¥è¯†æ–‡ä»¶åˆ—è¡¨
            knowledge_files = ["knowledge/structured_notes.md"]
            
            # å¦‚æœå­˜åœ¨ç´¯ç§¯çš„çŸ¥è¯†ï¼Œæ·»åŠ åˆ°çŸ¥è¯†æ–‡ä»¶åˆ—è¡¨
            knowledge_path = Path(work_dir) / ".notes/learning_agent/agent_knowledge.md"
            if knowledge_path.exists():
                knowledge_files.append(str(knowledge_path))
                print(f"  ğŸ“š æ£€æµ‹åˆ°å·²æœ‰çŸ¥è¯†ï¼Œæ–°Agentä¼šè¯»å–...")
            
            # æ¯ä¸ªä»»åŠ¡åˆ›å»ºæ–°Agentå®ä¾‹ï¼ˆé¿å…æ¶ˆæ¯ç´¯ç§¯ï¼‰ï¼Œä½†ä½¿ç”¨ç›¸åŒçš„å·¥ä½œç›®å½•å’Œåç§°
            agent = ReactAgentMinimal(
                work_dir=work_dir,  # ç»Ÿä¸€çš„å·¥ä½œç›®å½•
                name="learning_agent",  # ç»Ÿä¸€çš„Agentåç§°
                model="kimi-k2-turbo-preview",  # ä½¿ç”¨kimi
                knowledge_files=knowledge_files  # åŒ…å«ç´¯ç§¯çš„çŸ¥è¯†
            )
            
            
            start_time = datetime.now()
            
            # æ‰§è¡Œä»»åŠ¡
            result = agent.execute(task=f"""
            {task_def['task']}
            
            **æ‰§è¡Œè¦æ±‚**ï¼š
            - æ£€æŸ¥æ˜¯å¦åŒ¹é…å·²çŸ¥æ¨¡å¼ï¼ˆè¯»å–agent_knowledge.mdï¼‰
            - å¦‚æœæ˜¯å·²çŸ¥æ¨¡å¼ï¼Œç›´æ¥åº”ç”¨å·²çŸ¥è§£å†³æ–¹æ¡ˆ
            - åŠ¨æ€ä¿®æ”¹TODOï¼šå‘ç°æ·å¾„æ—¶åˆ é™¤ä¸å¿…è¦æ­¥éª¤
            
            ä»»åŠ¡ç»“æŸæ—¶ï¼Œè¯·æ›´æ–°çŸ¥è¯†æ–‡ä»¶ï¼š
            - ä½¿ç”¨write_fileå·¥å…·å†™å…¥åˆ°: .notes/learning_agent/agent_knowledge.mdï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            - å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆç”¨read_fileè¯»å–ï¼Œç„¶åæ›´æ–°å†…å®¹
            - è¯†åˆ«æ¨¡å¼å¹¶è®°å½•é¢‘ç‡ï¼ˆè¿™æ˜¯ç¬¬{i+1}æ¬¡ä»»åŠ¡ï¼‰
            - å¦‚æœæ˜¯é‡å¤æ¨¡å¼ï¼ˆæœªå®šä¹‰å˜é‡ï¼‰ï¼Œæ›´æ–°å‡ºç°æ¬¡æ•°ä¸º{i+1}æ¬¡
            - è®°å½•æœ¬æ¬¡å®é™…æ‰§è¡Œè½®æ•°
            """)
            
            elapsed = (datetime.now() - start_time).total_seconds()
            
            # æ£€æŸ¥æ˜¯å¦å­¦åˆ°äº†æ¨¡å¼
            learned = False
            knowledge_path = Path(work_dir) / ".notes/learning_agent/agent_knowledge.md"
            if knowledge_path.exists():
                with open(knowledge_path, "r") as f:
                    content = f.read()
                    if "æœªå®šä¹‰å˜é‡" in content:
                        learned = True
                        # æ£€æŸ¥é¢‘ç‡
                        if "3æ¬¡" in content or "ç¬¬3æ¬¡" in content or str(i+1) + "æ¬¡" in content:
                            print(f"  âœ… è¯†åˆ«åˆ°é‡å¤æ¨¡å¼ï¼")
            
            # è®°å½•ç»“æœ
            self.results["with_learning"].append({
                "task": task_def['name'],
                "time": elapsed,
                "pattern": task_def['expected_pattern'],
                "learned": learned
            })
            
            print(f"  è€—æ—¶: {elapsed:.1f}ç§’")
            if learned and i > 0:
                print(f"  ğŸ“ˆ ç›¸æ¯”æ— å­¦ä¹ ç‰ˆæœ¬å¿«äº†: {self.results['without_learning'][i]['time'] - elapsed:.1f}ç§’")
    
    def analyze_results(self):
        """åˆ†æå­¦ä¹ æ•ˆæœ"""
        print("\n" + "="*60)
        print("ğŸ“Š å­¦ä¹ æ•ˆæœåˆ†æ")
        print("="*60)
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        no_learn_times = [r['time'] for r in self.results['without_learning']]
        learn_times = [r['time'] for r in self.results['with_learning']]
        
        no_learn_avg = sum(no_learn_times) / len(no_learn_times) if no_learn_times else 0
        learn_avg = sum(learn_times) / len(learn_times) if learn_times else 0
        
        print(f"\nâ±ï¸ æ‰§è¡Œæ•ˆç‡å¯¹æ¯”ï¼š")
        print(f"  æ— å­¦ä¹ å¹³å‡: {no_learn_avg:.1f}ç§’")
        print(f"  æœ‰å­¦ä¹ å¹³å‡: {learn_avg:.1f}ç§’")
        print(f"  æ•ˆç‡æå‡: {(no_learn_avg - learn_avg) / no_learn_avg * 100:.1f}%")
        
        # å­¦ä¹ æ›²çº¿
        print(f"\nğŸ“ˆ å­¦ä¹ æ›²çº¿ï¼š")
        print("  ä»»åŠ¡  æ— å­¦ä¹   æœ‰å­¦ä¹   å·®å€¼")
        for i in range(len(no_learn_times)):
            diff = no_learn_times[i] - learn_times[i]
            print(f"   {i+1}    {no_learn_times[i]:6.1f}  {learn_times[i]:6.1f}  {diff:+6.1f}")
        
        # æ¨¡å¼è¯†åˆ«
        learned_patterns = sum(1 for r in self.results['with_learning'] if r['learned'])
        total_tasks = len(self.results['with_learning'])
        print(f"\nğŸ¯ æ¨¡å¼è¯†åˆ«ï¼š")
        print(f"  è¯†åˆ«å‡ºçš„æ¨¡å¼æ•°: {learned_patterns}")
        if total_tasks > 0:
            print(f"  æ¨¡å¼å¤ç”¨ç‡: {learned_patterns / total_tasks * 100:.1f}%")
        
        # æ”¹è¿›è¶‹åŠ¿
        if len(learn_times) >= 3:
            first_third = learn_times[0]
            last_third = learn_times[-1]
            improvement = (first_third - last_third) / first_third * 100
            print(f"\nğŸ“‰ æ”¹è¿›è¶‹åŠ¿ï¼š")
            print(f"  ç¬¬1ä¸ªä»»åŠ¡: {first_third:.1f}ç§’")
            print(f"  ç¬¬3ä¸ªä»»åŠ¡: {last_third:.1f}ç§’")
            print(f"  æ”¹è¿›å¹…åº¦: {improvement:.1f}%")
        
        return {
            "no_learning_avg": no_learn_avg,
            "learning_avg": learn_avg,
            "improvement": (no_learn_avg - learn_avg) / no_learn_avg * 100 if no_learn_avg > 0 else 0,
            "patterns_learned": learned_patterns
        }
    
    def verify_knowledge_evolution(self):
        """éªŒè¯çŸ¥è¯†è¿›åŒ–è´¨é‡"""
        print("\n" + "="*60)
        print("ğŸ” çŸ¥è¯†è´¨é‡åˆ†æ")
        print("="*60)
        
        knowledge_file = Path("output/test_with_learning/.notes/learning_agent/agent_knowledge.md")
        if not knowledge_file.exists():
            print("âŒ æœªæ‰¾åˆ°çŸ¥è¯†æ–‡ä»¶")
            return 0  # è¿”å›0è€Œä¸æ˜¯None
        
        with open(knowledge_file, "r") as f:
            content = f.read()
        
        # æ£€æŸ¥å…³é”®è¦ç´ 
        quality_checks = {
            "é¢‘ç‡ç»Ÿè®¡": "æ¬¡ä»»åŠ¡ä¸­å‡ºç°" in content or "é¢‘ç‡" in content,
            "æ¨¡å¼å‘½å": "## æ¨¡å¼è¯†åˆ«" in content or "### " in content,
            "æŠ½è±¡åŸç†": "åŸç†" in content or "é€šç”¨" in content,
            "é‡åŒ–æŒ‡æ ‡": "è½®" in content or "%" in content,
            "å¤±è´¥è®°å½•": "å¤±è´¥" in content or "é”™è¯¯" in content
        }
        
        print("\nçŸ¥è¯†è´¨é‡æ£€æŸ¥ï¼š")
        for check, passed in quality_checks.items():
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {check}")
        
        quality_score = sum(quality_checks.values()) / len(quality_checks) * 100
        print(f"\nçŸ¥è¯†è´¨é‡å¾—åˆ†: {quality_score:.0f}%")
        
        # å±•ç¤ºéƒ¨åˆ†çŸ¥è¯†å†…å®¹
        print("\nğŸ“ çŸ¥è¯†æ ·ä¾‹ï¼š")
        lines = content.split('\n')[:20]  # å‰20è¡Œ
        for line in lines:
            if line.strip() and not line.startswith('#'):
                print(f"  {line}")
        
        return quality_score


def run_verification():
    """è¿è¡Œå®Œæ•´çš„éªŒè¯å®éªŒ"""
    print("="*60)
    print("ğŸ§ª Agentè‡ªä¸»å­¦ä¹ æ•ˆæœéªŒè¯å®éªŒ")
    print("="*60)
    
    verifier = LearningEffectVerifier()
    
    # å‡†å¤‡æµ‹è¯•ä»»åŠ¡
    tasks = verifier.prepare_test_tasks()
    print(f"\nå‡†å¤‡äº† {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡")
    
    # è¿è¡Œå¯¹æ¯”å®éªŒ
    verifier.run_without_learning(tasks)
    verifier.run_with_learning(tasks)
    
    # åˆ†æç»“æœ
    results = verifier.analyze_results()
    
    # éªŒè¯çŸ¥è¯†è´¨é‡
    quality = verifier.verify_knowledge_evolution()
    
    # æœ€ç»ˆç»“è®º
    print("\n" + "="*60)
    print("âœ… å®éªŒç»“è®º")
    print("="*60)
    
    if results['improvement'] > 20:
        print("ğŸ‰ å­¦ä¹ æ•ˆæœæ˜¾è‘—ï¼")
    elif results['improvement'] > 10:
        print("ğŸ‘ å­¦ä¹ æ•ˆæœè‰¯å¥½")
    else:
        print("ğŸ¤” å­¦ä¹ æ•ˆæœæœ‰é™ï¼Œéœ€è¦ç»§ç»­ä¼˜åŒ–")
    
    print(f"\nå…³é”®æŒ‡æ ‡ï¼š")
    print(f"  - æ•ˆç‡æå‡: {results['improvement']:.1f}%")
    print(f"  - æ¨¡å¼è¯†åˆ«: {results['patterns_learned']}ä¸ª")
    if quality is not None:
        print(f"  - çŸ¥è¯†è´¨é‡: {quality:.0f}%")
    else:
        print(f"  - çŸ¥è¯†è´¨é‡: æ— æ³•è¯„ä¼°")
    
    # ä¿å­˜ç»“æœ
    with open("learning_verification_results.json", "w") as f:
        json.dump({
            "results": results,
            "quality_score": quality if quality is not None else 0,
            "timestamp": datetime.now().isoformat()
        }, f, indent=2)
    
    print(f"\nğŸ“Š è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° learning_verification_results.json")


if __name__ == "__main__":
    run_verification()